{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c6fc665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b7585",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.clear_all_output();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee08fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 3.8.8\n",
      "Tensorflow version 2.8.0\n",
      "Keras version 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "print(\"Python version %s.%s.%s\" % sys.version_info[:3])\n",
    "print(\"Tensorflow version %s\" % tf.__version__)\n",
    "print(\"Keras version %s\" % keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0414b",
   "metadata": {},
   "source": [
    "Import data from csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7c5709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0_0_20161219140623097.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_0_0_20161219140627985.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_0_0_20161219140642920.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_0_0_20161219154018476.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_0_0_20161219154556757.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               FILENAME  AGE\n",
       "0  1_0_0_20161219140623097.jpg.chip.jpg    1\n",
       "1  1_0_0_20161219140627985.jpg.chip.jpg    1\n",
       "2  1_0_0_20161219140642920.jpg.chip.jpg    1\n",
       "3  1_0_0_20161219154018476.jpg.chip.jpg    1\n",
       "4  1_0_0_20161219154556757.jpg.chip.jpg    1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#C:\\codebase\\preprocessed\\Unmodified>\n",
    "labels = pd.read_csv('C:\\\\codebase\\\\preprocessed\\\\CannyEdges\\\\CSV Filenames DL SP22.csv')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5db9c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0_0_20161219140623097.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_0_0_20161219140627985.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_0_0_20161219140642920.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_0_0_20161219154018476.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_0_0_20161219154556757.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9775</th>\n",
       "      <td>100_1_0_20170110183726390.jpg.chip.jpg</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9776</th>\n",
       "      <td>100_1_2_20170105174847679.jpg.chip.jpg</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9777</th>\n",
       "      <td>101_1_2_20170105174739309.jpg.chip.jpg</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9778</th>\n",
       "      <td>110_1_1_20170110155201038.jpg.chip.jpg</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9779</th>\n",
       "      <td>110_1_3_20170110155139762.jpg.chip.jpg</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9780 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    FILENAME  AGE\n",
       "0       1_0_0_20161219140623097.jpg.chip.jpg    1\n",
       "1       1_0_0_20161219140627985.jpg.chip.jpg    1\n",
       "2       1_0_0_20161219140642920.jpg.chip.jpg    1\n",
       "3       1_0_0_20161219154018476.jpg.chip.jpg    1\n",
       "4       1_0_0_20161219154556757.jpg.chip.jpg    1\n",
       "...                                      ...  ...\n",
       "9775  100_1_0_20170110183726390.jpg.chip.jpg  100\n",
       "9776  100_1_2_20170105174847679.jpg.chip.jpg  100\n",
       "9777  101_1_2_20170105174739309.jpg.chip.jpg  101\n",
       "9778  110_1_1_20170110155201038.jpg.chip.jpg  110\n",
       "9779  110_1_3_20170110155139762.jpg.chip.jpg  110\n",
       "\n",
       "[9780 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7712771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic number variables due to prior knowledge of dataset and algorithm needs\n",
    "\n",
    "label_1 = \"%s - %s\" %((labels[\"AGE\"][0]) , (labels[\"AGE\"][1870]))\n",
    "label_2 = \"%s - %s\" %((labels[\"AGE\"][1871]) , (labels[\"AGE\"][2786]))\n",
    "label_3 = \"%s - %s\" %((labels[\"AGE\"][2787]) , (labels[\"AGE\"][3821]))\n",
    "label_4 = \"%s - %s\" %((labels[\"AGE\"][3822]) , (labels[\"AGE\"][4980]))\n",
    "label_5 = \"%s - %s\" %((labels[\"AGE\"][4981]) , (labels[\"AGE\"][6027]))\n",
    "label_6 = \"%s - %s\" %((labels[\"AGE\"][6027]) , (labels[\"AGE\"][6939]))\n",
    "label_7 = \"%s - %s\" %((labels[\"AGE\"][6939]) , (labels[\"AGE\"][7980]))\n",
    "label_8 = \"%s - %s\" %((labels[\"AGE\"][7980]) , (labels[\"AGE\"][8833]))\n",
    "label_9 = \"%s - %s\" %((labels[\"AGE\"][8834]) , (labels[\"AGE\"][9779]))\n",
    "\n",
    "total_labels = [label_1,\n",
    "                label_2,\n",
    "                label_3,\n",
    "                label_4,\n",
    "                label_5,\n",
    "                label_6,\n",
    "                label_7,\n",
    "                label_8,\n",
    "                label_9]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9352d598",
   "metadata": {},
   "source": [
    "Code for the extracting the image and perform it to the numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70a86fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "img_width = 224 #Magic number variables due to prior knowledge of dataset and algorithm needs\n",
    "\n",
    "def get_image(filename):\n",
    "    original = load_img(filename, target_size=(224, 224))\n",
    "    numpy_image = img_to_array(original)\n",
    "    return numpy_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ce9bd",
   "metadata": {},
   "source": [
    "testing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe58ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "#image = get_image('C:\\\\codebase\\\\preprocessed\\\\Unmodified\\\\%s' % labels['FILENAME'][0])\n",
    "#print(image.shape)\n",
    "#plt.imshow(np.uint8(image))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "795719fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Magic number variables due to prior knowledge of dataset and algorithm needs\n",
    "num_train_images = 9780 \n",
    "split_point = 7000\n",
    "num_classes = 9\n",
    "arr = [i for i in range(num_classes)]\n",
    "num = 9778 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f75c0",
   "metadata": {},
   "source": [
    "function to perform labels from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf809053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_num(num):\n",
    "    if (1 <= num <= 3):\n",
    "        return 0\n",
    "    if (4 <= num <= 8):\n",
    "        return 1\n",
    "    if (9 <= num <= 16):\n",
    "        return 2\n",
    "    if (17 <= num <= 25):\n",
    "        return 3\n",
    "    if (26 <= num <= 32):\n",
    "        return 4\n",
    "    if (33 <= num <= 42):\n",
    "        return 5\n",
    "    if (43 <= num <= 55):\n",
    "        return 6\n",
    "    if (56 <= num <= 66):\n",
    "        return 7\n",
    "    if (67 <= num <= 110):\n",
    "        return 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebe0a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign_num(labels[\"AGE\"][9779])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5707c40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images loaded\n",
      "2000 images loaded\n",
      "3000 images loaded\n",
      "4000 images loaded\n",
      "5000 images loaded\n",
      "6000 images loaded\n",
      "7000 images loaded\n",
      "8000 images loaded\n",
      "9000 images loaded\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((num_train_images, img_width, img_width, 3), dtype=np.uint8)\n",
    "y = np.zeros((num_train_images, num_classes), dtype=np.uint8)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(num_train_images):\n",
    "    x[i] = get_image('C:\\\\codebase\\\\preprocessed\\\\CannyEdges\\\\%s' % labels['FILENAME'][i])\n",
    "    y[i][assign_num(labels[\"AGE\"][i])] = 1\n",
    "    count += 1\n",
    "    if(count % 1000 == 0): print(count, 'images loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2e3ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 9778 #Magic number variables due to prior knowledge of dataset and algorithm needs\n",
    "#print(\"orig : %d\" % labels[\"AGE\"][num])\n",
    "#print(y[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83cb8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbe82ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "933aedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2a5a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "760ea601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f595e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01f358bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet50 = resnet50.ResNet50(weights='imagenet', include_top=True)\n",
    "#pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b37a6a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import resnet50\n",
    "vgg16_model = vgg16.VGG16(weights='imagenet', include_top=True)\n",
    "resnet50 = resnet50.ResNet50(weights='imagenet', include_top=True)\n",
    "new_resnet50 = Model(inputs = resnet50.input, outputs = resnet50.get_layer('avg_pool').output)\n",
    "new_vgg16 = Model(inputs = vgg16_model.input, outputs = vgg16_model.get_layer('fc2').output)\n",
    "new_resnet50.summary()\n",
    "new_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "497d6d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(resnet50.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d67fd476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 1775s 3s/step\n",
      "612/612 [==============================] - 5595s 9s/step\n"
     ]
    }
   ],
   "source": [
    "resnet_predictions = new_resnet50.predict(x, batch_size=16, verbose=1)\n",
    "vgg16_predictions = new_vgg16.predict(x, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f2ce1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56d7d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg16_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dc23a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = np.concatenate([resnet_predictions, vgg16_predictions],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f34eb2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "383f77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a4afcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Activation, BatchNormalization\n",
    "\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "##     Hyperparameters\n",
    "dropOutOne = 0.7\n",
    "denseTwoPower = 9 # 9 = 512\n",
    "dropOutTwo = 0.3\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "\n",
    "\n",
    "combined_inputs = Input(shape = (6144))\n",
    "x = Dropout(dropOutOne)(combined_inputs) # add a dropout layer\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(denseTwoPower)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(dropOutTwo)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "new_predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03afb07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 6144)             24576     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 9)                36        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "model = Model(inputs=combined_inputs, outputs=new_predictions) # specify what is network input, and what is network output\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74e7702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e045c113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "69/69 [==============================] - 3s 28ms/step - loss: 2.1525 - accuracy: 0.1985 - val_loss: 1.8908 - val_accuracy: 0.3170\n",
      "Epoch 2/30\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 1.9265 - accuracy: 0.3030 - val_loss: 1.8099 - val_accuracy: 0.3671\n",
      "Epoch 3/30\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 1.8554 - accuracy: 0.3262 - val_loss: 1.7453 - val_accuracy: 0.4008\n",
      "Epoch 4/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.7925 - accuracy: 0.3386 - val_loss: 1.6927 - val_accuracy: 0.3978\n",
      "Epoch 5/30\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 1.7460 - accuracy: 0.3532 - val_loss: 1.6476 - val_accuracy: 0.4070\n",
      "Epoch 6/30\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 1.7172 - accuracy: 0.3576 - val_loss: 1.6105 - val_accuracy: 0.4243\n",
      "Epoch 7/30\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 1.6838 - accuracy: 0.3706 - val_loss: 1.5832 - val_accuracy: 0.4223\n",
      "Epoch 8/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.6740 - accuracy: 0.3717 - val_loss: 1.5633 - val_accuracy: 0.4274\n",
      "Epoch 9/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.6623 - accuracy: 0.3750 - val_loss: 1.5513 - val_accuracy: 0.4223\n",
      "Epoch 10/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.6424 - accuracy: 0.3817 - val_loss: 1.5367 - val_accuracy: 0.4254\n",
      "Epoch 11/30\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 1.6324 - accuracy: 0.3828 - val_loss: 1.5255 - val_accuracy: 0.4366\n",
      "Epoch 12/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.6210 - accuracy: 0.3882 - val_loss: 1.5194 - val_accuracy: 0.4366\n",
      "Epoch 13/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.6136 - accuracy: 0.3812 - val_loss: 1.5140 - val_accuracy: 0.4387\n",
      "Epoch 14/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.6146 - accuracy: 0.3848 - val_loss: 1.5100 - val_accuracy: 0.4387\n",
      "Epoch 15/30\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 1.6078 - accuracy: 0.3906 - val_loss: 1.5051 - val_accuracy: 0.4438\n",
      "Epoch 16/30\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 1.6059 - accuracy: 0.3874 - val_loss: 1.5045 - val_accuracy: 0.4335\n",
      "Epoch 17/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.5815 - accuracy: 0.3988 - val_loss: 1.4969 - val_accuracy: 0.4325\n",
      "Epoch 18/30\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 1.5826 - accuracy: 0.4010 - val_loss: 1.5002 - val_accuracy: 0.4346\n",
      "Epoch 19/30\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 1.5800 - accuracy: 0.3985 - val_loss: 1.4970 - val_accuracy: 0.4346\n",
      "Epoch 20/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.5830 - accuracy: 0.3983 - val_loss: 1.4944 - val_accuracy: 0.4366\n",
      "Epoch 21/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.5824 - accuracy: 0.3950 - val_loss: 1.4916 - val_accuracy: 0.4356\n",
      "Epoch 22/30\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 1.5845 - accuracy: 0.4001 - val_loss: 1.4886 - val_accuracy: 0.4366\n",
      "Epoch 23/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.5713 - accuracy: 0.4010 - val_loss: 1.4823 - val_accuracy: 0.4448\n",
      "Epoch 24/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.5750 - accuracy: 0.3956 - val_loss: 1.4833 - val_accuracy: 0.4356\n",
      "Epoch 25/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.5642 - accuracy: 0.3988 - val_loss: 1.4833 - val_accuracy: 0.4335\n",
      "Epoch 26/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.5623 - accuracy: 0.4059 - val_loss: 1.4831 - val_accuracy: 0.4366\n",
      "Epoch 27/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.5729 - accuracy: 0.4062 - val_loss: 1.4815 - val_accuracy: 0.4397\n",
      "Epoch 28/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.5715 - accuracy: 0.3972 - val_loss: 1.4834 - val_accuracy: 0.4468\n",
      "Epoch 29/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.5615 - accuracy: 0.4018 - val_loss: 1.4829 - val_accuracy: 0.4438\n",
      "Epoch 30/30\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 1.5640 - accuracy: 0.4033 - val_loss: 1.4833 - val_accuracy: 0.4458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2edd12c6040>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',  patience=6, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=30, \n",
    "              validation_data=(X_test, y_test), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d23f547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 6144)             24576     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:8 D2:dropOutTwo0.1[0.27709612250328064, 0.38366279006004333, 0.41956374049186707, 0.4542149603366852, 0.48193591833114624, 0.5076119303703308, 0.5238581895828247, 0.5463531017303467, 0.5544194579124451, 0.5655533075332642, 0.5757782459259033, 0.5928198099136353, 0.6050897240638733, 0.6038400530815125]\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 6144)             24576     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:8 D2:dropOutTwo0.2[0.2743694484233856, 0.3527607321739197, 0.39740967750549316, 0.42138150334358215, 0.45160192251205444, 0.4745512306690216, 0.48659396171569824, 0.49886390566825867, 0.5135196447372437, 0.5227221250534058, 0.5307884812355042, 0.5435128211975098, 0.5468075275421143, 0.5410134196281433, 0.5457850694656372]\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 6144)             24576     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:8 D2:dropOutTwo0.3[0.2571006715297699, 0.3190183937549591, 0.3512837886810303, 0.3821858763694763, 0.40695297718048096, 0.4352419972419739, 0.43433311581611633, 0.4572824239730835, 0.46080437302589417, 0.4730742871761322, 0.4886389374732971, 0.4917064309120178, 0.4964780807495117, 0.5001136064529419, 0.5124971866607666, 0.5205634832382202, 0.5189729332923889, 0.5240854620933533, 0.5255623459815979, 0.5355600714683533]\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 6144)             24576     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 8)                32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:8 D2:dropOutTwo0.5[0.24233128130435944, 0.29584184288978577, 0.3178822994232178, 0.3329924941062927, 0.3412860631942749, 0.3520790636539459, 0.3634401261806488, 0.3648034632205963, 0.3795728385448456, 0.37241536378860474, 0.3795728385448456, 0.3905930519104004, 0.39570552110671997, 0.3967280089855194, 0.39275163412094116, 0.3984321653842926, 0.40388548374176025, 0.4139968156814575, 0.4114973843097687, 0.4066121280193329, 0.41331514716148376, 0.4160418212413788, 0.4158145785331726, 0.4146784842014313, 0.4144512712955475, 0.42467620968818665, 0.4288797974586487, 0.4287661910057068, 0.4237673282623291, 0.428538978099823]\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:8 D2:dropOutTwo0.9[0.16371279954910278, 0.17496024072170258, 0.19586457312107086, 0.19927288591861725, 0.20722563564777374, 0.2017723172903061, 0.2080209106206894, 0.20381730794906616, 0.20449897646903992, 0.2065439671278, 0.20552147924900055, 0.20540785789489746, 0.20677119493484497, 0.20836172997951508, 0.20722563564777374, 0.20688480138778687, 0.20768007636070251, 0.20768007636070251, 0.2080209106206894, 0.21006590127944946, 0.21063394844532013, 0.2079072892665863, 0.21154282987117767, 0.20745284855365753, 0.21006590127944946, 0.2065439671278, 0.2126789391040802, 0.210974782705307, 0.20972506701946259, 0.206316739320755]\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 9)                36        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:9 D2:dropOutTwo0.1[0.18541240692138672, 0.32004091143608093, 0.4000227153301239, 0.45932742953300476, 0.4981822371482849, 0.532038152217865, 0.5480572581291199, 0.5730515718460083, 0.5953192710876465, 0.6003181338310242, 0.6103158593177795, 0.624062716960907, 0.630652129650116, 0.6339468359947205]\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 9)                36        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:9 D2:dropOutTwo0.2[0.2617586851119995, 0.3619631826877594, 0.4017268717288971, 0.4317200779914856, 0.4527380168437958, 0.4756873548030853, 0.4932969808578491, 0.5109066367149353, 0.5170415639877319, 0.5370370149612427, 0.5438536405563354, 0.5622586011886597, 0.5600999593734741, 0.5711202025413513, 0.5830492973327637, 0.5774824023246765, 0.5835037231445312]\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 9)                36        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:9 D2:dropOutTwo0.3[0.23767325282096863, 0.32288116216659546, 0.35605543851852417, 0.37707340717315674, 0.39275163412094116, 0.41354238986968994, 0.4319472908973694, 0.45137467980384827, 0.4600090980529785, 0.4665985107421875, 0.48318564891815186, 0.4810270369052887, 0.48977506160736084, 0.5011361241340637, 0.5096569061279297, 0.5113610625267029, 0.521586000919342, 0.5260168313980103]\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 9)                36        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:9 D2:dropOutTwo0.5[0.22778913378715515, 0.2933424115180969, 0.3301522433757782, 0.35003408789634705, 0.35321518778800964, 0.3766189515590668, 0.3779822885990143, 0.3812769949436188, 0.3810497522354126, 0.3970688581466675, 0.40093159675598145, 0.4092251658439636, 0.4129743278026581, 0.4128607213497162, 0.42160871624946594, 0.4209270477294922, 0.42331287264823914, 0.4225175976753235, 0.42638036608695984, 0.4318336844444275, 0.4335378408432007, 0.43569642305374146, 0.4378550350666046, 0.4410361349582672, 0.4380822479724884, 0.4458077847957611, 0.45126107335090637, 0.4462622106075287, 0.4575096666812897, 0.452056348323822]\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 9)                36        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:9 D2:dropOutTwo0.9[0.17836855351924896, 0.19325153529644012, 0.21529197692871094, 0.21858668327331543, 0.22347193956375122, 0.22392638027668, 0.2222222238779068, 0.22313110530376434, 0.2300613522529602, 0.2255169302225113, 0.22824357450008392, 0.2350602149963379, 0.23267439007759094, 0.23210634291172028, 0.23221994936466217, 0.2316519021987915, 0.23449216783046722, 0.23244717717170715, 0.23596909642219543, 0.23619632422924042, 0.23778685927391052, 0.2411951869726181, 0.2411951869726181, 0.24039991199970245, 0.24153602123260498, 0.2398318499326706, 0.23994547128677368, 0.24324017763137817, 0.24233128130435944, 0.2381276935338974]\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:10 D2:dropOutTwo0.1[0.3014087677001953, 0.4080890715122223, 0.4522835612297058, 0.493865042924881, 0.5216996073722839, 0.5451033711433411, 0.5705521702766418, 0.588388979434967, 0.6033855676651001, 0.6066802740097046, 0.6295160055160522, 0.6355373859405518, 0.6457623243331909, 0.6593955755233765]\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:10 D2:dropOutTwo0.2[0.3078845739364624, 0.3908202648162842, 0.4236537218093872, 0.4508066475391388, 0.4777323305606842, 0.5064758062362671, 0.5192002058029175, 0.5272665023803711, 0.5478300452232361, 0.5600999593734741, 0.5616905093193054, 0.5769143104553223, 0.5863440036773682, 0.5928198099136353, 0.601567804813385, 0.6021358966827393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:10 D2:dropOutTwo0.3[0.234946608543396, 0.3302658498287201, 0.380595326423645, 0.41161099076271057, 0.42774370312690735, 0.45478299260139465, 0.4588729739189148, 0.4727334678173065, 0.49306976795196533, 0.5048852562904358, 0.504658043384552, 0.5223813056945801, 0.5279482007026672, 0.5341967940330505, 0.5404453277587891, 0.5426039695739746, 0.5478300452232361, 0.5493069887161255]\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:10 D2:dropOutTwo0.5[0.20359009504318237, 0.2844808101654053, 0.3253805935382843, 0.3446943759918213, 0.358554869890213, 0.3649170696735382, 0.3854805827140808, 0.38945692777633667, 0.4011588394641876, 0.4062713086605072, 0.4063849151134491, 0.4108157157897949, 0.42115429043769836, 0.4329697787761688, 0.43421950936317444, 0.43740057945251465, 0.4329697787761688, 0.44387638568878174, 0.4400136470794678, 0.45137467980384827, 0.45932742953300476, 0.45307883620262146, 0.45614632964134216, 0.4523971676826477, 0.46307656168937683, 0.45035219192504883, 0.46273574233055115, 0.45796409249305725, 0.4714837670326233, 0.4651215672492981]\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:10 D2:dropOutTwo0.9[0.1776868849992752, 0.1938195824623108, 0.20211315155029297, 0.2049534171819687, 0.20540785789489746, 0.21222449839115143, 0.2238127738237381, 0.2271074801683426, 0.23097023367881775, 0.23153828084468842, 0.23062939941883087, 0.23267439007759094, 0.2334696650505066, 0.23392410576343536, 0.2335832715034485, 0.23687797784805298, 0.24369461834430695, 0.23744603991508484, 0.23574188351631165, 0.2334696650505066, 0.23858213424682617, 0.23687797784805298, 0.23767325282096863, 0.24108156561851501, 0.24335378408432007, 0.24085435271263123, 0.23892296850681305, 0.2430129498243332, 0.24074074625968933, 0.2411951869726181]\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 11)               44        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 11)                0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:11 D2:dropOutTwo0.1[0.33117473125457764, 0.40865713357925415, 0.44171780347824097, 0.48829811811447144, 0.5305612087249756, 0.5615769028663635, 0.5755510330200195, 0.5990684032440186, 0.6144058108329773, 0.6224721670150757, 0.6430356502532959, 0.6597363948822021, 0.6641672253608704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 11)               44        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 11)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:11 D2:dropOutTwo0.2[0.34185412526130676, 0.408429890871048, 0.43717336654663086, 0.4717109799385071, 0.49625083804130554, 0.5167007446289062, 0.5379459261894226, 0.556350827217102, 0.5640763640403748, 0.5797545909881592, 0.5858895778656006, 0.5895251035690308, 0.602363109588623, 0.6094069480895996]\n",
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 11)               44        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 11)                0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:11 D2:dropOutTwo0.3[0.28493523597717285, 0.3669620454311371, 0.4062713086605072, 0.4305839538574219, 0.45160192251205444, 0.4663712680339813, 0.4955691993236542, 0.5013633370399475, 0.5138604640960693, 0.5206770896911621, 0.530106782913208, 0.536696195602417, 0.5482844710350037, 0.5508975386619568, 0.5515791773796082, 0.5508975386619568]\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 11)               44        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 11)                0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:11 D2:dropOutTwo0.5[0.24017268419265747, 0.3048170804977417, 0.34310382604599, 0.3559418320655823, 0.3729834258556366, 0.3828675448894501, 0.39263802766799927, 0.4011588394641876, 0.4138832092285156, 0.4267211854457855, 0.42751646041870117, 0.4319472908973694, 0.4299022853374481, 0.44035446643829346, 0.44819357991218567, 0.44058167934417725, 0.453987717628479, 0.4535332918167114, 0.45478299260139465, 0.45637354254722595, 0.45978185534477234, 0.4618268609046936]\n",
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 11)               44        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 11)                0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:11 D2:dropOutTwo0.9[0.1430356800556183, 0.1904112696647644, 0.20211315155029297, 0.20586229860782623, 0.212906152009964, 0.21381504833698273, 0.22279027104377747, 0.22585776448249817, 0.22506248950958252, 0.22392638027668, 0.22585776448249817, 0.22744831442832947, 0.22892524302005768, 0.22574414312839508, 0.23062939941883087, 0.2285844087600708, 0.2286980301141739, 0.23062939941883087, 0.23244717717170715, 0.2317655086517334, 0.2335832715034485, 0.22983412444591522, 0.23403771221637726, 0.22767552733421326, 0.22903884947299957, 0.23301522433757782, 0.2316519021987915, 0.2334696650505066, 0.23221994936466217, 0.2333560585975647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 12)               48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 12)                0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:12 D2:dropOutTwo0.1[0.32799363136291504, 0.4176323413848877, 0.45966824889183044, 0.5064758062362671, 0.53476482629776, 0.5620313286781311, 0.5823676586151123, 0.6097477674484253, 0.6150875091552734, 0.6345148682594299, 0.647580087184906, 0.6606453061103821, 0.6640536189079285, 0.6879118084907532]\n",
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 12)               48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 12)                0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:12 D2:dropOutTwo0.2[0.29459214210510254, 0.3837764263153076, 0.42149510979652405, 0.45501023530960083, 0.48204952478408813, 0.509316086769104, 0.5268120765686035, 0.5414678454399109, 0.557259738445282, 0.5686207413673401, 0.5856623649597168, 0.5944103598594666, 0.6006589531898499, 0.6156555414199829]\n",
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 12)               48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 12)                0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:12 D2:dropOutTwo0.3[0.20063622295856476, 0.3495796322822571, 0.3908202648162842, 0.42660757899284363, 0.45148828625679016, 0.46750739216804504, 0.493410587310791, 0.5012497305870056, 0.5221540331840515, 0.5294251441955566, 0.5348784327507019, 0.5451033711433411, 0.5539650321006775, 0.5631674528121948, 0.5754374265670776]\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_27 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 12)               48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 12)                0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:12 D2:dropOutTwo0.5[0.2492615282535553, 0.3186775743961334, 0.3446943759918213, 0.363212913274765, 0.38150420784950256, 0.39604634046554565, 0.406498521566391, 0.41479209065437317, 0.4272892475128174, 0.43433311581611633, 0.4430811107158661, 0.43740057945251465, 0.4494433104991913, 0.45012497901916504, 0.4654623866081238, 0.4619404673576355, 0.463303804397583, 0.46296295523643494, 0.47989094257354736, 0.4763689935207367]\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_28 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 6144)              0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 12)               48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 12)                0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:12 D2:dropOutTwo0.9[0.16325834393501282, 0.17666439712047577, 0.20415814220905304, 0.21699613332748413, 0.22619858384132385, 0.22313110530376434, 0.23040218651294708, 0.23528742790222168, 0.23596909642219543, 0.2334696650505066, 0.2382413148880005, 0.2396046370267868, 0.23892296850681305, 0.24062712490558624, 0.23903658986091614, 0.24164962768554688, 0.24505794048309326, 0.24074074625968933, 0.24551238119602203, 0.24380822479724884, 0.24130879342556, 0.2430129498243332, 0.24369461834430695, 0.24153602123260498, 0.24664849042892456, 0.2474437654018402, 0.24471710622310638, 0.24517154693603516, 0.24392183125019073, 0.24392183125019073]\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_29 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:8 D2:dropOutTwo0.1[0.23608270287513733, 0.3730970323085785, 0.42774370312690735, 0.45171552896499634, 0.47557371854782104, 0.489206999540329, 0.5032947063446045, 0.5287434458732605, 0.5227221250534058, 0.5436264276504517, 0.5448761582374573, 0.5578277707099915, 0.5599863529205322, 0.5618041157722473, 0.5683935284614563]\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_30 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:8 D2:dropOutTwo0.2[0.27380141615867615, 0.3540104627609253, 0.3870711326599121, 0.4076346158981323, 0.4344467222690582, 0.44501250982284546, 0.45796409249305725, 0.471824586391449, 0.4828447997570038, 0.48523062467575073, 0.4970461130142212, 0.49909111857414246, 0.513178825378418, 0.505680501461029, 0.5172687768936157, 0.519768238067627, 0.5245398879051208, 0.5221540331840515, 0.5247671008110046, 0.5288570523262024, 0.5370370149612427, 0.5352192521095276, 0.5420358777046204]\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_31 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:8 D2:dropOutTwo0.3[0.2269938588142395, 0.3286752998828888, 0.3699159324169159, 0.38468530774116516, 0.40365827083587646, 0.41536015272140503, 0.43705976009368896, 0.43899112939834595, 0.4425130784511566, 0.45126107335090637, 0.45796409249305725, 0.4587593674659729, 0.4655759930610657, 0.4712565243244171, 0.47375595569610596, 0.46898433566093445, 0.48352646827697754, 0.48159509897232056, 0.489206999540329, 0.48829811811447144, 0.4965916872024536, 0.49454668164253235]\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_32 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:8 D2:dropOutTwo0.5[0.1922290325164795, 0.24892069399356842, 0.2999318242073059, 0.3269711434841156, 0.3368552625179291, 0.3368552625179291, 0.34026357531547546, 0.35344240069389343, 0.36071348190307617, 0.3695750832557678, 0.359009325504303, 0.3667348325252533, 0.3729834258556366, 0.3665076196193695, 0.37525561451911926, 0.37877756357192993, 0.3908202648162842, 0.3854805827140808, 0.38150420784950256, 0.384458065032959, 0.3901385962963104, 0.3903658390045166, 0.3955919146537781, 0.3885480463504791, 0.38809362053871155, 0.3909338712692261, 0.3985457718372345, 0.39309248328208923, 0.3963871896266937, 0.39002498984336853]\n",
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_33 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_60 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_61 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_30 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:8 D2:dropOutTwo0.9[0.1633719652891159, 0.16871166229248047, 0.18688935041427612, 0.19291070103645325, 0.19245626032352448, 0.19336514174938202, 0.19790956377983093, 0.20120427012443542, 0.20563508570194244, 0.20586229860782623, 0.206316739320755, 0.20733924210071564, 0.2080209106206894, 0.2112019956111908, 0.2125653326511383, 0.2092706263065338, 0.21074755489826202, 0.21676892042160034, 0.21710975468158722, 0.2157464176416397, 0.21801863610744476, 0.2172233611345291, 0.21404226124286652, 0.21926835179328918, 0.2207452803850174, 0.2207452803850174, 0.21824584901332855, 0.22006362676620483, 0.2189275175333023, 0.22154055535793304]\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_34 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_63 (Bat  (None, 9)                36        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_31 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:9 D2:dropOutTwo0.1[0.17814132571220398, 0.2951602041721344, 0.40593045949935913, 0.45444217324256897, 0.47386956214904785, 0.49420586228370667, 0.5265848636627197, 0.5324926376342773, 0.5376051068305969, 0.5515791773796082, 0.558282196521759, 0.5662349462509155, 0.5804362893104553, 0.5872529149055481, 0.5867984294891357]\n",
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_35 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 9)                36        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:9 D2:dropOutTwo0.2[0.24471710622310638, 0.35026130080223083, 0.3917291462421417, 0.4271756410598755, 0.4399000108242035, 0.4585321545600891, 0.4780731797218323, 0.4935241937637329, 0.49784138798713684, 0.5072710514068604, 0.5170415639877319, 0.5296523571014404, 0.5352192521095276, 0.5433992147445679, 0.5465803146362305, 0.5435128211975098, 0.5537377595901489, 0.5547602772712708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_36 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_66 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_67 (Bat  (None, 9)                36        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:9 D2:dropOutTwo0.3[0.26119065284729004, 0.3463985323905945, 0.3858214020729065, 0.4012724459171295, 0.41172459721565247, 0.4299022853374481, 0.441263347864151, 0.4491024911403656, 0.45955464243888855, 0.46091797947883606, 0.4790956676006317, 0.4750056862831116, 0.4790956676006317, 0.484548956155777, 0.4955691993236542, 0.4947739243507385, 0.49466031789779663, 0.49920472502708435, 0.5061349868774414, 0.5024994611740112, 0.5137468576431274, 0.5026130676269531, 0.5081799626350403, 0.5052260756492615, 0.5118154883384705, 0.5097705125808716, 0.5245398879051208, 0.5186321139335632, 0.5140877366065979]\n",
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_37 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_68 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_69 (Bat  (None, 9)                36        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:9 D2:dropOutTwo0.5[0.19120654463768005, 0.26107701659202576, 0.29425129294395447, 0.31208816170692444, 0.3224267065525055, 0.3360599875450134, 0.35787320137023926, 0.3649170696735382, 0.37048399448394775, 0.37718701362609863, 0.3727561831474304, 0.3858214020729065, 0.3808225393295288, 0.39468303322792053, 0.3918427526950836, 0.3860486149787903, 0.3987730145454407, 0.4013860523700714, 0.39888662099838257, 0.39888662099838257, 0.4029766023159027, 0.41217905282974243, 0.40570324659347534, 0.40718019008636475, 0.4060440957546234, 0.40911155939102173, 0.40911155939102173, 0.4188820719718933, 0.41660985350608826, 0.4253578782081604]\n",
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_38 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_70 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_71 (Bat  (None, 9)                36        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:9 D2:dropOutTwo0.9[0.16791638731956482, 0.19143377244472504, 0.19495569169521332, 0.20097705721855164, 0.21052034199237823, 0.21688252687454224, 0.217336967587471, 0.22108611464500427, 0.21858668327331543, 0.21995000541210175, 0.22335833311080933, 0.22494886815547943, 0.22199499607086182, 0.22449442744255066, 0.22597137093544006, 0.2240399867296219, 0.22290389239788055, 0.22653941810131073, 0.2254033237695694, 0.22517609596252441, 0.2252897024154663, 0.23233355581760406, 0.2252897024154663, 0.2269938588142395, 0.22903884947299957, 0.22460804879665375, 0.22881163656711578, 0.22972051799297333, 0.22960691154003143, 0.23221994936466217]\n",
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_39 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_72 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_73 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_36 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:10 D2:dropOutTwo0.1[0.3019768297672272, 0.3924108147621155, 0.4480799734592438, 0.4812542498111725, 0.5013633370399475, 0.5263576507568359, 0.5501022338867188, 0.5606680512428284, 0.5706657767295837, 0.5888434648513794, 0.5985003113746643, 0.6054306030273438, 0.6066802740097046, 0.6092933416366577]\n",
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_40 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_74 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_75 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_37 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:10 D2:dropOutTwo0.2[0.18768461048603058, 0.33424222469329834, 0.393774151802063, 0.42797091603279114, 0.45307883620262146, 0.4715973734855652, 0.4855714738368988, 0.493410587310791, 0.5090888142585754, 0.510338544845581, 0.5261304378509521, 0.5311293005943298, 0.5379459261894226, 0.547034740447998, 0.5481708645820618]\n",
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_41 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_76 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_77 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_38 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:10 D2:dropOutTwo0.3[0.23608270287513733, 0.33287888765335083, 0.38036808371543884, 0.4033174216747284, 0.4241081476211548, 0.4429675042629242, 0.4511474668979645, 0.46773460507392883, 0.469438761472702, 0.47670984268188477, 0.48023176193237305, 0.4871619939804077, 0.4970461130142212, 0.5026130676269531, 0.5053396821022034, 0.5076119303703308, 0.5013633370399475, 0.5047716498374939, 0.5177232623100281, 0.5155646204948425]\n",
      "Model: \"model_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_42 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_78 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_79 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_39 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:10 D2:dropOutTwo0.5[0.2461940497159958, 0.29754599928855896, 0.3348102569580078, 0.34480801224708557, 0.3583276569843292, 0.365144282579422, 0.37571007013320923, 0.37866392731666565, 0.3902522027492523, 0.38991138339042664, 0.3984321653842926, 0.4001363217830658, 0.4027493894100189, 0.400363564491272, 0.41024768352508545, 0.42592594027519226, 0.4076346158981323, 0.41342875361442566, 0.4146784842014313, 0.41638264060020447, 0.4253578782081604, 0.42172232270240784, 0.4146784842014313, 0.42001816630363464, 0.42638036608695984, 0.43092480301856995, 0.4319472908973694, 0.43069756031036377, 0.43694615364074707, 0.4302431344985962]\n",
      "Model: \"model_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_43 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_80 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_81 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_40 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 10)                0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:10 D2:dropOutTwo0.9[0.17018859088420868, 0.19870483875274658, 0.20052260160446167, 0.21142922341823578, 0.2112019956111908, 0.21551920473575592, 0.21370142698287964, 0.21972279250621796, 0.21631447970867157, 0.217336967587471, 0.2190411239862442, 0.22097250819206238, 0.2255169302225113, 0.22199499607086182, 0.22597137093544006, 0.22494886815547943, 0.22631220519542694, 0.2268802523612976, 0.22972051799297333, 0.22881163656711578, 0.22563053667545319, 0.22949329018592834, 0.2284708023071289, 0.23392410576343536, 0.22744831442832947, 0.2335832715034485, 0.23062939941883087, 0.2300613522529602, 0.22642581164836884, 0.2333560585975647]\n",
      "Model: \"model_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_44 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_82 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_83 (Bat  (None, 11)               44        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_41 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 11)                0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:11 D2:dropOutTwo0.1[0.27709612250328064, 0.3917291462421417, 0.43740057945251465, 0.47716426849365234, 0.5028402805328369, 0.5142013430595398, 0.5396500825881958, 0.5488525629043579, 0.5688480138778687, 0.5700976848602295, 0.5886162519454956, 0.5953192710876465, 0.60429447889328]\n",
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_45 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_84 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_85 (Bat  (None, 11)               44        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_42 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, 11)                0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:11 D2:dropOutTwo0.2[0.2574414908885956, 0.34503522515296936, 0.3934333026409149, 0.43081116676330566, 0.45773687958717346, 0.4795500934123993, 0.4931833744049072, 0.5095432996749878, 0.5227221250534058, 0.5264712572097778, 0.5335150957107544, 0.5451033711433411, 0.5519199967384338, 0.559191107749939, 0.5553283095359802]\n",
      "Model: \"model_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_46 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_86 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_86 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_87 (Bat  (None, 11)               44        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_43 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, 11)                0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:11 D2:dropOutTwo0.3[0.26437172293663025, 0.3541240692138672, 0.39411497116088867, 0.4224039912223816, 0.43751421570777893, 0.4553510546684265, 0.46728014945983887, 0.4828447997570038, 0.4954555928707123, 0.48466256260871887, 0.5054532885551453, 0.5051124691963196, 0.5064758062362671, 0.518859326839447, 0.5251079201698303, 0.5184049010276794, 0.5202226638793945, 0.5269256830215454, 0.543285608291626, 0.5355600714683533]\n",
      "Model: \"model_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_47 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_88 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_89 (Bat  (None, 11)               44        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_44 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 11)                0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1:0.2 D2P:11 D2:dropOutTwo0.5[0.24369461834430695, 0.30106794834136963, 0.334583044052124, 0.34526243805885315, 0.3616223633289337, 0.37559646368026733, 0.37695977091789246, 0.39763689041137695, 0.3935469090938568, 0.40570324659347534, 0.40718019008636475, 0.4127471148967743, 0.4208134412765503, 0.42444899678230286, 0.4222903847694397, 0.42922061681747437, 0.4297886788845062, 0.43399226665496826, 0.4330833852291107, 0.43569642305374146, 0.4427402913570404, 0.4376278221607208, 0.4299022853374481, 0.44024085998535156, 0.4384230971336365, 0.44512611627578735, 0.4568279981613159, 0.4472846984863281, 0.45489662885665894, 0.4476255476474762]\n",
      "Model: \"model_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_48 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_90 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_91 (Bat  (None, 11)               44        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_45 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 11)                0         \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:11 D2:dropOutTwo0.9[0.16950693726539612, 0.1890479475259781, 0.19495569169521332, 0.20665757358074188, 0.20677119493484497, 0.20904339849948883, 0.21233810484409332, 0.21551920473575592, 0.22085890173912048, 0.2174505740404129, 0.22392638027668, 0.22494886815547943, 0.2254033237695694, 0.22744831442832947, 0.2267666459083557, 0.23449216783046722, 0.22824357450008392, 0.2286980301141739, 0.23119746148586273, 0.23051579296588898, 0.22824357450008392, 0.23085662722587585, 0.2318791151046753, 0.23415133357048035, 0.2350602149963379, 0.23381049931049347, 0.23403771221637726, 0.2350602149963379, 0.23233355581760406, 0.234719380736351]\n",
      "Model: \"model_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_49 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_92 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_93 (Bat  (None, 12)               48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_46 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, 12)                0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:12 D2:dropOutTwo0.1[0.2732333540916443, 0.4097932279109955, 0.45625993609428406, 0.4885253310203552, 0.513178825378418, 0.5402181148529053, 0.5514655709266663, 0.5678254961967468, 0.5844126343727112, 0.5900931358337402, 0.6027039289474487, 0.6134969592094421, 0.6165643930435181, 0.6234946846961975]\n",
      "Model: \"model_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_50 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_94 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_95 (Bat  (None, 12)               48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_47 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_95 (Dropout)        (None, 12)                0         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:12 D2:dropOutTwo0.2[0.2857305109500885, 0.3730970323085785, 0.41047489643096924, 0.4442172348499298, 0.46432629227638245, 0.4886389374732971, 0.506589412689209, 0.5132924318313599, 0.5321517586708069, 0.540558934211731, 0.5537377595901489, 0.5573733448982239, 0.5613496899604797, 0.5763462781906128]\n",
      "Model: \"model_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_51 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_96 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_97 (Bat  (None, 12)               48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_48 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 12)                0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:12 D2:dropOutTwo0.3[0.27857306599617004, 0.36105430126190186, 0.40218132734298706, 0.4191092848777771, 0.43728697299957275, 0.4575096666812897, 0.4696659743785858, 0.4759145677089691, 0.4871619939804077, 0.498068630695343, 0.506589412689209, 0.5198818445205688, 0.5068166255950928, 0.5229493379592896, 0.523517370223999, 0.5355600714683533, 0.5259032249450684, 0.5437400341033936, 0.5365825891494751, 0.541354238986969]\n",
      "Model: \"model_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_52 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_98 (Dropout)        (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_98 (Bat  (None, 6144)             24576     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_99 (Bat  (None, 12)               48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_49 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_99 (Dropout)        (None, 12)                0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:12 D2:dropOutTwo0.5[0.25005680322647095, 0.31481480598449707, 0.3367416560649872, 0.36400818824768066, 0.3808225393295288, 0.3901385962963104, 0.39615997672080994, 0.4049079716205597, 0.41638264060020447, 0.40899795293807983, 0.4314928352832794, 0.4367189407348633, 0.4287661910057068, 0.43899112939834595, 0.43887752294540405, 0.4445580542087555, 0.44194501638412476, 0.43694615364074707, 0.44558054208755493, 0.43581002950668335, 0.45489662885665894, 0.4506930112838745, 0.45478299260139465, 0.45625993609428406, 0.44342195987701416, 0.4543285667896271, 0.46739378571510315, 0.4569416046142578, 0.46603044867515564, 0.46603044867515564]\n",
      "Model: \"model_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_53 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_100 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_101 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_50 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:12 D2:dropOutTwo0.9[0.1807543784379959, 0.19972734153270721, 0.20881617069244385, 0.22267666459083557, 0.22517609596252441, 0.22665303945541382, 0.22903884947299957, 0.22744831442832947, 0.23574188351631165, 0.23062939941883087, 0.2364235371351242, 0.2365371435880661, 0.23869575560092926, 0.23676437139511108, 0.23710520565509796, 0.23869575560092926, 0.24153602123260498, 0.24835264682769775, 0.24721653759479523, 0.24199046194553375, 0.24403545260429382, 0.2428993433713913, 0.2506248652935028, 0.24721653759479523, 0.24698932468891144, 0.25028401613235474, 0.24869348108768463, 0.2506248652935028, 0.25153374671936035, 0.24880708754062653]\n",
      "Model: \"model_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_54 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_102 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_103 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_51 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:8 D2:dropOutTwo0.1[0.2573278844356537, 0.36264485120773315, 0.39900022745132446, 0.42331287264823914, 0.4384230971336365, 0.46409907937049866, 0.4731879234313965, 0.4733015298843384, 0.48625311255455017, 0.4986366629600525, 0.5098841190338135, 0.5132924318313599, 0.5177232623100281, 0.5297659635543823, 0.5310156941413879, 0.5423767566680908, 0.5418086647987366, 0.5387411713600159]\n",
      "Model: \"model_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_55 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_104 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_104 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_105 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_52 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_105 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:8 D2:dropOutTwo0.2[0.2459668219089508, 0.3203817307949066, 0.3599182069301605, 0.37877756357192993, 0.3965007960796356, 0.42115429043769836, 0.42956146597862244, 0.4495569169521332, 0.45773687958717346, 0.4664849042892456, 0.4655759930610657, 0.4730742871761322, 0.4885253310203552, 0.49443307518959045, 0.49784138798713684, 0.4885253310203552, 0.49761417508125305, 0.4931833744049072, 0.5114746689796448, 0.5097705125808716, 0.5115882754325867]\n",
      "Model: \"model_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_56 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_106 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_107 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_53 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:8 D2:dropOutTwo0.3[0.21767780184745789, 0.3140195310115814, 0.3584412634372711, 0.3828675448894501, 0.39570552110671997, 0.40581685304641724, 0.41161099076271057, 0.42319926619529724, 0.4289934039115906, 0.44046807289123535, 0.428538978099823, 0.44694387912750244, 0.4456941485404968, 0.45807769894599915, 0.4505794048309326, 0.4621676802635193, 0.4585321545600891, 0.46148601174354553, 0.4639854431152344, 0.46739378571510315, 0.46614405512809753, 0.46728014945983887, 0.47080209851264954, 0.4773915112018585, 0.47193819284439087]\n",
      "Model: \"model_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_57 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_108 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_109 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_54 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:8 D2:dropOutTwo0.5[0.21824584901332855, 0.2781186103820801, 0.3018632233142853, 0.3001590669155121, 0.3045898675918579, 0.32810723781585693, 0.33128833770751953, 0.3251533806324005, 0.3412860631942749, 0.3462849259376526, 0.3511701822280884, 0.3568507134914398, 0.365144282579422, 0.3687798082828522, 0.367075651884079, 0.37241536378860474, 0.36753010749816895, 0.3776414394378662, 0.3810497522354126, 0.37786865234375, 0.37991365790367126, 0.38366279006004333, 0.38673028349876404, 0.37673255801200867, 0.3794592022895813, 0.3874119520187378, 0.3919563591480255, 0.38798001408576965, 0.3905930519104004, 0.3758236765861511]\n",
      "Model: \"model_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_58 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_110 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_111 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_55 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:8 D2:dropOutTwo0.9[0.13462848961353302, 0.18223130702972412, 0.19018404185771942, 0.18813906610012054, 0.18972960114479065, 0.19484208524227142, 0.19722791016101837, 0.19790956377983093, 0.19631901383399963, 0.19915927946567535, 0.20211315155029297, 0.2014314979314804, 0.20029538869857788, 0.19927288591861725, 0.20199954509735107, 0.20290842652320862, 0.20222677290439606, 0.20427176356315613, 0.20245398581027985, 0.20393092930316925, 0.2048398107290268, 0.20574869215488434, 0.20733924210071564, 0.2049534171819687, 0.20381730794906616, 0.2032492607831955, 0.20563508570194244, 0.20518064498901367, 0.2046125829219818, 0.20574869215488434]\n",
      "Model: \"model_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_59 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_112 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_112 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_113 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_56 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:9 D2:dropOutTwo0.1[0.29163825511932373, 0.3729834258556366, 0.40899795293807983, 0.4335378408432007, 0.45955464243888855, 0.48148149251937866, 0.4937514066696167, 0.49920472502708435, 0.5194274187088013, 0.5266984701156616, 0.5329470634460449, 0.5464667081832886, 0.5449897646903992, 0.5643035769462585, 0.5530561208724976, 0.5654397010803223, 0.5696432590484619, 0.5770279765129089]\n",
      "Model: \"model_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_60 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_114 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_115 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_57 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:9 D2:dropOutTwo0.2[0.2428993433713913, 0.339241087436676, 0.37673255801200867, 0.3968416154384613, 0.41672345995903015, 0.43262895941734314, 0.4476255476474762, 0.4584185481071472, 0.47250625491142273, 0.4780731797218323, 0.4838673174381256, 0.4875028431415558, 0.4922744929790497, 0.5007952451705933, 0.5044308304786682, 0.513178825378418, 0.5095432996749878, 0.510338544845581, 0.5148829817771912, 0.5239717960357666, 0.5164735317230225, 0.524426281452179]\n",
      "Model: \"model_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_61 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_116 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_116 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_117 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_58 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:9 D2:dropOutTwo0.3[0.1920018196105957, 0.29004770517349243, 0.3591229319572449, 0.39161553978919983, 0.39786413311958313, 0.42263123393058777, 0.4268348217010498, 0.44364917278289795, 0.4400136470794678, 0.4492160975933075, 0.44842082262039185, 0.4509202539920807, 0.45296522974967957, 0.4622812867164612, 0.46614405512809753, 0.4668257236480713, 0.463303804397583, 0.4680754244327545, 0.4813678562641144, 0.46773460507392883, 0.4794364869594574]\n",
      "Model: \"model_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_62 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_118 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_119 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_59 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:9 D2:dropOutTwo0.5[0.16394001245498657, 0.2585775852203369, 0.3047034740447998, 0.3241308927536011, 0.3440127372741699, 0.3479890823364258, 0.3558282256126404, 0.35798680782318115, 0.36764371395111084, 0.3729834258556366, 0.37673255801200867, 0.37684616446495056, 0.37991365790367126, 0.3746875822544098, 0.3775278329849243, 0.38627585768699646, 0.38627585768699646, 0.3810497522354126, 0.3903658390045166, 0.387184739112854, 0.389116108417511, 0.3951374590396881, 0.3953647017478943, 0.38798001408576965, 0.3966144025325775, 0.3995682895183563, 0.39775049686431885, 0.39263802766799927, 0.39411497116088867, 0.40422630310058594]\n",
      "Model: \"model_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_63 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_120 (Dropout)       (None, 6144)              0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " batch_normalization_120 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_121 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_60 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:9 D2:dropOutTwo0.9[0.17007498443126678, 0.18279936909675598, 0.1902976632118225, 0.19597817957401276, 0.19927288591861725, 0.2031356543302536, 0.20359009504318237, 0.20529425144195557, 0.20870256423950195, 0.20881617069244385, 0.21029311418533325, 0.20836172997951508, 0.2093842327594757, 0.20677119493484497, 0.21529197692871094, 0.2112019956111908, 0.212906152009964, 0.21006590127944946, 0.21313337981700897, 0.212906152009964, 0.21222449839115143, 0.21381504833698273, 0.2172233611345291, 0.21676892042160034, 0.2127925455570221, 0.21370142698287964, 0.21506476402282715, 0.2172233611345291, 0.21370142698287964, 0.21461030840873718]\n",
      "Model: \"model_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_64 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_122 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_122 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_123 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_61 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_123 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:10 D2:dropOutTwo0.1[0.2933424115180969, 0.3870711326599121, 0.4272892475128174, 0.44842082262039185, 0.4744376242160797, 0.4968189001083374, 0.5097705125808716, 0.522494912147522, 0.5322653651237488, 0.5408998131752014, 0.5520336031913757, 0.5502158403396606, 0.5554419159889221, 0.5666893720626831, 0.5696432590484619, 0.5806635022163391, 0.5716882348060608]\n",
      "Model: \"model_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_65 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_124 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_124 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_125 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_62 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_125 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:10 D2:dropOutTwo0.2[0.2364235371351242, 0.3399227559566498, 0.38309475779533386, 0.41331514716148376, 0.43069756031036377, 0.44853442907333374, 0.4572824239730835, 0.47205179929733276, 0.476028174161911, 0.4903430938720703, 0.48625311255455017, 0.5109066367149353, 0.5034083127975464, 0.5124971866607666, 0.5213587880134583, 0.5232901573181152, 0.5240854620933533, 0.5365825891494751, 0.5348784327507019, 0.538627564907074, 0.5324926376342773, 0.5396500825881958, 0.5444217324256897]\n",
      "Model: \"model_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_66 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_126 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_126 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_127 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_63 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_127 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:10 D2:dropOutTwo0.3[0.21336059272289276, 0.27062031626701355, 0.3236764371395111, 0.37786865234375, 0.4012724459171295, 0.41263347864151, 0.42263123393058777, 0.4313792288303375, 0.4527380168437958, 0.4575096666812897, 0.46250852942466736, 0.4715973734855652, 0.47693705558776855, 0.4714837670326233, 0.477959543466568, 0.4743240177631378, 0.47239264845848083, 0.48818451166152954, 0.4915928244590759]\n",
      "Model: \"model_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_67 (InputLayer)       [(None, 6144)]            0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dropout_128 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_128 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_129 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_64 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_129 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:10 D2:dropOutTwo0.5[0.2221086174249649, 0.2886843979358673, 0.3033401370048523, 0.3235628306865692, 0.3362872004508972, 0.345830500125885, 0.36094069480895996, 0.3683253824710846, 0.3711656332015991, 0.37786865234375, 0.3748011887073517, 0.38457170128822327, 0.38343557715415955, 0.38525334000587463, 0.397977739572525, 0.39945468306541443, 0.397977739572525, 0.39297887682914734, 0.40706658363342285, 0.3987730145454407, 0.40581685304641724, 0.41365599632263184, 0.4030902087688446, 0.4079754650592804, 0.4113837778568268, 0.4051351845264435, 0.4078618586063385, 0.417291522026062, 0.41536015272140503, 0.41376960277557373]\n",
      "Model: \"model_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_68 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_130 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_130 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_131 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_65 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_131 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:10 D2:dropOutTwo0.9[0.15757782757282257, 0.18189047276973724, 0.19336514174938202, 0.20359009504318237, 0.20404453575611115, 0.20881617069244385, 0.20824812352657318, 0.210974782705307, 0.21177005767822266, 0.21154282987117767, 0.21154282987117767, 0.2125653326511383, 0.21233810484409332, 0.21461030840873718, 0.21404226124286652, 0.2157464176416397, 0.21336059272289276, 0.21086116135120392, 0.21392865478992462, 0.21529197692871094, 0.21517837047576904, 0.21199727058410645, 0.20904339849948883, 0.21222449839115143, 0.21938195824623108, 0.21926835179328918, 0.2188139110803604, 0.21870028972625732, 0.21676892042160034, 0.21551920473575592]\n",
      "Model: \"model_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_69 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_132 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_133 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_66 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:11 D2:dropOutTwo0.1[0.2853896915912628, 0.37366506457328796, 0.4205862283706665, 0.45319244265556335, 0.476028174161911, 0.5012497305870056, 0.518859326839447, 0.5352192521095276, 0.5382867455482483, 0.5427175760269165, 0.557259738445282, 0.5595319271087646, 0.5666893720626831, 0.5746421217918396]\n",
      "Model: \"model_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_70 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_134 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_134 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_135 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_67 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_135 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:11 D2:dropOutTwo0.2[0.17995910346508026, 0.34526243805885315, 0.4096796214580536, 0.43262895941734314, 0.45648714900016785, 0.46921154856681824, 0.48364007472991943, 0.4917064309120178, 0.49772778153419495, 0.5051124691963196, 0.522494912147522, 0.5248807072639465, 0.5194274187088013, 0.5226085186004639, 0.5372642874717712, 0.5318109393119812]\n",
      "Model: \"model_70\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_71 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_136 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_136 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_137 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_68 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_137 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:11 D2:dropOutTwo0.3[0.2661895155906677, 0.3587820827960968, 0.39593273401260376, 0.41161099076271057, 0.43081116676330566, 0.43126562237739563, 0.44785276055336, 0.44523972272872925, 0.47239264845848083, 0.46478071808815, 0.47886842489242554, 0.4742104113101959, 0.4907975494861603, 0.4870483875274658, 0.4907975494861603, 0.49454668164253235, 0.5044308304786682, 0.4997727870941162, 0.5011361241340637, 0.5051124691963196, 0.511247456073761, 0.5121563076972961, 0.5132924318313599, 0.5128380060195923, 0.5097705125808716, 0.5115882754325867, 0.5137468576431274]\n",
      "Model: \"model_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_72 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_138 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_138 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_139 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_69 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_139 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:11 D2:dropOutTwo0.5[0.24028630554676056, 0.3019768297672272, 0.32310837507247925, 0.3535560071468353, 0.36412179470062256, 0.37786865234375, 0.38991138339042664, 0.3953647017478943, 0.40047717094421387, 0.3982049524784088, 0.4001363217830658, 0.3997955024242401, 0.40422630310058594, 0.4077482521533966, 0.4033174216747284, 0.4114973843097687, 0.4138832092285156, 0.41967734694480896, 0.4203590154647827, 0.42433539032936096, 0.428538978099823, 0.4251306653022766, 0.4236537218093872, 0.42933425307273865]\n",
      "Model: \"model_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_73 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_140 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_140 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_141 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_70 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_141 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:11 D2:dropOutTwo0.9[0.16405361890792847, 0.1764371693134308, 0.18598045408725739, 0.19109293818473816, 0.1887071132659912, 0.193592369556427, 0.19154737889766693, 0.2016587108373642, 0.20824812352657318, 0.21006590127944946, 0.20881617069244385, 0.21040672063827515, 0.20995227992534637, 0.20881617069244385, 0.21154282987117767, 0.21029311418533325, 0.21052034199237823, 0.21063394844532013, 0.2144967019557953, 0.21472392976284027, 0.21654169261455536, 0.21551920473575592, 0.21483753621578217, 0.21199727058410645, 0.21495114266872406, 0.21165643632411957, 0.2141558676958084, 0.21472392976284027, 0.21631447970867157, 0.21006590127944946]\n",
      "Model: \"model_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_74 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_142 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_142 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_143 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_71 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_143 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:12 D2:dropOutTwo0.1[0.30708929896354675, 0.39434218406677246, 0.43126562237739563, 0.4695523679256439, 0.4951147437095642, 0.5187457203865051, 0.5306748747825623, 0.5435128211975098, 0.5590775012969971, 0.5678254961967468, 0.5732787847518921, 0.5738468766212463, 0.5823676586151123, 0.5891842842102051, 0.6024767160415649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_75 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_144 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_144 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_145 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_72 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_145 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:12 D2:dropOutTwo0.2[0.19893206655979156, 0.3364008069038391, 0.40206772089004517, 0.4335378408432007, 0.463303804397583, 0.471824586391449, 0.487275630235672, 0.501931369304657, 0.5040899515151978, 0.5180640816688538, 0.5237445831298828, 0.5306748747825623, 0.5439673066139221, 0.5544194579124451, 0.5522608757019043, 0.5535105466842651, 0.5544194579124451, 0.5612360835075378, 0.5599863529205322]\n",
      "Model: \"model_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_76 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_146 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_146 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_147 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_73 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_147 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:12 D2:dropOutTwo0.3[0.269711434841156, 0.3553737699985504, 0.3840036392211914, 0.40865713357925415, 0.43387866020202637, 0.4394455850124359, 0.45955464243888855, 0.4551238417625427, 0.4696659743785858, 0.4727334678173065, 0.48329925537109375, 0.4893206059932709, 0.4860258996486664, 0.49250170588493347, 0.5021585822105408, 0.5040899515151978, 0.5113610625267029, 0.4984094500541687]\n",
      "Model: \"model_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_77 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_148 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_148 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_149 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_74 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_149 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:12 D2:dropOutTwo0.5[0.23210634291172028, 0.28652578592300415, 0.32788002490997314, 0.3494660258293152, 0.3635537326335907, 0.37196090817451477, 0.38173142075538635, 0.38354918360710144, 0.39138832688331604, 0.39138832688331604, 0.4185412526130676, 0.4013860523700714, 0.4127471148967743, 0.4109293222427368, 0.40581685304641724, 0.41036128997802734, 0.4189956784248352, 0.419222891330719, 0.4297886788845062, 0.4274028539657593, 0.43240171670913696, 0.42808452248573303, 0.43728697299957275, 0.42922061681747437, 0.4286525845527649, 0.44239944219589233, 0.43705976009368896, 0.42763009667396545, 0.43546921014785767, 0.4350147545337677]\n",
      "Model: \"model_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_78 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_150 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_151 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_75 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:12 D2:dropOutTwo0.9[0.18325380980968475, 0.20688480138778687, 0.21245171129703522, 0.2191547304391861, 0.2188139110803604, 0.21824584901332855, 0.2223358303308487, 0.22154055535793304, 0.22574414312839508, 0.2268802523612976, 0.22756192088127136, 0.22824357450008392, 0.2268802523612976, 0.2284708023071289, 0.2299477458000183, 0.22801636159420013, 0.22790275514125824, 0.2318791151046753, 0.23267439007759094, 0.2319927215576172, 0.23426494002342224, 0.23256078362464905, 0.23733241856098175, 0.23278799653053284, 0.23687797784805298, 0.23426494002342224, 0.22937968373298645, 0.23699159920215607, 0.23392410576343536, 0.2379004806280136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_79 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_152 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_152 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_153 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_76 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_153 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:8 D2:dropOutTwo0.1[0.217336967587471, 0.3298113942146301, 0.36105430126190186, 0.38650307059288025, 0.4100204408168793, 0.42922061681747437, 0.44660302996635437, 0.45660078525543213, 0.46148601174354553, 0.4745512306690216, 0.4667121171951294, 0.4635310173034668, 0.4794364869594574, 0.49125197529792786, 0.4793228805065155, 0.4915928244590759, 0.49579641222953796, 0.49466031789779663, 0.49772778153419495, 0.5009089112281799, 0.49613723158836365, 0.49625083804130554]\n",
      "Model: \"model_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_80 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_154 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_154 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_155 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_77 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_155 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:8 D2:dropOutTwo0.2[0.25925925374031067, 0.3144739866256714, 0.33696886897087097, 0.36616677045822144, 0.38468530774116516, 0.40059077739715576, 0.4067257344722748, 0.4155873656272888, 0.41638264060020447, 0.42785730957984924, 0.43399226665496826, 0.4345603287220001, 0.44387638568878174, 0.44512611627578735, 0.44717109203338623, 0.44239944219589233, 0.4551238417625427, 0.4570552110671997, 0.4536468982696533, 0.45932742953300476, 0.46432629227638245, 0.46137240529060364, 0.46137240529060364, 0.45921382308006287, 0.46614405512809753, 0.46296295523643494, 0.4665985107421875, 0.4727334678173065, 0.46273574233055115, 0.4702340364456177]\n",
      "Model: \"model_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_81 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_156 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_156 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_157 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_78 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_157 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:8 D2:dropOutTwo0.3[0.2300613522529602, 0.2924335300922394, 0.3142467737197876, 0.34060439467430115, 0.3527607321739197, 0.37059760093688965, 0.39161553978919983, 0.3965007960796356, 0.3996818959712982, 0.4093387722969055, 0.4050215780735016, 0.4141104221343994, 0.4083162844181061, 0.4201318025588989, 0.41047489643096924, 0.41501930356025696, 0.4209270477294922, 0.4237673282623291, 0.42638036608695984, 0.4321745038032532, 0.42649397253990173, 0.4272892475128174, 0.43001589179039, 0.436605304479599, 0.4321745038032532, 0.43069756031036377, 0.43126562237739563, 0.43092480301856995, 0.43387866020202637, 0.4256986975669861]\n",
      "Model: \"model_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_82 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_158 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_158 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_159 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_79 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_159 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1:0.5 D2P:8 D2:dropOutTwo0.5[0.20347648859024048, 0.26266756653785706, 0.2995910048484802, 0.31492841243743896, 0.32628947496414185, 0.33401498198509216, 0.3268575370311737, 0.3426494002342224, 0.34696659445762634, 0.345830500125885, 0.34651216864585876, 0.3476482629776001, 0.3478754758834839, 0.35321518778800964, 0.359009325504303, 0.3542376756668091, 0.36264485120773315, 0.3520790636539459, 0.35798680782318115, 0.35446488857269287, 0.358554869890213, 0.3620767891407013, 0.36889344453811646, 0.359009325504303, 0.3633265197277069, 0.3687798082828522, 0.3695750832557678, 0.369802325963974, 0.3663940131664276, 0.36787092685699463]\n",
      "Model: \"model_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_83 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_160 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_160 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_161 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_80 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      " dropout_161 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:8 D2:dropOutTwo0.9[0.17223358154296875, 0.19450125098228455, 0.20256759226322174, 0.19643263518810272, 0.20563508570194244, 0.21245171129703522, 0.21392865478992462, 0.21563281118869781, 0.2126789391040802, 0.21960918605327606, 0.21813224256038666, 0.21688252687454224, 0.21870028972625732, 0.21767780184745789, 0.21699613332748413, 0.21949556469917297, 0.22097250819206238, 0.21688252687454224, 0.22085890173912048, 0.21824584901332855, 0.21870028972625732, 0.2189275175333023, 0.21938195824623108, 0.21960918605327606, 0.22142694890499115, 0.22165417671203613, 0.2223358303308487, 0.22653941810131073, 0.22040444612503052, 0.22415360808372498]\n",
      "Model: \"model_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_84 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_162 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_162 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_163 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_81 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_163 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:9 D2:dropOutTwo0.1[0.24187684059143066, 0.35980460047721863, 0.40195411443710327, 0.42297205328941345, 0.43115201592445374, 0.4558055102825165, 0.4571688175201416, 0.46421268582344055, 0.4651215672492981, 0.4790956676006317, 0.4811406433582306, 0.48182231187820435, 0.49409225583076477, 0.4985230565071106, 0.495341956615448, 0.505680501461029, 0.5040899515151978, 0.5088616013526917, 0.5101113319396973, 0.5152238011360168, 0.510452151298523, 0.5109066367149353]\n",
      "Model: \"model_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_85 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_164 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_164 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_165 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_82 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_165 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:9 D2:dropOutTwo0.2[0.26391729712486267, 0.3361735939979553, 0.36389458179473877, 0.3902522027492523, 0.3982049524784088, 0.4158145785331726, 0.4252442717552185, 0.43387866020202637, 0.44183140993118286, 0.4443308413028717, 0.45148828625679016, 0.45307883620262146, 0.45455577969551086, 0.45625993609428406, 0.46239492297172546, 0.45603272318840027, 0.46750739216804504, 0.4681890606880188, 0.4742104113101959, 0.47682344913482666, 0.48000454902648926, 0.4807998239994049, 0.47364234924316406, 0.48182231187820435, 0.48170870542526245, 0.4772779047489166, 0.4792092740535736, 0.48670756816864014, 0.4796636998653412, 0.4870483875274658]\n",
      "Model: \"model_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_86 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_166 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_166 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_167 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_83 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_167 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:9 D2:dropOutTwo0.3[0.23926380276679993, 0.30833899974823, 0.3432174623012543, 0.35787320137023926, 0.37093842029571533, 0.38195863366127014, 0.3872983455657959, 0.3968416154384613, 0.4029766023159027, 0.4096796214580536, 0.40706658363342285, 0.4143376648426056, 0.4221767783164978, 0.4252442717552185, 0.42160871624946594, 0.42263123393058777, 0.4317200779914856, 0.4329697787761688, 0.43853670358657837, 0.4319472908973694, 0.4399000108242035, 0.44387638568878174, 0.44830721616744995, 0.4378550350666046, 0.44364917278289795, 0.44978412985801697, 0.4511474668979645, 0.44364917278289795, 0.44717109203338623, 0.45603272318840027]\n",
      "Model: \"model_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_87 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_168 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_168 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_169 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_84 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_169 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:9 D2:dropOutTwo0.5[0.2240399867296219, 0.2733469605445862, 0.29731878638267517, 0.3144739866256714, 0.32810723781585693, 0.33412861824035645, 0.34014996886253357, 0.3425357937812805, 0.34355828166007996, 0.3568507134914398, 0.35151103138923645, 0.35298794507980347, 0.35344240069389343, 0.3536696135997772, 0.36571234464645386, 0.36605316400527954, 0.3652578890323639, 0.36730289459228516, 0.3679845631122589, 0.3665076196193695, 0.367075651884079, 0.3695750832557678, 0.3687798082828522, 0.376391738653183, 0.3828675448894501, 0.3885480463504791, 0.3876391649246216, 0.38809362053871155, 0.38002726435661316, 0.39468303322792053]\n",
      "Model: \"model_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_88 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_170 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_170 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_171 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_85 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      " dropout_171 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:9 D2:dropOutTwo0.9[0.1775732785463333, 0.19586457312107086, 0.20756645500659943, 0.21654169261455536, 0.21472392976284027, 0.21835947036743164, 0.22313110530376434, 0.2238127738237381, 0.22744831442832947, 0.22733469307422638, 0.22563053667545319, 0.22653941810131073, 0.22585776448249817, 0.22506248950958252, 0.22949329018592834, 0.22824357450008392, 0.22915247082710266, 0.23221994936466217, 0.2300613522529602, 0.2254033237695694, 0.22881163656711578, 0.22983412444591522, 0.2332424521446228, 0.23142467439174652, 0.23085662722587585, 0.22926607728004456, 0.23619632422924042, 0.23517382144927979, 0.23755964636802673, 0.23312883079051971]\n",
      "Model: \"model_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_89 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_172 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_172 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_173 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_86 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:10 D2:dropOutTwo0.1[0.2605089843273163, 0.3648034632205963, 0.3967280089855194, 0.417745977640152, 0.4334242343902588, 0.4492160975933075, 0.45978185534477234, 0.4654623866081238, 0.4742104113101959, 0.4823903739452362, 0.4909111559391022, 0.4893206059932709, 0.4969325065612793, 0.4981822371482849, 0.5081799626350403, 0.5026130676269531, 0.501931369304657, 0.5272665023803711, 0.5037491321563721, 0.5164735317230225, 0.5185185074806213]\n",
      "Model: \"model_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_90 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_174 (Dropout)       (None, 6144)              0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " batch_normalization_174 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_175 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_87 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_175 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:10 D2:dropOutTwo0.2[0.17689161002635956, 0.3141331374645233, 0.3810497522354126, 0.3920699954032898, 0.4158145785331726, 0.4203590154647827, 0.4350147545337677, 0.43887752294540405, 0.44330835342407227, 0.4475119411945343, 0.4585321545600891, 0.45625993609428406, 0.45966824889183044, 0.4669393301010132, 0.47068849205970764, 0.46273574233055115, 0.4750056862831116, 0.47977733612060547, 0.4746648371219635, 0.4726198613643646, 0.48011815547943115, 0.47659623622894287]\n",
      "Model: \"model_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_91 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_176 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_176 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_177 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_88 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_177 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:10 D2:dropOutTwo0.3[0.2649397850036621, 0.3271983563899994, 0.3506021499633789, 0.3699159324169159, 0.37820950150489807, 0.39615997672080994, 0.39752328395843506, 0.4035446345806122, 0.4141104221343994, 0.42478981614112854, 0.4143376648426056, 0.4239945411682129, 0.435128390789032, 0.4270620346069336, 0.4384230971336365, 0.43228811025619507, 0.4347875416278839, 0.4396727979183197, 0.43865031003952026, 0.44353556632995605, 0.4384230971336365, 0.44853442907333374, 0.44853442907333374, 0.44058167934417725, 0.4559191167354584, 0.4425130784511566, 0.44842082262039185, 0.4527380168437958]\n",
      "Model: \"model_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_92 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_178 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_178 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_179 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_89 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_179 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:10 D2:dropOutTwo0.5[0.18518517911434174, 0.26891615986824036, 0.2970915734767914, 0.3108384311199188, 0.32810723781585693, 0.3424221873283386, 0.34855714440345764, 0.35639628767967224, 0.36048623919487, 0.3685525953769684, 0.36548513174057007, 0.3712792694568634, 0.375937283039093, 0.3804817199707031, 0.37843671441078186, 0.38513973355293274, 0.3885480463504791, 0.389116108417511, 0.3861622214317322, 0.3904794454574585, 0.3902522027492523, 0.38513973355293274, 0.39309248328208923, 0.3877527713775635, 0.38491252064704895, 0.4012724459171295, 0.3905930519104004, 0.3934333026409149, 0.3901385962963104]\n",
      "Model: \"model_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_93 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_180 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_180 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_181 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_90 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dropout_181 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:10 D2:dropOutTwo0.9[0.17427857220172882, 0.20109066367149353, 0.2030220478773117, 0.21063394844532013, 0.20972506701946259, 0.2191547304391861, 0.2240399867296219, 0.2284708023071289, 0.2254033237695694, 0.2301749587059021, 0.23062939941883087, 0.22790275514125824, 0.23256078362464905, 0.23437854647636414, 0.23392410576343536, 0.23608270287513733, 0.234946608543396, 0.2319927215576172, 0.2318791151046753, 0.23403771221637726, 0.2318791151046753, 0.2379004806280136, 0.2335832715034485, 0.23381049931049347, 0.23608270287513733, 0.23710520565509796, 0.23676437139511108, 0.24017268419265747, 0.23551465570926666, 0.23858213424682617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_94 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_182 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_182 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_183 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_91 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_183 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:11 D2:dropOutTwo0.1[0.2764144539833069, 0.3605998754501343, 0.38945692777633667, 0.4108157157897949, 0.4267211854457855, 0.43581002950668335, 0.452056348323822, 0.4638718366622925, 0.4727334678173065, 0.47670984268188477, 0.47693705558776855, 0.4904567003250122, 0.4810270369052887, 0.5006816387176514, 0.5007952451705933, 0.5064758062362671, 0.5098841190338135, 0.5074983239173889, 0.5062485933303833, 0.5170415639877319, 0.5126107931137085, 0.5199954509735107]\n",
      "Model: \"model_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_95 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_184 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_184 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_185 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_92 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_185 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:11 D2:dropOutTwo0.2[0.27039310336112976, 0.34355828166007996, 0.3886616826057434, 0.41524654626846313, 0.4174051284790039, 0.43069756031036377, 0.4392183721065521, 0.4496705234050751, 0.45637354254722595, 0.46239492297172546, 0.46625766158103943, 0.4588729739189148, 0.4748920798301697, 0.47864121198654175, 0.48034536838531494, 0.4729606807231903, 0.48352646827697754, 0.48341286182403564, 0.48954781889915466, 0.4869347810745239, 0.49625083804130554, 0.49579641222953796]\n",
      "Model: \"model_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_96 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_186 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_186 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_187 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_93 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_187 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:11 D2:dropOutTwo0.3[0.2653942406177521, 0.3384458124637604, 0.3679845631122589, 0.3860486149787903, 0.40388548374176025, 0.4067257344722748, 0.4171779155731201, 0.4160418212413788, 0.4302431344985962, 0.43421950936317444, 0.4411497414112091, 0.4361508786678314, 0.4427402913570404, 0.4491024911403656, 0.4463758170604706, 0.44819357991218567, 0.44978412985801697, 0.4491024911403656, 0.453987717628479, 0.4511474668979645, 0.46603044867515564, 0.45148828625679016, 0.456714391708374, 0.46921154856681824, 0.4620540738105774, 0.4655759930610657, 0.46091797947883606, 0.4583049416542053, 0.46625766158103943]\n",
      "Model: \"model_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_97 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_188 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_188 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_189 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_94 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_189 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:11 D2:dropOutTwo0.5[0.2224494367837906, 0.2808452546596527, 0.3156100809574127, 0.33117473125457764, 0.3460577130317688, 0.3473074436187744, 0.3494660258293152, 0.36582595109939575, 0.36616677045822144, 0.3728697896003723, 0.367075651884079, 0.37855032086372375, 0.37866392731666565, 0.3750284016132355, 0.3779822885990143, 0.38638946413993835, 0.38195863366127014, 0.38457170128822327, 0.38968417048454285, 0.40195411443710327, 0.39150193333625793, 0.4080890715122223, 0.40422630310058594, 0.40365827083587646, 0.39525106549263, 0.410702109336853, 0.40365827083587646, 0.411156564950943, 0.40854352712631226, 0.4060440957546234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_98 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_190 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_190 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_190 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_191 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_95 (Activation)  (None, 11)                0         \n",
      "                                                                 \n",
      " dropout_191 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:11 D2:dropOutTwo0.9[0.1792774349451065, 0.19132015109062195, 0.19393320381641388, 0.20438537001609802, 0.2158600389957428, 0.21483753621578217, 0.21495114266872406, 0.22256305813789368, 0.2207452803850174, 0.2223358303308487, 0.22256305813789368, 0.22017723321914673, 0.22188138961791992, 0.22574414312839508, 0.22324471175670624, 0.22506248950958252, 0.22619858384132385, 0.22642581164836884, 0.23142467439174652, 0.23312883079051971, 0.22438082098960876, 0.22608497738838196, 0.230288565158844, 0.230288565158844, 0.23131106793880463, 0.2268802523612976, 0.23210634291172028, 0.23142467439174652, 0.23256078362464905, 0.23301522433757782]\n",
      "Model: \"model_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_99 (InputLayer)       [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_192 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_192 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_193 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_96 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_193 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:12 D2:dropOutTwo0.1[0.2698250412940979, 0.35662350058555603, 0.4011588394641876, 0.4314928352832794, 0.44546693563461304, 0.4668257236480713, 0.4792092740535736, 0.4746648371219635, 0.48670756816864014, 0.48682117462158203, 0.49613723158836365, 0.5101113319396973, 0.5081799626350403, 0.5174960494041443, 0.5146557688713074, 0.5190865993499756, 0.5291979312896729, 0.5143149495124817, 0.5229493379592896, 0.5277209877967834, 0.5305612087249756, 0.5371506214141846, 0.5371506214141846]\n",
      "Model: \"model_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_100 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_194 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_194 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_195 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_97 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_195 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:12 D2:dropOutTwo0.2[0.3026584982872009, 0.36434900760650635, 0.39468303322792053, 0.4108157157897949, 0.42751646041870117, 0.43751421570777893, 0.4480799734592438, 0.452056348323822, 0.45637354254722595, 0.4726198613643646, 0.4651215672492981, 0.46773460507392883, 0.47534650564193726, 0.48034536838531494, 0.4838673174381256, 0.4854578375816345, 0.48148149251937866, 0.48625311255455017, 0.4931833744049072, 0.49147921800613403]\n",
      "Model: \"model_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_101 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_196 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_196 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_197 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_98 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_197 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:12 D2:dropOutTwo0.3[0.2853896915912628, 0.34026357531547546, 0.3812769949436188, 0.3861622214317322, 0.4094524085521698, 0.41217905282974243, 0.421949565410614, 0.43001589179039, 0.43228811025619507, 0.4335378408432007, 0.4475119411945343, 0.4448988735675812, 0.45762327313423157, 0.4506930112838745, 0.45023858547210693, 0.45444217324256897, 0.45455577969551086, 0.4601227045059204, 0.45614632964134216, 0.46080437302589417, 0.4697795808315277, 0.4731879234313965, 0.4600090980529785, 0.47523289918899536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_102 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_198 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_198 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_199 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_99 (Activation)  (None, 12)                0         \n",
      "                                                                 \n",
      " dropout_199 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:12 D2:dropOutTwo0.5[0.19722791016101837, 0.2827766537666321, 0.3209497928619385, 0.3348102569580078, 0.3525335192680359, 0.36094069480895996, 0.36457622051239014, 0.37059760093688965, 0.37377870082855225, 0.3790047764778137, 0.38195863366127014, 0.3854805827140808, 0.38502612709999084, 0.387184739112854, 0.3902522027492523, 0.39104747772216797, 0.3827539086341858, 0.3919563591480255, 0.40218132734298706, 0.39570552110671997, 0.40195411443710327, 0.39297887682914734, 0.3935469090938568, 0.4027493894100189, 0.39752328395843506, 0.40411269664764404, 0.4035446345806122, 0.4035446345806122, 0.39786413311958313, 0.39775049686431885]\n",
      "Model: \"model_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_103 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_200 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_200 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_200 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_201 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_100 (Activation)  (None, 12)               0         \n",
      "                                                                 \n",
      " dropout_201 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:12 D2:dropOutTwo0.9[0.16303113102912903, 0.18541240692138672, 0.1982503980398178, 0.19927288591861725, 0.2046125829219818, 0.21858668327331543, 0.2159736454486847, 0.21563281118869781, 0.22279027104377747, 0.22597137093544006, 0.22608497738838196, 0.22926607728004456, 0.22733469307422638, 0.22983412444591522, 0.22824357450008392, 0.23585548996925354, 0.23040218651294708, 0.22812996804714203, 0.23403771221637726, 0.22790275514125824, 0.22892524302005768, 0.23210634291172028, 0.23540104925632477, 0.23312883079051971, 0.23517382144927979, 0.23051579296588898, 0.23244717717170715, 0.2317655086517334, 0.2379004806280136, 0.234719380736351]\n",
      "Model: \"model_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_104 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_202 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_202 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_203 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_101 (Activation)  (None, 8)                0         \n",
      "                                                                 \n",
      " dropout_203 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:8 D2:dropOutTwo0.1[0.212906152009964, 0.2860713601112366, 0.3079981803894043, 0.31799590587615967, 0.32822084426879883, 0.34049078822135925, 0.3490116000175476, 0.3512837886810303, 0.3479890823364258, 0.3523063063621521, 0.3613951504230499, 0.3599182069301605, 0.3635537326335907, 0.36253124475479126, 0.36605316400527954, 0.36593955755233765, 0.3683253824710846, 0.36775732040405273, 0.3701431453227997, 0.36775732040405273, 0.36923426389694214, 0.37207451462745667, 0.3701431453227997, 0.3734378516674042, 0.3743467330932617, 0.3728697896003723, 0.3687798082828522, 0.37411952018737793, 0.371733695268631, 0.37389230728149414]\n",
      "Model: \"model_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_105 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_204 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_204 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_205 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_102 (Activation)  (None, 8)                0         \n",
      "                                                                 \n",
      " dropout_205 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:8 D2:dropOutTwo0.2[0.1572369933128357, 0.2350602149963379, 0.27845942974090576, 0.299818217754364, 0.3042490482330322, 0.31651896238327026, 0.3124289810657501, 0.31492841243743896, 0.32435810565948486, 0.32617586851119995, 0.3337877690792084, 0.3351511061191559, 0.3384458124637604, 0.3395819067955017, 0.33719608187675476, 0.3412860631942749, 0.3408316373825073, 0.3520790636539459, 0.3475346565246582, 0.34310382604599, 0.3445807695388794, 0.3507157564163208, 0.35332879424095154, 0.3459441065788269, 0.3444671630859375, 0.352419912815094, 0.3511701822280884, 0.3512837886810303, 0.35503295063972473, 0.3583276569843292]\n",
      "Model: \"model_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_106 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_206 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_206 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_207 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_103 (Activation)  (None, 8)                0         \n",
      "                                                                 \n",
      " dropout_207 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:8 D2:dropOutTwo0.3[0.12769825756549835, 0.18450352549552917, 0.2427857369184494, 0.27209725975990295, 0.2825494110584259, 0.30254486203193665, 0.30856624245643616, 0.31174734234809875, 0.32288116216659546, 0.3208361864089966, 0.32310837507247925, 0.32163146138191223, 0.3208361864089966, 0.32458531856536865, 0.3336741626262665, 0.32572141289711, 0.3394683003425598, 0.3334469497203827, 0.3376505374908447, 0.3400363624095917, 0.3381049633026123, 0.3377641439437866, 0.33867302536964417, 0.3378777503967285, 0.3381049633026123, 0.34049078822135925, 0.34526243805885315, 0.3473074436187744, 0.34174051880836487, 0.34378549456596375]\n",
      "Model: \"model_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_107 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_208 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_208 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_209 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_104 (Activation)  (None, 8)                0         \n",
      "                                                                 \n",
      " dropout_209 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:8 D2:dropOutTwo0.5[0.15814587473869324, 0.20359009504318237, 0.23880936205387115, 0.2543739974498749, 0.2713019847869873, 0.27527835965156555, 0.2778913974761963, 0.280504435300827, 0.28777551651000977, 0.2842535674571991, 0.2941376864910126, 0.289025217294693, 0.2920927107334137, 0.2935696542263031, 0.2982276678085327, 0.3031129240989685, 0.30674847960472107, 0.30402180552482605, 0.29731878638267517, 0.30254486203193665, 0.29618269205093384, 0.29947739839553833, 0.30368098616600037, 0.30072709918022156, 0.2968643605709076, 0.30231764912605286, 0.3099295496940613, 0.3045898675918579, 0.3027721047401428, 0.3098159432411194]\n",
      "Model: \"model_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_108 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_210 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_210 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_210 (Dense)           (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_211 (Ba  (None, 8)                32        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_105 (Activation)  (None, 8)                0         \n",
      "                                                                 \n",
      " dropout_211 (Dropout)       (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:8 D2:dropOutTwo0.9[0.16848443448543549, 0.17723244428634644, 0.19120654463768005, 0.19768235087394714, 0.20063622295856476, 0.2049534171819687, 0.20234037935733795, 0.20768007636070251, 0.206316739320755, 0.21074755489826202, 0.21040672063827515, 0.21233810484409332, 0.21381504833698273, 0.21551920473575592, 0.21540558338165283, 0.21699613332748413, 0.21835947036743164, 0.21563281118869781, 0.21676892042160034, 0.217564195394516, 0.2159736454486847, 0.21563281118869781, 0.22176778316497803, 0.21972279250621796, 0.2223358303308487, 0.2191547304391861, 0.21983639895915985, 0.22301749885082245, 0.22472165524959564, 0.22301749885082245]\n",
      "Model: \"model_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_109 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_212 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_212 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_212 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_213 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_106 (Activation)  (None, 9)                0         \n",
      "                                                                 \n",
      " dropout_213 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:9 D2:dropOutTwo0.1[0.1905248761177063, 0.27402862906455994, 0.2997046113014221, 0.31663256883621216, 0.33719608187675476, 0.35026130080223083, 0.3488979637622833, 0.3521926701068878, 0.3587820827960968, 0.36094069480895996, 0.36298567056655884, 0.36241763830184937, 0.363212913274765, 0.3652578890323639, 0.3712792694568634, 0.3682117760181427, 0.3766189515590668, 0.36787092685699463, 0.3748011887073517, 0.37048399448394775, 0.36889344453811646, 0.36628037691116333, 0.3700295388698578, 0.37230175733566284, 0.3700295388698578, 0.37559646368026733, 0.3765053451061249, 0.38002726435661316, 0.37514200806617737, 0.37411952018737793]\n",
      "Model: \"model_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_110 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_214 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_214 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_215 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_107 (Activation)  (None, 9)                0         \n",
      "                                                                 \n",
      " dropout_215 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:9 D2:dropOutTwo0.2[0.2110883891582489, 0.28175413608551025, 0.311065673828125, 0.31322425603866577, 0.3206089437007904, 0.3332197368144989, 0.3381049633026123, 0.3428766131401062, 0.3463985323905945, 0.34821632504463196, 0.34844353795051575, 0.3488979637622833, 0.3525335192680359, 0.35037490725517273, 0.358554869890213, 0.35787320137023926, 0.3490116000175476, 0.35037490725517273, 0.3508293628692627, 0.3652578890323639, 0.3637809455394745, 0.35014769434928894, 0.3554873764514923, 0.3573051691055298, 0.36116790771484375, 0.35821405053138733, 0.36412179470062256, 0.36230403184890747, 0.3600318133831024, 0.36582595109939575]\n",
      "Model: \"model_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_111 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_216 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_216 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_217 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_108 (Activation)  (None, 9)                0         \n",
      "                                                                 \n",
      " dropout_217 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:9 D2:dropOutTwo0.3[0.19927288591861725, 0.2555101215839386, 0.2852760851383209, 0.29152464866638184, 0.2995910048484802, 0.30231764912605286, 0.3092479109764099, 0.3193592429161072, 0.32106339931488037, 0.32004091143608093, 0.3234492242336273, 0.32583504915237427, 0.3316291868686676, 0.33128833770751953, 0.32969778776168823, 0.339241087436676, 0.3351511061191559, 0.3443535566329956, 0.3412860631942749, 0.34071803092956543, 0.34310382604599, 0.3493524193763733, 0.3379913568496704, 0.3396955132484436, 0.34378549456596375, 0.3410588502883911, 0.3441263437271118, 0.34662577509880066, 0.34980687499046326, 0.34526243805885315]\n",
      "Model: \"model_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_112 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_218 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_218 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_219 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_109 (Activation)  (None, 9)                0         \n",
      "                                                                 \n",
      " dropout_219 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:9 D2:dropOutTwo0.5[0.16859804093837738, 0.2174505740404129, 0.2430129498243332, 0.2571006715297699, 0.26562145352363586, 0.27209725975990295, 0.27221086621284485, 0.28027722239494324, 0.2775505483150482, 0.28618496656417847, 0.2853896915912628, 0.2920927107334137, 0.2965235114097595, 0.2983412742614746, 0.2917518615722656, 0.30368098616600037, 0.30697569251060486, 0.30731651186943054, 0.312997043132782, 0.3050442934036255, 0.3079981803894043, 0.30674847960472107, 0.31174734234809875, 0.31481480598449707, 0.3079981803894043, 0.31186094880104065, 0.31015679240226746, 0.31345149874687195, 0.31833675503730774, 0.31651896238327026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_113 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_220 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_220 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_220 (Dense)           (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_221 (Ba  (None, 9)                36        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_110 (Activation)  (None, 9)                0         \n",
      "                                                                 \n",
      " dropout_221 (Dropout)       (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:9 D2:dropOutTwo0.9[0.15928198397159576, 0.17246080935001373, 0.18200409412384033, 0.18120881915092468, 0.1871165633201599, 0.18961599469184875, 0.19177459180355072, 0.19450125098228455]\n",
      "Model: \"model_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_114 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_222 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_222 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_223 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_111 (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      " dropout_223 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:10 D2:dropOutTwo0.1[0.21517837047576904, 0.30402180552482605, 0.3219722807407379, 0.32924336194992065, 0.3410588502883911, 0.3462849259376526, 0.3558282256126404, 0.36605316400527954, 0.36128151416778564, 0.35946375131607056, 0.3652578890323639, 0.3699159324169159, 0.3710520267486572, 0.37218815088272095, 0.3729834258556366, 0.37252897024154663, 0.3728697896003723, 0.3718473017215729, 0.38036808371543884, 0.3699159324169159, 0.38366279006004333, 0.37389230728149414, 0.3700295388698578, 0.3774142265319824, 0.3793455958366394, 0.38354918360710144, 0.376391738653183, 0.37684616446495056, 0.3733242452144623, 0.3887752890586853]\n",
      "Model: \"model_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_115 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_224 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_224 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_225 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_112 (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      " dropout_225 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:10 D2:dropOutTwo0.2[0.20052260160446167, 0.2605089843273163, 0.2797091603279114, 0.3033401370048523, 0.3124289810657501, 0.32435810565948486, 0.33128833770751953, 0.3362872004508972, 0.33128833770751953, 0.3367416560649872, 0.34719380736351013, 0.3429902195930481, 0.34310382604599, 0.35662350058555603, 0.3571915328502655, 0.3600318133831024, 0.3537832200527191, 0.3569643199443817, 0.3605998754501343, 0.358554869890213, 0.36275845766067505, 0.35639628767967224, 0.3605998754501343, 0.36253124475479126, 0.36071348190307617, 0.3680981695652008, 0.3620767891407013, 0.3635537326335907, 0.3744603395462036, 0.36605316400527954]\n",
      "Model: \"model_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_116 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_226 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_226 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_227 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_113 (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      " dropout_227 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:10 D2:dropOutTwo0.3[0.1747330129146576, 0.2411951869726181, 0.2734605669975281, 0.29913654923439026, 0.3018632233142853, 0.3075437545776367, 0.3249261677265167, 0.3201545178890228, 0.32469892501831055, 0.3321972191333771, 0.3317427933216095, 0.3377641439437866, 0.33571916818618774, 0.3334469497203827, 0.33730968832969666, 0.33401498198509216, 0.3362872004508972, 0.34685298800468445, 0.34810271859169006, 0.34196773171424866, 0.3473074436187744, 0.34378549456596375, 0.3495796322822571, 0.3461713194847107, 0.34855714440345764, 0.3492388129234314, 0.35139739513397217, 0.34844353795051575, 0.3511701822280884, 0.3525335192680359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_117 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_228 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_228 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_229 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_114 (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      " dropout_229 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:10 D2:dropOutTwo0.5[0.17257441580295563, 0.23119746148586273, 0.2571006715297699, 0.26414451003074646, 0.27732333540916443, 0.2860713601112366, 0.28947967290878296, 0.2985685169696808, 0.3011815547943115, 0.3082253932952881, 0.3016359806060791, 0.3082253932952881, 0.31856396794319153, 0.31379231810569763, 0.31981366872787476, 0.3178822994232178, 0.3098159432411194, 0.3116337060928345, 0.3109520673751831, 0.3158373236656189, 0.31663256883621216, 0.31833675503730774, 0.3192456364631653, 0.3223131000995636, 0.3236764371395111, 0.32583504915237427, 0.32322198152542114, 0.31981366872787476, 0.3193592429161072, 0.32424449920654297]\n",
      "Model: \"model_117\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_118 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_230 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_230 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_230 (Dense)           (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_231 (Ba  (None, 10)               40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_115 (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      " dropout_231 (Dropout)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:10 D2:dropOutTwo0.9[0.15587367117404938, 0.16927970945835114, 0.17598272860050201, 0.17905022203922272, 0.18382185697555542, 0.188934326171875, 0.19166098535060883, 0.19461485743522644, 0.19915927946567535, 0.19768235087394714, 0.2014314979314804, 0.20279482007026672, 0.2048398107290268, 0.206316739320755, 0.20756645500659943, 0.206316739320755, 0.20915700495243073, 0.210974782705307, 0.21086116135120392, 0.212906152009964, 0.2126789391040802, 0.21199727058410645, 0.21563281118869781, 0.2125653326511383, 0.21767780184745789, 0.2157464176416397, 0.21404226124286652, 0.21847307682037354, 0.21699613332748413, 0.2158600389957428]\n",
      "Model: \"model_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_119 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_232 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_232 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_233 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_116 (Activation)  (None, 11)               0         \n",
      "                                                                 \n",
      " dropout_233 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:11 D2:dropOutTwo0.1[0.2205180674791336, 0.28811633586883545, 0.32151782512664795, 0.3302658498287201, 0.3413996696472168, 0.33855941891670227, 0.3488979637622833, 0.35332879424095154, 0.3584412634372711, 0.3616223633289337, 0.3679845631122589, 0.3650306761264801, 0.3694614768028259, 0.3702567517757416, 0.3729834258556366, 0.37673255801200867, 0.3729834258556366, 0.37571007013320923, 0.3712792694568634, 0.3748011887073517, 0.38195863366127014, 0.3701431453227997, 0.37786865234375, 0.38014087080955505, 0.37400591373443604, 0.37866392731666565, 0.3795728385448456, 0.3734378516674042, 0.3807089328765869, 0.38309475779533386]\n",
      "Model: \"model_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_120 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_234 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_234 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_235 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_117 (Activation)  (None, 11)               0         \n",
      "                                                                 \n",
      " dropout_235 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:11 D2:dropOutTwo0.2[0.17973187565803528, 0.26391729712486267, 0.2935696542263031, 0.3178822994232178, 0.3285616934299469, 0.3283344805240631, 0.341626912355423, 0.33855941891670227, 0.34333106875419617, 0.3444671630859375, 0.34480801224708557, 0.3511701822280884, 0.3584412634372711, 0.354351282119751, 0.36128151416778564, 0.3573051691055298, 0.35616904497146606, 0.35185185074806213, 0.3568507134914398, 0.3619631826877594, 0.36287206411361694, 0.36730289459228516, 0.3633265197277069, 0.36548513174057007, 0.365144282579422, 0.36457622051239014, 0.35935014486312866, 0.3634401261806488, 0.35798680782318115, 0.37366506457328796]\n",
      "Model: \"model_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_121 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_236 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_236 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_237 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_118 (Activation)  (None, 11)               0         \n",
      "                                                                 \n",
      " dropout_237 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:11 D2:dropOutTwo0.3[0.17848215997219086, 0.2543739974498749, 0.2823221981525421, 0.29311519861221313, 0.29925015568733215, 0.30720290541648865, 0.31845036149024963, 0.3208361864089966, 0.32288116216659546, 0.32117700576782227, 0.3301522433757782, 0.3271983563899994, 0.34026357531547546, 0.3428766131401062, 0.34992048144340515, 0.3424221873283386, 0.3488979637622833, 0.35151103138923645, 0.3494660258293152, 0.34832993149757385, 0.34821632504463196, 0.3552601635456085, 0.3494660258293152, 0.35628265142440796, 0.34514883160591125, 0.35469210147857666, 0.354351282119751, 0.35151103138923645, 0.3541240692138672, 0.35139739513397217]\n",
      "Model: \"model_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_122 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_238 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_238 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_239 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_119 (Activation)  (None, 11)               0         \n",
      "                                                                 \n",
      " dropout_239 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:11 D2:dropOutTwo0.5[0.14871619641780853, 0.22494886815547943, 0.25028401613235474, 0.27255168557167053, 0.28982049226760864, 0.29436492919921875, 0.30209043622016907, 0.3012951612472534, 0.3059532046318054, 0.3143603801727295, 0.31333789229393005, 0.3116337060928345, 0.3236764371395111, 0.3141331374645233, 0.3251533806324005, 0.3271983563899994, 0.32117700576782227, 0.3201545178890228, 0.32140421867370605, 0.3234492242336273, 0.3287889063358307, 0.32765281200408936, 0.3273119628429413, 0.3352647125720978, 0.32628947496414185, 0.3249261677265167, 0.3253805935382843, 0.3298113942146301, 0.32776641845703125, 0.3219722807407379]\n",
      "Model: \"model_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_123 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_240 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_240 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_240 (Dense)           (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_241 (Ba  (None, 11)               44        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_120 (Activation)  (None, 11)               0         \n",
      "                                                                 \n",
      " dropout_241 (Dropout)       (None, 11)                0         \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:11 D2:dropOutTwo0.9[0.16280390322208405, 0.1665530502796173, 0.1745058000087738, 0.18200409412384033, 0.18768461048603058, 0.19279709458351135, 0.19575096666812897, 0.19472846388816833, 0.19620540738105774]\n",
      "Model: \"model_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_124 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_242 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_242 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_243 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_121 (Activation)  (None, 12)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dropout_243 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:12 D2:dropOutTwo0.1[0.20268121361732483, 0.2970915734767914, 0.3271983563899994, 0.3424221873283386, 0.3476482629776001, 0.3559418320655823, 0.3535560071468353, 0.3603726327419281, 0.3648034632205963, 0.37037035822868347, 0.3653714954853058, 0.3746875822544098, 0.37820950150489807, 0.37059760093688965, 0.3748011887073517, 0.3745739459991455, 0.36582595109939575, 0.37548285722732544, 0.37718701362609863, 0.37400591373443604, 0.3791183829307556, 0.38195863366127014, 0.38309475779533386, 0.3870711326599121, 0.3811633586883545, 0.3861622214317322, 0.3877527713775635, 0.38320836424827576, 0.37877756357192993, 0.38161781430244446]\n",
      "Model: \"model_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_125 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_244 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_244 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_245 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_122 (Activation)  (None, 12)               0         \n",
      "                                                                 \n",
      " dropout_245 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:12 D2:dropOutTwo0.2[0.18382185697555542, 0.2820949852466583, 0.31061121821403503, 0.3178822994232178, 0.3320836126804352, 0.3394683003425598, 0.33730968832969666, 0.34071803092956543, 0.35014769434928894, 0.34980687499046326, 0.3493524193763733, 0.3537832200527191, 0.36389458179473877, 0.36071348190307617, 0.3591229319572449, 0.35935014486312866, 0.3586684763431549, 0.3613951504230499, 0.3648034632205963, 0.36457622051239014, 0.36412179470062256, 0.36434900760650635, 0.3687798082828522, 0.37366506457328796, 0.36753010749816895, 0.3699159324169159, 0.3666212260723114, 0.3663940131664276, 0.37037035822868347, 0.36605316400527954]\n",
      "Model: \"model_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_126 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_246 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_246 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_247 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_123 (Activation)  (None, 12)               0         \n",
      "                                                                 \n",
      " dropout_247 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:12 D2:dropOutTwo0.3[0.17030219733715057, 0.25017040967941284, 0.2820949852466583, 0.2983412742614746, 0.29436492919921875, 0.3160645365715027, 0.3208361864089966, 0.3201545178890228, 0.3299250304698944, 0.3236764371395111, 0.3398091197013855, 0.33730968832969666, 0.34174051880836487, 0.33855941891670227, 0.3491252064704895, 0.34696659445762634, 0.35185185074806213, 0.3542376756668091, 0.3488979637622833, 0.3510565757751465, 0.34844353795051575, 0.35457849502563477, 0.36105430126190186, 0.3584412634372711, 0.35162463784217834, 0.3536696135997772, 0.3569643199443817, 0.35616904497146606, 0.35344240069389343, 0.3619631826877594]\n",
      "Model: \"model_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_127 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_248 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_248 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_249 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_124 (Activation)  (None, 12)               0         \n",
      "                                                                 \n",
      " dropout_249 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:12 D2:dropOutTwo0.5[0.13837763667106628, 0.21029311418533325, 0.25471484661102295, 0.2774369418621063, 0.2797091603279114, 0.28777551651000977, 0.295614629983902, 0.2987957298755646, 0.31049761176109314, 0.30902066826820374, 0.3116337060928345, 0.3147011995315552, 0.3161781430244446, 0.31640535593032837, 0.3268575370311737, 0.32765281200408936, 0.3221994936466217, 0.3270847499370575, 0.3271983563899994, 0.33276528120040894, 0.33106112480163574, 0.3335605561733246, 0.3337877690792084, 0.3320836126804352, 0.33083391189575195, 0.3315155506134033, 0.34049078822135925, 0.33401498198509216, 0.3393546938896179, 0.3352647125720978]\n",
      "Model: \"model_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_128 (InputLayer)      [(None, 6144)]            0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dropout_250 (Dropout)       (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_250 (Ba  (None, 6144)             24576     \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_250 (Dense)           (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_251 (Ba  (None, 12)               48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_125 (Activation)  (None, 12)               0         \n",
      "                                                                 \n",
      " dropout_251 (Dropout)       (None, 12)                0         \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:12 D2:dropOutTwo0.9[0.15825948119163513, 0.16893887519836426, 0.17393773794174194, 0.17870938777923584, 0.1874573975801468, 0.1904112696647644, 0.19177459180355072, 0.1954101324081421, 0.19495569169521332, 0.20040899515151978, 0.20063622295856476, 0.20109066367149353, 0.20586229860782623, 0.2016587108373642, 0.20540785789489746, 0.20688480138778687, 0.21233810484409332, 0.20892979204654694, 0.21029311418533325, 0.2065439671278, 0.20870256423950195, 0.20892979204654694, 0.21347421407699585, 0.2126789391040802, 0.21074755489826202, 0.21029311418533325, 0.2159736454486847, 0.21461030840873718, 0.2112019956111908, 0.21313337981700897]\n"
     ]
    }
   ],
   "source": [
    "iterations = {}\n",
    "\n",
    "\n",
    "for dropOutOne in [0.1, 0.2, 0.3, 0.5, 0.9]:               #[0.1,0.2]: #\n",
    "    for denseTwoPower in [8,9,10,11,12]:                         #[9,10]: #\n",
    "        for dropOutTwo in [0.1, 0.2, 0.3, 0.5, 0.9]:       #[0.1]: #\n",
    "\n",
    "        \n",
    "            #dropOutOne = 0.7\n",
    "            #denseTwoPower = 12 # 9 = 512\n",
    "            #dropOutTwo = 0.3\n",
    "\n",
    "            thisIteration=\"D1:\" + str(dropOutOne) + \" D2P:\" + str(denseTwoPower) + \" D2:dropOutTwo\" + str(dropOutTwo)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            combined_features = np.concatenate([resnet_predictions, vgg16_predictions],axis=1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(combined_features, y, test_size=0.1, random_state=42)\n",
    "            from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Activation, BatchNormalization\n",
    "\n",
    "            combined_inputs = Input(shape = (6144))\n",
    "            x = Dropout(dropOutOne)(combined_inputs) # add a dropout layer\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dense(denseTwoPower)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation(\"relu\")(x)\n",
    "            x = Dropout(dropOutTwo)(x) # add a dropout layer\n",
    "            # Softmax layer to the output classes\n",
    "            new_predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "            from tensorflow.keras.models import Model\n",
    "            model = Model(inputs=combined_inputs, outputs=new_predictions) # specify what is network input, and what is network output\n",
    "            model.summary()\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "            from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "            early_stop = EarlyStopping(monitor='val_loss',  patience=6, verbose=0)\n",
    "            # stop if loss does not improve for 3 iterations\n",
    "\n",
    "            history=model.fit(X_train, y_train, batch_size=128, epochs=30, \n",
    "                          validation_data=(X_test, y_test), callbacks=[early_stop], verbose=0)\n",
    "\n",
    "            iterations[thisIteration] = history.history['accuracy']\n",
    "            \n",
    "            print(thisIteration + str(history.history['accuracy']))\n",
    "\n",
    "\n",
    "#for obj in iterations:\n",
    "#    print(obj)\n",
    "#print(iterations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "815a7088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "OBJ:D1:0.1 D2P:8 D2:dropOutTwo0.1 acc:0.6038400530815125\n",
      "OBJ:D1:0.1 D2P:8 D2:dropOutTwo0.2 acc:0.5457850694656372\n",
      "OBJ:D1:0.1 D2P:8 D2:dropOutTwo0.3 acc:0.5355600714683533\n",
      "OBJ:D1:0.1 D2P:8 D2:dropOutTwo0.5 acc:0.428538978099823\n",
      "OBJ:D1:0.1 D2P:8 D2:dropOutTwo0.9 acc:0.206316739320755\n",
      "OBJ:D1:0.1 D2P:9 D2:dropOutTwo0.1 acc:0.6339468359947205\n",
      "OBJ:D1:0.1 D2P:9 D2:dropOutTwo0.2 acc:0.5835037231445312\n",
      "OBJ:D1:0.1 D2P:9 D2:dropOutTwo0.3 acc:0.5260168313980103\n",
      "OBJ:D1:0.1 D2P:9 D2:dropOutTwo0.5 acc:0.452056348323822\n",
      "OBJ:D1:0.1 D2P:9 D2:dropOutTwo0.9 acc:0.2381276935338974\n",
      "OBJ:D1:0.1 D2P:10 D2:dropOutTwo0.1 acc:0.6593955755233765\n",
      "OBJ:D1:0.1 D2P:10 D2:dropOutTwo0.2 acc:0.6021358966827393\n",
      "OBJ:D1:0.1 D2P:10 D2:dropOutTwo0.3 acc:0.5493069887161255\n",
      "OBJ:D1:0.1 D2P:10 D2:dropOutTwo0.5 acc:0.4651215672492981\n",
      "OBJ:D1:0.1 D2P:10 D2:dropOutTwo0.9 acc:0.2411951869726181\n",
      "OBJ:D1:0.1 D2P:11 D2:dropOutTwo0.1 acc:0.6641672253608704\n",
      "OBJ:D1:0.1 D2P:11 D2:dropOutTwo0.2 acc:0.6094069480895996\n",
      "OBJ:D1:0.1 D2P:11 D2:dropOutTwo0.3 acc:0.5508975386619568\n",
      "OBJ:D1:0.1 D2P:11 D2:dropOutTwo0.5 acc:0.4618268609046936\n",
      "OBJ:D1:0.1 D2P:11 D2:dropOutTwo0.9 acc:0.2333560585975647\n",
      "OBJ:D1:0.1 D2P:12 D2:dropOutTwo0.1 acc:0.6879118084907532\n",
      "OBJ:D1:0.1 D2P:12 D2:dropOutTwo0.2 acc:0.6156555414199829\n",
      "OBJ:D1:0.1 D2P:12 D2:dropOutTwo0.3 acc:0.5754374265670776\n",
      "OBJ:D1:0.1 D2P:12 D2:dropOutTwo0.5 acc:0.4763689935207367\n",
      "OBJ:D1:0.1 D2P:12 D2:dropOutTwo0.9 acc:0.24392183125019073\n",
      "OBJ:D1:0.2 D2P:8 D2:dropOutTwo0.1 acc:0.5683935284614563\n",
      "OBJ:D1:0.2 D2P:8 D2:dropOutTwo0.2 acc:0.5420358777046204\n",
      "OBJ:D1:0.2 D2P:8 D2:dropOutTwo0.3 acc:0.49454668164253235\n",
      "OBJ:D1:0.2 D2P:8 D2:dropOutTwo0.5 acc:0.39002498984336853\n",
      "OBJ:D1:0.2 D2P:8 D2:dropOutTwo0.9 acc:0.22154055535793304\n",
      "OBJ:D1:0.2 D2P:9 D2:dropOutTwo0.1 acc:0.5867984294891357\n",
      "OBJ:D1:0.2 D2P:9 D2:dropOutTwo0.2 acc:0.5547602772712708\n",
      "OBJ:D1:0.2 D2P:9 D2:dropOutTwo0.3 acc:0.5140877366065979\n",
      "OBJ:D1:0.2 D2P:9 D2:dropOutTwo0.5 acc:0.4253578782081604\n",
      "OBJ:D1:0.2 D2P:9 D2:dropOutTwo0.9 acc:0.23221994936466217\n",
      "OBJ:D1:0.2 D2P:10 D2:dropOutTwo0.1 acc:0.6092933416366577\n",
      "OBJ:D1:0.2 D2P:10 D2:dropOutTwo0.2 acc:0.5481708645820618\n",
      "OBJ:D1:0.2 D2P:10 D2:dropOutTwo0.3 acc:0.5155646204948425\n",
      "OBJ:D1:0.2 D2P:10 D2:dropOutTwo0.5 acc:0.4302431344985962\n",
      "OBJ:D1:0.2 D2P:10 D2:dropOutTwo0.9 acc:0.2333560585975647\n",
      "OBJ:D1:0.2 D2P:11 D2:dropOutTwo0.1 acc:0.60429447889328\n",
      "OBJ:D1:0.2 D2P:11 D2:dropOutTwo0.2 acc:0.5553283095359802\n",
      "OBJ:D1:0.2 D2P:11 D2:dropOutTwo0.3 acc:0.5355600714683533\n",
      "OBJ:D1:0.2 D2P:11 D2:dropOutTwo0.5 acc:0.4476255476474762\n",
      "OBJ:D1:0.2 D2P:11 D2:dropOutTwo0.9 acc:0.234719380736351\n",
      "OBJ:D1:0.2 D2P:12 D2:dropOutTwo0.1 acc:0.6234946846961975\n",
      "OBJ:D1:0.2 D2P:12 D2:dropOutTwo0.2 acc:0.5763462781906128\n",
      "OBJ:D1:0.2 D2P:12 D2:dropOutTwo0.3 acc:0.541354238986969\n",
      "OBJ:D1:0.2 D2P:12 D2:dropOutTwo0.5 acc:0.46603044867515564\n",
      "OBJ:D1:0.2 D2P:12 D2:dropOutTwo0.9 acc:0.24880708754062653\n",
      "OBJ:D1:0.3 D2P:8 D2:dropOutTwo0.1 acc:0.5387411713600159\n",
      "OBJ:D1:0.3 D2P:8 D2:dropOutTwo0.2 acc:0.5115882754325867\n",
      "OBJ:D1:0.3 D2P:8 D2:dropOutTwo0.3 acc:0.47193819284439087\n",
      "OBJ:D1:0.3 D2P:8 D2:dropOutTwo0.5 acc:0.3758236765861511\n",
      "OBJ:D1:0.3 D2P:8 D2:dropOutTwo0.9 acc:0.20574869215488434\n",
      "OBJ:D1:0.3 D2P:9 D2:dropOutTwo0.1 acc:0.5770279765129089\n",
      "OBJ:D1:0.3 D2P:9 D2:dropOutTwo0.2 acc:0.524426281452179\n",
      "OBJ:D1:0.3 D2P:9 D2:dropOutTwo0.3 acc:0.4794364869594574\n",
      "OBJ:D1:0.3 D2P:9 D2:dropOutTwo0.5 acc:0.40422630310058594\n",
      "OBJ:D1:0.3 D2P:9 D2:dropOutTwo0.9 acc:0.21461030840873718\n",
      "OBJ:D1:0.3 D2P:10 D2:dropOutTwo0.1 acc:0.5716882348060608\n",
      "OBJ:D1:0.3 D2P:10 D2:dropOutTwo0.2 acc:0.5444217324256897\n",
      "OBJ:D1:0.3 D2P:10 D2:dropOutTwo0.3 acc:0.4915928244590759\n",
      "OBJ:D1:0.3 D2P:10 D2:dropOutTwo0.5 acc:0.41376960277557373\n",
      "OBJ:D1:0.3 D2P:10 D2:dropOutTwo0.9 acc:0.21551920473575592\n",
      "OBJ:D1:0.3 D2P:11 D2:dropOutTwo0.1 acc:0.5746421217918396\n",
      "OBJ:D1:0.3 D2P:11 D2:dropOutTwo0.2 acc:0.5318109393119812\n",
      "OBJ:D1:0.3 D2P:11 D2:dropOutTwo0.3 acc:0.5137468576431274\n",
      "OBJ:D1:0.3 D2P:11 D2:dropOutTwo0.5 acc:0.42933425307273865\n",
      "OBJ:D1:0.3 D2P:11 D2:dropOutTwo0.9 acc:0.21006590127944946\n",
      "OBJ:D1:0.3 D2P:12 D2:dropOutTwo0.1 acc:0.6024767160415649\n",
      "OBJ:D1:0.3 D2P:12 D2:dropOutTwo0.2 acc:0.5599863529205322\n",
      "OBJ:D1:0.3 D2P:12 D2:dropOutTwo0.3 acc:0.4984094500541687\n",
      "OBJ:D1:0.3 D2P:12 D2:dropOutTwo0.5 acc:0.4350147545337677\n",
      "OBJ:D1:0.3 D2P:12 D2:dropOutTwo0.9 acc:0.2379004806280136\n",
      "OBJ:D1:0.5 D2P:8 D2:dropOutTwo0.1 acc:0.49625083804130554\n",
      "OBJ:D1:0.5 D2P:8 D2:dropOutTwo0.2 acc:0.4702340364456177\n",
      "OBJ:D1:0.5 D2P:8 D2:dropOutTwo0.3 acc:0.4256986975669861\n",
      "OBJ:D1:0.5 D2P:8 D2:dropOutTwo0.5 acc:0.36787092685699463\n",
      "OBJ:D1:0.5 D2P:8 D2:dropOutTwo0.9 acc:0.22415360808372498\n",
      "OBJ:D1:0.5 D2P:9 D2:dropOutTwo0.1 acc:0.5109066367149353\n",
      "OBJ:D1:0.5 D2P:9 D2:dropOutTwo0.2 acc:0.4870483875274658\n",
      "OBJ:D1:0.5 D2P:9 D2:dropOutTwo0.3 acc:0.45603272318840027\n",
      "OBJ:D1:0.5 D2P:9 D2:dropOutTwo0.5 acc:0.39468303322792053\n",
      "OBJ:D1:0.5 D2P:9 D2:dropOutTwo0.9 acc:0.23312883079051971\n",
      "OBJ:D1:0.5 D2P:10 D2:dropOutTwo0.1 acc:0.5185185074806213\n",
      "OBJ:D1:0.5 D2P:10 D2:dropOutTwo0.2 acc:0.47659623622894287\n",
      "OBJ:D1:0.5 D2P:10 D2:dropOutTwo0.3 acc:0.4527380168437958\n",
      "OBJ:D1:0.5 D2P:10 D2:dropOutTwo0.5 acc:0.3901385962963104\n",
      "OBJ:D1:0.5 D2P:10 D2:dropOutTwo0.9 acc:0.23858213424682617\n",
      "OBJ:D1:0.5 D2P:11 D2:dropOutTwo0.1 acc:0.5199954509735107\n",
      "OBJ:D1:0.5 D2P:11 D2:dropOutTwo0.2 acc:0.49579641222953796\n",
      "OBJ:D1:0.5 D2P:11 D2:dropOutTwo0.3 acc:0.46625766158103943\n",
      "OBJ:D1:0.5 D2P:11 D2:dropOutTwo0.5 acc:0.4060440957546234\n",
      "OBJ:D1:0.5 D2P:11 D2:dropOutTwo0.9 acc:0.23301522433757782\n",
      "OBJ:D1:0.5 D2P:12 D2:dropOutTwo0.1 acc:0.5371506214141846\n",
      "OBJ:D1:0.5 D2P:12 D2:dropOutTwo0.2 acc:0.49147921800613403\n",
      "OBJ:D1:0.5 D2P:12 D2:dropOutTwo0.3 acc:0.47523289918899536\n",
      "OBJ:D1:0.5 D2P:12 D2:dropOutTwo0.5 acc:0.39775049686431885\n",
      "OBJ:D1:0.5 D2P:12 D2:dropOutTwo0.9 acc:0.234719380736351\n",
      "OBJ:D1:0.9 D2P:8 D2:dropOutTwo0.1 acc:0.37389230728149414\n",
      "OBJ:D1:0.9 D2P:8 D2:dropOutTwo0.2 acc:0.3583276569843292\n",
      "OBJ:D1:0.9 D2P:8 D2:dropOutTwo0.3 acc:0.34378549456596375\n",
      "OBJ:D1:0.9 D2P:8 D2:dropOutTwo0.5 acc:0.3098159432411194\n",
      "OBJ:D1:0.9 D2P:8 D2:dropOutTwo0.9 acc:0.22301749885082245\n",
      "OBJ:D1:0.9 D2P:9 D2:dropOutTwo0.1 acc:0.37411952018737793\n",
      "OBJ:D1:0.9 D2P:9 D2:dropOutTwo0.2 acc:0.36582595109939575\n",
      "OBJ:D1:0.9 D2P:9 D2:dropOutTwo0.3 acc:0.34526243805885315\n",
      "OBJ:D1:0.9 D2P:9 D2:dropOutTwo0.5 acc:0.31651896238327026\n",
      "OBJ:D1:0.9 D2P:9 D2:dropOutTwo0.9 acc:0.19450125098228455\n",
      "OBJ:D1:0.9 D2P:10 D2:dropOutTwo0.1 acc:0.3887752890586853\n",
      "OBJ:D1:0.9 D2P:10 D2:dropOutTwo0.2 acc:0.36605316400527954\n",
      "OBJ:D1:0.9 D2P:10 D2:dropOutTwo0.3 acc:0.3525335192680359\n",
      "OBJ:D1:0.9 D2P:10 D2:dropOutTwo0.5 acc:0.32424449920654297\n",
      "OBJ:D1:0.9 D2P:10 D2:dropOutTwo0.9 acc:0.2158600389957428\n",
      "OBJ:D1:0.9 D2P:11 D2:dropOutTwo0.1 acc:0.38309475779533386\n",
      "OBJ:D1:0.9 D2P:11 D2:dropOutTwo0.2 acc:0.37366506457328796\n",
      "OBJ:D1:0.9 D2P:11 D2:dropOutTwo0.3 acc:0.35139739513397217\n",
      "OBJ:D1:0.9 D2P:11 D2:dropOutTwo0.5 acc:0.3219722807407379\n",
      "OBJ:D1:0.9 D2P:11 D2:dropOutTwo0.9 acc:0.19620540738105774\n",
      "OBJ:D1:0.9 D2P:12 D2:dropOutTwo0.1 acc:0.38161781430244446\n",
      "OBJ:D1:0.9 D2P:12 D2:dropOutTwo0.2 acc:0.36605316400527954\n",
      "OBJ:D1:0.9 D2P:12 D2:dropOutTwo0.3 acc:0.3619631826877594\n",
      "OBJ:D1:0.9 D2P:12 D2:dropOutTwo0.5 acc:0.3352647125720978\n",
      "OBJ:D1:0.9 D2P:12 D2:dropOutTwo0.9 acc:0.21313337981700897\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "#print(model.metrics['accuracy'])\n",
    "#print(model.loss_tracker.result().numpy())\n",
    "#print(str(model.metrics[1]))\n",
    "\n",
    "#print(keras.callbacks.History)\n",
    "#print(iterations)\n",
    "for obj in iterations:\n",
    "    #print(str(iterations[obj]))\n",
    "    #print(iterations[obj][len(iterations[obj]-1)])\n",
    "    #print(\"OBJ:\" + obj + \" acc:\"+  str(iterations[obj][0]))\n",
    "    #print(len(iterations[obj]))\n",
    "    #print(len(iterations[obj]))\n",
    "    print(\"OBJ:\" + obj + \" acc:\"+ str(iterations[obj][len(iterations[obj])-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec32eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e99964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
