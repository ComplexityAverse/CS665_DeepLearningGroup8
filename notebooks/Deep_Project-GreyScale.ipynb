{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6fc665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fe3b7585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.clear_all_output();\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.clear_all_output();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6ee08fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 3.8.8\n",
      "Tensorflow version 2.8.0\n",
      "Keras version 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "print(\"Python version %s.%s.%s\" % sys.version_info[:3])\n",
    "print(\"Tensorflow version %s\" % tf.__version__)\n",
    "print(\"Keras version %s\" % keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0414b",
   "metadata": {},
   "source": [
    "Import data from csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fd7c5709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0_0_20161219140623097.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_0_0_20161219140627985.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_0_0_20161219140642920.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_0_0_20161219154018476.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_0_0_20161219154556757.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               FILENAME  AGE\n",
       "0  1_0_0_20161219140623097.jpg.chip.jpg    1\n",
       "1  1_0_0_20161219140627985.jpg.chip.jpg    1\n",
       "2  1_0_0_20161219140642920.jpg.chip.jpg    1\n",
       "3  1_0_0_20161219154018476.jpg.chip.jpg    1\n",
       "4  1_0_0_20161219154556757.jpg.chip.jpg    1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#C:\\codebase\\preprocessed\\Unmodified>\n",
    "labels = pd.read_csv('C:\\\\codebase\\\\preprocessed\\\\Greyscale\\\\CSV Filenames DL SP22.csv')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d5db9c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0_0_20161219140623097.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_0_0_20161219140627985.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_0_0_20161219140642920.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_0_0_20161219154018476.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_0_0_20161219154556757.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9775</th>\n",
       "      <td>100_1_0_20170110183726390.jpg.chip.jpg</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9776</th>\n",
       "      <td>100_1_2_20170105174847679.jpg.chip.jpg</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9777</th>\n",
       "      <td>101_1_2_20170105174739309.jpg.chip.jpg</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9778</th>\n",
       "      <td>110_1_1_20170110155201038.jpg.chip.jpg</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9779</th>\n",
       "      <td>110_1_3_20170110155139762.jpg.chip.jpg</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9780 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    FILENAME  AGE\n",
       "0       1_0_0_20161219140623097.jpg.chip.jpg    1\n",
       "1       1_0_0_20161219140627985.jpg.chip.jpg    1\n",
       "2       1_0_0_20161219140642920.jpg.chip.jpg    1\n",
       "3       1_0_0_20161219154018476.jpg.chip.jpg    1\n",
       "4       1_0_0_20161219154556757.jpg.chip.jpg    1\n",
       "...                                      ...  ...\n",
       "9775  100_1_0_20170110183726390.jpg.chip.jpg  100\n",
       "9776  100_1_2_20170105174847679.jpg.chip.jpg  100\n",
       "9777  101_1_2_20170105174739309.jpg.chip.jpg  101\n",
       "9778  110_1_1_20170110155201038.jpg.chip.jpg  110\n",
       "9779  110_1_3_20170110155139762.jpg.chip.jpg  110\n",
       "\n",
       "[9780 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7712771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic number variables due to prior knowledge of dataset and algorithm needs\n",
    "\n",
    "label_1 = \"%s - %s\" %((labels[\"AGE\"][0]) , (labels[\"AGE\"][1870]))\n",
    "label_2 = \"%s - %s\" %((labels[\"AGE\"][1871]) , (labels[\"AGE\"][2786]))\n",
    "label_3 = \"%s - %s\" %((labels[\"AGE\"][2787]) , (labels[\"AGE\"][3821]))\n",
    "label_4 = \"%s - %s\" %((labels[\"AGE\"][3822]) , (labels[\"AGE\"][4980]))\n",
    "label_5 = \"%s - %s\" %((labels[\"AGE\"][4981]) , (labels[\"AGE\"][6027]))\n",
    "label_6 = \"%s - %s\" %((labels[\"AGE\"][6027]) , (labels[\"AGE\"][6939]))\n",
    "label_7 = \"%s - %s\" %((labels[\"AGE\"][6939]) , (labels[\"AGE\"][7980]))\n",
    "label_8 = \"%s - %s\" %((labels[\"AGE\"][7980]) , (labels[\"AGE\"][8833]))\n",
    "label_9 = \"%s - %s\" %((labels[\"AGE\"][8834]) , (labels[\"AGE\"][9779]))\n",
    "\n",
    "total_labels = [label_1,\n",
    "                label_2,\n",
    "                label_3,\n",
    "                label_4,\n",
    "                label_5,\n",
    "                label_6,\n",
    "                label_7,\n",
    "                label_8,\n",
    "                label_9]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9352d598",
   "metadata": {},
   "source": [
    "Code for the extracting the image and perform it to the numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "70a86fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "img_width = 224 #Magic number variables due to prior knowledge of dataset and algorithm needs\n",
    "\n",
    "def get_image(filename):\n",
    "    original = load_img(filename, target_size=(224, 224))\n",
    "    numpy_image = img_to_array(original)\n",
    "    return numpy_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ce9bd",
   "metadata": {},
   "source": [
    "testing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fe58ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "#image = get_image('C:\\\\codebase\\\\preprocessed\\\\Unmodified\\\\%s' % labels['FILENAME'][0])\n",
    "#print(image.shape)\n",
    "#plt.imshow(np.uint8(image))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "795719fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Magic number variables due to prior knowledge of dataset and algorithm needs\n",
    "num_train_images = 9780 \n",
    "split_point = 7000\n",
    "num_classes = 9\n",
    "arr = [i for i in range(num_classes)]\n",
    "num = 9778 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f75c0",
   "metadata": {},
   "source": [
    "function to perform labels from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cf809053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_num(num):\n",
    "    if (1 <= num <= 3):\n",
    "        return 0\n",
    "    if (4 <= num <= 8):\n",
    "        return 1\n",
    "    if (9 <= num <= 16):\n",
    "        return 2\n",
    "    if (17 <= num <= 25):\n",
    "        return 3\n",
    "    if (26 <= num <= 32):\n",
    "        return 4\n",
    "    if (33 <= num <= 42):\n",
    "        return 5\n",
    "    if (43 <= num <= 55):\n",
    "        return 6\n",
    "    if (56 <= num <= 66):\n",
    "        return 7\n",
    "    if (67 <= num <= 110):\n",
    "        return 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ebe0a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign_num(labels[\"AGE\"][9779])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5707c40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images loaded\n",
      "2000 images loaded\n",
      "3000 images loaded\n",
      "4000 images loaded\n",
      "5000 images loaded\n",
      "6000 images loaded\n",
      "7000 images loaded\n",
      "8000 images loaded\n",
      "9000 images loaded\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((num_train_images, img_width, img_width, 3), dtype=np.uint8)\n",
    "y = np.zeros((num_train_images, num_classes), dtype=np.uint8)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(num_train_images):\n",
    "    x[i] = get_image('C:\\\\codebase\\\\preprocessed\\\\Unmodified\\\\%s' % labels['FILENAME'][i])\n",
    "    y[i][assign_num(labels[\"AGE\"][i])] = 1\n",
    "    count += 1\n",
    "    if(count % 1000 == 0): print(count, 'images loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d2e3ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 9778 #Magic number variables due to prior knowledge of dataset and algorithm needs\n",
    "#print(\"orig : %d\" % labels[\"AGE\"][num])\n",
    "#print(y[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "83cb8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dbe82ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "933aedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e2a5a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "760ea601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f595e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "01f358bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet50 = resnet50.ResNet50(weights='imagenet', include_top=True)\n",
    "#pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b37a6a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_991\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_995 (InputLayer)         [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_995[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_992\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_994 (InputLayer)      [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import resnet50\n",
    "vgg16_model = vgg16.VGG16(weights='imagenet', include_top=True)\n",
    "resnet50 = resnet50.ResNet50(weights='imagenet', include_top=True)\n",
    "new_resnet50 = Model(inputs = resnet50.input, outputs = resnet50.get_layer('avg_pool').output)\n",
    "new_vgg16 = Model(inputs = vgg16_model.input, outputs = vgg16_model.get_layer('fc2').output)\n",
    "new_resnet50.summary()\n",
    "new_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "497d6d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(resnet50.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d67fd476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 3465s 6s/step\n",
      "612/612 [==============================] - 11883s 19s/step\n"
     ]
    }
   ],
   "source": [
    "resnet_predictions = new_resnet50.predict(x, batch_size=16, verbose=1)\n",
    "vgg16_predictions = new_vgg16.predict(x, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8f2ce1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "56d7d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg16_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9dc23a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = np.concatenate([resnet_predictions, vgg16_predictions],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f34eb2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "383f77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2a4afcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Activation, BatchNormalization\n",
    "\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "##     Hyperparameters\n",
    "dropOutOne = 0.7\n",
    "denseTwoPower = 9 # 9 = 512\n",
    "dropOutTwo = 0.3\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "#####################################################################################\n",
    "\n",
    "\n",
    "combined_inputs = Input(shape = (6144))\n",
    "x = Dropout(dropOutOne)(combined_inputs) # add a dropout layer\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(denseTwoPower)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(dropOutTwo)(x) # add a dropout layer\n",
    "# Softmax layer to the output classes\n",
    "new_predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "03afb07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_993\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_996 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_1978 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_1978 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_1978 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_1979 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_989 (Activation)  (None, 9)                0         \n",
      "                                                                 \n",
      " dropout_1979 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_1979 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "model = Model(inputs=combined_inputs, outputs=new_predictions) # specify what is network input, and what is network output\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "74e7702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e045c113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "69/69 [==============================] - 8s 60ms/step - loss: 2.0074 - accuracy: 0.2723 - val_loss: 1.7296 - val_accuracy: 0.3906\n",
      "Epoch 2/30\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 1.7919 - accuracy: 0.3621 - val_loss: 1.6432 - val_accuracy: 0.4550\n",
      "Epoch 3/30\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 1.7066 - accuracy: 0.3999 - val_loss: 1.5671 - val_accuracy: 0.4703\n",
      "Epoch 4/30\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 1.6317 - accuracy: 0.4098 - val_loss: 1.4882 - val_accuracy: 0.4867\n",
      "Epoch 5/30\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 1.5712 - accuracy: 0.4247 - val_loss: 1.4249 - val_accuracy: 0.5031\n",
      "Epoch 6/30\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 1.5084 - accuracy: 0.4414 - val_loss: 1.3717 - val_accuracy: 0.5082\n",
      "Epoch 7/30\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 1.4673 - accuracy: 0.4484 - val_loss: 1.3292 - val_accuracy: 0.5204\n",
      "Epoch 8/30\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 1.4486 - accuracy: 0.4463 - val_loss: 1.3008 - val_accuracy: 0.5276\n",
      "Epoch 9/30\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 1.4311 - accuracy: 0.4460 - val_loss: 1.2782 - val_accuracy: 0.5337\n",
      "Epoch 10/30\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 1.3957 - accuracy: 0.4554 - val_loss: 1.2584 - val_accuracy: 0.5440\n",
      "Epoch 11/30\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 1.3927 - accuracy: 0.4541 - val_loss: 1.2465 - val_accuracy: 0.5552\n",
      "Epoch 12/30\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 1.3840 - accuracy: 0.4593 - val_loss: 1.2355 - val_accuracy: 0.5470\n",
      "Epoch 13/30\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 1.3737 - accuracy: 0.4656 - val_loss: 1.2277 - val_accuracy: 0.5470\n",
      "Epoch 14/30\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 1.3563 - accuracy: 0.4639 - val_loss: 1.2152 - val_accuracy: 0.5552\n",
      "Epoch 15/30\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 1.3528 - accuracy: 0.4632 - val_loss: 1.2099 - val_accuracy: 0.5603\n",
      "Epoch 16/30\n",
      "69/69 [==============================] - 3s 44ms/step - loss: 1.3475 - accuracy: 0.4676 - val_loss: 1.2092 - val_accuracy: 0.5542\n",
      "Epoch 17/30\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 1.3381 - accuracy: 0.4684 - val_loss: 1.2002 - val_accuracy: 0.5644\n",
      "Epoch 18/30\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 1.3301 - accuracy: 0.4823 - val_loss: 1.1955 - val_accuracy: 0.5573\n",
      "Epoch 19/30\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 1.3152 - accuracy: 0.4841 - val_loss: 1.1924 - val_accuracy: 0.5644\n",
      "Epoch 20/30\n",
      "69/69 [==============================] - 4s 54ms/step - loss: 1.3281 - accuracy: 0.4772 - val_loss: 1.1917 - val_accuracy: 0.5593\n",
      "Epoch 21/30\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 1.3273 - accuracy: 0.4759 - val_loss: 1.1958 - val_accuracy: 0.5532\n",
      "Epoch 22/30\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 1.3330 - accuracy: 0.4792 - val_loss: 1.1921 - val_accuracy: 0.5481\n",
      "Epoch 23/30\n",
      "69/69 [==============================] - 4s 54ms/step - loss: 1.3268 - accuracy: 0.4728 - val_loss: 1.1873 - val_accuracy: 0.5450\n",
      "Epoch 24/30\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 1.3175 - accuracy: 0.4760 - val_loss: 1.1878 - val_accuracy: 0.5481\n",
      "Epoch 25/30\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 1.3031 - accuracy: 0.4827 - val_loss: 1.1831 - val_accuracy: 0.5593\n",
      "Epoch 26/30\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 1.3163 - accuracy: 0.4767 - val_loss: 1.1770 - val_accuracy: 0.5511\n",
      "Epoch 27/30\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 1.3145 - accuracy: 0.4753 - val_loss: 1.1777 - val_accuracy: 0.5521\n",
      "Epoch 28/30\n",
      "69/69 [==============================] - 4s 54ms/step - loss: 1.3083 - accuracy: 0.4856 - val_loss: 1.1760 - val_accuracy: 0.5613\n",
      "Epoch 29/30\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 1.3068 - accuracy: 0.4888 - val_loss: 1.1751 - val_accuracy: 0.5511\n",
      "Epoch 30/30\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 1.3018 - accuracy: 0.4735 - val_loss: 1.1761 - val_accuracy: 0.5665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17c191227c0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',  patience=6, verbose=1)\n",
    "# stop if loss does not improve for 3 iterations\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=30, \n",
    "              validation_data=(X_test, y_test), callbacks=[early_stop], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2d23f547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_994\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_997 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_1980 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_1980 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_1980 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_1981 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_990 (Activation)  (None, 8)                0         \n",
      "                                                                 \n",
      " dropout_1981 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_1981 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:8 D2:dropOutTwo0.1[0.35639628767967224, 0.45285162329673767, 0.49250170588493347, 0.5318109393119812, 0.5685071349143982, 0.5992956161499023, 0.62213134765625, 0.6391729116439819, 0.6555328369140625, 0.6695069074630737, 0.683140218257904, 0.6882526874542236, 0.7026811838150024, 0.7149511575698853]\n",
      "Model: \"model_995\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_998 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_1982 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_1982 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_1982 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_1983 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_991 (Activation)  (None, 8)                0         \n",
      "                                                                 \n",
      " dropout_1983 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_1983 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:8 D2:dropOutTwo0.2[0.2953874170780182, 0.4029766023159027, 0.4526244103908539, 0.49727335572242737, 0.5132924318313599, 0.5373778939247131, 0.544080913066864, 0.5613496899604797, 0.5652124285697937, 0.5831629037857056, 0.5877073407173157, 0.6011133790016174, 0.6039536595344543, 0.6183822154998779, 0.6307657361030579, 0.6395137310028076]\n",
      "Model: \"model_996\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_999 (InputLayer)      [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_1984 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_1984 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_1984 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_1985 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_992 (Activation)  (None, 8)                0         \n",
      "                                                                 \n",
      " dropout_1985 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_1985 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:8 D2:dropOutTwo0.3[0.31958645582199097, 0.401840478181839, 0.4381958544254303, 0.46273574233055115, 0.48784366250038147, 0.5005680322647095, 0.5189729332923889, 0.532833456993103, 0.5469211339950562, 0.5478300452232361, 0.5641899704933167, 0.5685071349143982, 0.5760054588317871, 0.5905476212501526, 0.5999772548675537, 0.5985003113746643, 0.610883891582489]\n",
      "Model: \"model_997\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1000 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_1986 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_1986 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_1986 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_1987 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_993 (Activation)  (None, 8)                0         \n",
      "                                                                 \n",
      " dropout_1987 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_1987 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:8 D2:dropOutTwo0.5[0.20449897646903992, 0.2765280604362488, 0.3520790636539459, 0.3907066583633423, 0.4044535458087921, 0.4235401153564453, 0.4271756410598755, 0.43262895941734314, 0.4384230971336365, 0.4456941485404968, 0.46103158593177795, 0.4653487801551819, 0.47205179929733276, 0.4701204299926758, 0.4667121171951294, 0.47386956214904785, 0.47977733612060547, 0.4810270369052887, 0.48523062467575073, 0.4793228805065155, 0.49613723158836365, 0.48988866806030273, 0.49431946873664856, 0.49420586228370667, 0.493410587310791, 0.5014769434928894, 0.49568280577659607, 0.5029538869857788]\n",
      "Model: \"model_998\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " input_1001 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_1988 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_1988 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_1988 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_1989 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_994 (Activation)  (None, 8)                0         \n",
      "                                                                 \n",
      " dropout_1989 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_1989 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:8 D2:dropOutTwo0.9[0.1918882131576538, 0.20915700495243073, 0.2158600389957428, 0.22483526170253754, 0.21688252687454224, 0.22040444612503052, 0.22608497738838196, 0.2240399867296219, 0.2252897024154663, 0.21972279250621796, 0.22154055535793304, 0.2255169302225113, 0.22722108662128448, 0.22733469307422638, 0.22960691154003143, 0.22733469307422638, 0.22722108662128448, 0.2301749587059021, 0.23142467439174652, 0.22563053667545319, 0.23119746148586273, 0.22812996804714203, 0.22744831442832947, 0.22506248950958252, 0.23040218651294708, 0.22790275514125824, 0.2318791151046753, 0.22790275514125824, 0.22744831442832947, 0.22937968373298645]\n",
      "Model: \"model_999\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1002 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_1990 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_1990 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_1990 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_1991 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_995 (Activation)  (None, 9)                0         \n",
      "                                                                 \n",
      " dropout_1991 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_1991 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:9 D2:dropOutTwo0.1[0.3443535566329956, 0.4397864043712616, 0.4917064309120178, 0.545216977596283, 0.5954328775405884, 0.6236082911491394, 0.6529197692871094, 0.6741649508476257, 0.6905248761177063, 0.704839825630188, 0.7215405702590942, 0.7265394330024719, 0.7355146408081055, 0.7400590777397156]\n",
      "Model: \"model_1000\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1003 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_1992 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_1992 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_1992 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_1993 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_996 (Activation)  (None, 9)                0         \n",
      "                                                                 \n",
      " dropout_1993 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_1993 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:9 D2:dropOutTwo0.2[0.33276528120040894, 0.4347875416278839, 0.46875709295272827, 0.4996591806411743, 0.5327198505401611, 0.5585094094276428, 0.5814587473869324, 0.6055442094802856, 0.6188366413116455, 0.6345148682594299, 0.6480345129966736, 0.6521245241165161, 0.6648489236831665, 0.6739377379417419, 0.6814360618591309, 0.6788229942321777]\n",
      "Model: \"model_1001\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1004 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_1994 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_1994 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_1994 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_1995 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_997 (Activation)  (None, 9)                0         \n",
      "                                                                 \n",
      " dropout_1995 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_1995 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:9 D2:dropOutTwo0.3[0.3202681243419647, 0.39286527037620544, 0.4242217540740967, 0.4829584062099457, 0.5035219192504883, 0.5210179686546326, 0.540558934211731, 0.5596455335617065, 0.5654397010803223, 0.5704385638237, 0.5856623649597168, 0.5905476212501526, 0.5853215456008911, 0.6038400530815125, 0.6038400530815125, 0.6188366413116455, 0.6157691478729248, 0.6148602366447449, 0.6262212991714478]\n",
      "Model: \"model_1002\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input_1005 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_1996 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_1996 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_1996 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_1997 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_998 (Activation)  (None, 9)                0         \n",
      "                                                                 \n",
      " dropout_1997 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_1997 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:9 D2:dropOutTwo0.5[0.25766870379447937, 0.3112928867340088, 0.33890023827552795, 0.35332879424095154, 0.3699159324169159, 0.3987730145454407, 0.4078618586063385, 0.41479209065437317, 0.4220631718635559, 0.43251532316207886, 0.4337650537490845, 0.45137467980384827, 0.45921382308006287, 0.4650079607963562, 0.47511929273605347, 0.4701204299926758, 0.4665985107421875, 0.48034536838531494, 0.4773915112018585, 0.4955691993236542, 0.49295613169670105, 0.49738696217536926, 0.48648035526275635]\n",
      "Model: \"model_1003\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1006 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_1998 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_1998 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_1998 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_1999 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_999 (Activation)  (None, 9)                0         \n",
      "                                                                 \n",
      " dropout_1999 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_1999 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:9 D2:dropOutTwo0.9[0.17848215997219086, 0.2017723172903061, 0.21540558338165283, 0.23051579296588898, 0.23528742790222168, 0.23540104925632477, 0.23710520565509796, 0.24403545260429382, 0.24210406839847565, 0.24096795916557312, 0.24392183125019073, 0.2460804432630539, 0.24869348108768463, 0.24994319677352905, 0.247670978307724, 0.25346511602401733, 0.25346511602401733, 0.247670978307724, 0.2511928975582123, 0.25323790311813354, 0.25198817253112793, 0.2553965151309967, 0.2538059651851654, 0.2525562345981598, 0.2559645473957062, 0.25812315940856934, 0.2573278844356537, 0.2555101215839386, 0.25607815384864807, 0.2590320408344269]\n",
      "Model: \"model_1004\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1007 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2000 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2000 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2000 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2001 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1000 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2001 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2001 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:10 D2:dropOutTwo0.1[0.3551465570926666, 0.4748920798301697, 0.5269256830215454, 0.5783912539482117, 0.6170188784599304, 0.6491706371307373, 0.6734833121299744, 0.6952965259552002, 0.7168825268745422, 0.7271074652671814, 0.7342649102210999, 0.7557373046875, 0.7600545287132263]\n",
      "Model: \"model_1005\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1008 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2002 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2002 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2002 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2003 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1001 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2003 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2003 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:10 D2:dropOutTwo0.2[0.3493524193763733, 0.44398999214172363, 0.48943421244621277, 0.5291979312896729, 0.5561236143112183, 0.5935014486312866, 0.6073619723320007, 0.6254260540008545, 0.6394001245498657, 0.6542831063270569, 0.6687116622924805, 0.6663258075714111, 0.6773460507392883, 0.6805271506309509]\n",
      "Model: \"model_1006\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1009 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2004 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2004 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2004 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2005 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1002 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2005 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2005 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:10 D2:dropOutTwo0.3[0.3302658498287201, 0.4267211854457855, 0.4678482115268707, 0.5045444369316101, 0.5237445831298828, 0.5435128211975098, 0.5672574639320374, 0.5777096152305603, 0.5880481600761414, 0.5936151146888733, 0.6032719612121582, 0.6084980964660645, 0.6196318864822388, 0.6169052720069885, 0.6337196230888367, 0.6332651376724243, 0.6421267986297607, 0.6389456987380981]\n",
      "Model: \"model_1007\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1010 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2006 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2006 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2006 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2007 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1003 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2007 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2007 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:10 D2:dropOutTwo0.5[0.275846391916275, 0.34662577509880066, 0.38809362053871155, 0.39150193333625793, 0.40752100944519043, 0.4301295280456543, 0.43876391649246216, 0.4409225285053253, 0.445921391248703, 0.45921382308006287, 0.463303804397583, 0.469893217086792, 0.48261758685112, 0.4805726110935211, 0.4915928244590759, 0.49625083804130554, 0.49272891879081726, 0.49466031789779663, 0.5074983239173889, 0.5192002058029175, 0.5171551704406738, 0.5251079201698303, 0.5211315751075745, 0.5203362703323364, 0.5248807072639465, 0.53476482629776, 0.538627564907074, 0.5360145568847656]\n",
      "Model: \"model_1008\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1011 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2008 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2008 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2008 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2009 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1004 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2009 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2009 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:10 D2:dropOutTwo0.9[0.1968870759010315, 0.21370142698287964, 0.22176778316497803, 0.2269938588142395, 0.22801636159420013, 0.23312883079051971, 0.22949329018592834, 0.22960691154003143]\n",
      "Model: \"model_1009\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1012 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2010 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2010 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2010 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2011 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1005 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2011 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2011 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:11 D2:dropOutTwo0.1[0.38968417048454285, 0.484548956155777, 0.5382867455482483, 0.5808907151222229, 0.6265621185302734, 0.660758912563324, 0.6809815764427185, 0.7069984078407288, 0.7215405702590942, 0.7379004955291748, 0.7523289918899536, 0.7586911916732788, 0.7701658606529236]\n",
      "Model: \"model_1010\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " input_1013 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2012 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2012 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2012 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2013 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1006 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2013 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2013 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:11 D2:dropOutTwo0.2[0.3459441065788269, 0.4535332918167114, 0.5031810998916626, 0.547034740447998, 0.5768007040023804, 0.6039536595344543, 0.6309929490089417, 0.6459895372390747, 0.6551920175552368, 0.6672347187995911, 0.6833674311637878, 0.6925698518753052, 0.70404452085495, 0.713360607624054]\n",
      "Model: \"model_1011\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1014 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2014 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2014 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2014 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2015 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1007 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2015 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2015 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:11 D2:dropOutTwo0.3[0.23755964636802673, 0.3790047764778137, 0.4745512306690216, 0.5005680322647095, 0.5276073813438416, 0.5472620129585266, 0.5720291137695312, 0.5890706777572632, 0.6039536595344543, 0.608952522277832, 0.6296296119689941, 0.6276982426643372, 0.6350829601287842, 0.6416723728179932, 0.6512156128883362]\n",
      "Model: \"model_1012\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1015 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2016 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2016 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2016 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2017 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1008 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2017 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2017 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:11 D2:dropOutTwo0.5[0.27357417345046997, 0.35935014486312866, 0.3947966396808624, 0.4239945411682129, 0.43887752294540405, 0.4559191167354584, 0.46523517370224, 0.48000454902648926, 0.48261758685112, 0.4920472502708435, 0.5022721886634827, 0.5086343884468079, 0.5051124691963196, 0.5173823833465576, 0.524426281452179, 0.5241990685462952, 0.537491500377655, 0.5312429070472717, 0.5414678454399109, 0.5476028323173523, 0.5476028323173523, 0.5390820503234863, 0.5431720018386841, 0.5515791773796082, 0.5501022338867188, 0.5466939210891724]\n",
      "Model: \"model_1013\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1016 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2018 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2018 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2018 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2019 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1009 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2019 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2019 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:11 D2:dropOutTwo0.9[0.14246761798858643, 0.1714383065700531, 0.19143377244472504, 0.199954554438591, 0.20768007636070251, 0.2062031328678131, 0.210974782705307, 0.20836172997951508, 0.20756645500659943, 0.2110883891582489, 0.21199727058410645, 0.212906152009964, 0.21347421407699585, 0.22347193956375122, 0.22892524302005768, 0.23097023367881775, 0.2335832715034485, 0.2319927215576172, 0.23085662722587585, 0.23312883079051971, 0.23221994936466217, 0.23915019631385803, 0.23153828084468842, 0.24164962768554688, 0.23381049931049347, 0.23687797784805298, 0.23767325282096863, 0.2382413148880005, 0.23608270287513733, 0.23608270287513733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1014\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1017 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2020 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2020 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2020 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2021 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1010 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2021 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2021 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:12 D2:dropOutTwo0.1[0.36241763830184937, 0.44217222929000854, 0.5209043622016907, 0.588388979434967, 0.6339468359947205, 0.6623494625091553, 0.690865695476532, 0.7147239446640015, 0.7309702634811401, 0.7498295903205872, 0.7599409222602844, 0.7655078172683716, 0.7786866426467896]\n",
      "Model: \"model_1015\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1018 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2022 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2022 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2022 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2023 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1011 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2023 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2023 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:12 D2:dropOutTwo0.2[0.30220404267311096, 0.44376277923583984, 0.5004544258117676, 0.5507839322090149, 0.5886162519454956, 0.6119064092636108, 0.6382640600204468, 0.6497386693954468, 0.6746193766593933, 0.6857532262802124, 0.702113151550293, 0.7164281010627747, 0.7184730768203735, 0.7224494218826294, 0.728357195854187]\n",
      "Model: \"model_1016\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1019 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2024 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2024 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2024 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2025 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1012 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2025 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2025 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:12 D2:dropOutTwo0.3[0.29266077280044556, 0.42444899678230286, 0.4667121171951294, 0.508520781993866, 0.5389684438705444, 0.5618041157722473, 0.5814587473869324, 0.5942967534065247, 0.6162235736846924, 0.627811849117279, 0.6323562860488892, 0.6462167501449585, 0.650306761264801, 0.6633719801902771, 0.6696205139160156, 0.6715519428253174, 0.6815496683120728]\n",
      "Model: \"model_1017\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1020 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2026 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2026 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2026 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2027 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1013 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2027 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2027 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:12 D2:dropOutTwo0.5[0.2857305109500885, 0.36434900760650635, 0.4095660150051117, 0.4225175976753235, 0.45035219192504883, 0.4619404673576355, 0.4839809238910675, 0.48000454902648926, 0.488752543926239, 0.5054532885551453, 0.5124971866607666, 0.5182912945747375, 0.5285162329673767, 0.5293115377426147, 0.528175413608551, 0.5474892258644104, 0.5451033711433411, 0.5393092632293701, 0.5486252903938293, 0.5471483469009399]\n",
      "Model: \"model_1018\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1021 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2028 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2028 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2028 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2029 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1014 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2029 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2029 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.1 D2P:12 D2:dropOutTwo0.9[0.17564189434051514, 0.20120427012443542, 0.22006362676620483, 0.2255169302225113, 0.2333560585975647, 0.23619632422924042, 0.23244717717170715, 0.2414223998785019, 0.24176323413848877, 0.24255850911140442, 0.24176323413848877, 0.2458532154560089, 0.24630765616893768, 0.24812541902065277, 0.24562598764896393, 0.24653488397598267, 0.25039762258529663, 0.2507384717464447, 0.2521018087863922, 0.25164735317230225, 0.2555101215839386, 0.2569870352745056, 0.2568734288215637, 0.2511928975582123, 0.25619176030158997, 0.25460124015808105, 0.2616450786590576, 0.25766870379447937, 0.25812315940856934, 0.25505566596984863]\n",
      "Model: \"model_1019\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1022 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2030 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2030 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2030 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2031 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1015 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2031 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2031 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:8 D2:dropOutTwo0.1[0.3362872004508972, 0.44683027267456055, 0.48477619886398315, 0.5003408193588257, 0.526244044303894, 0.5456714630126953, 0.5703248977661133, 0.5869120359420776, 0.6041808724403381, 0.6286071538925171, 0.6457623243331909, 0.6461031436920166, 0.6540558934211731, 0.661554217338562, 0.6687116622924805, 0.678595781326294, 0.6779140830039978]\n",
      "Model: \"model_1020\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1023 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2032 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2032 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2032 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2033 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1016 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2033 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2033 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:8 D2:dropOutTwo0.2[0.27096113562583923, 0.3804817199707031, 0.4319472908973694, 0.469893217086792, 0.5032947063446045, 0.5248807072639465, 0.5513519644737244, 0.5581685900688171, 0.5707793831825256, 0.5720291137695312, 0.5916836857795715, 0.5965689420700073, 0.6069075465202332, 0.6167916655540466, 0.6172460913658142, 0.6276982426643372, 0.6263349056243896, 0.6299704909324646]\n",
      "Model: \"model_1021\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1024 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2034 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2034 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2034 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2035 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1017 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2035 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2035 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:8 D2:dropOutTwo0.3[0.27391502261161804, 0.3853669762611389, 0.443194717168808, 0.46137240529060364, 0.47557371854782104, 0.4987502694129944, 0.5115882754325867, 0.5130652189254761, 0.5271528959274292, 0.5270392894744873, 0.5399909019470215, 0.5427175760269165, 0.5544194579124451, 0.5546466708183289, 0.5555555820465088, 0.5649852156639099, 0.5704385638237, 0.5803226828575134, 0.578845739364624, 0.5802090167999268, 0.5770279765129089, 0.589297890663147, 0.5806635022163391, 0.582708477973938, 0.5904340147972107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1022\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1025 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2036 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2036 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2036 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2037 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1018 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2037 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2037 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:8 D2:dropOutTwo0.5[0.2573278844356537, 0.3043626546859741, 0.3476482629776001, 0.36764371395111084, 0.3857077956199646, 0.40263575315475464, 0.4034310281276703, 0.406498521566391, 0.4185412526130676, 0.4209270477294922, 0.42263123393058777, 0.4364916980266571, 0.4349011480808258, 0.441263347864151, 0.4521699547767639, 0.4446716606616974, 0.4456941485404968, 0.44717109203338623, 0.45944103598594666, 0.44830721616744995, 0.45466938614845276, 0.45330607891082764, 0.4536468982696533, 0.4622812867164612, 0.4729606807231903, 0.463303804397583, 0.4618268609046936, 0.4639854431152344, 0.46762099862098694, 0.4669393301010132]\n",
      "Model: \"model_1023\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1026 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2038 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2038 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2038 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2039 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1019 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2039 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2039 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:8 D2:dropOutTwo0.9[0.15985003113746643, 0.1840490847826004, 0.19416041672229767, 0.1966598480939865, 0.20188593864440918, 0.20586229860782623, 0.2046125829219818, 0.20540785789489746]\n",
      "Model: \"model_1024\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1027 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2040 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2040 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2040 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2041 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1020 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2041 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2041 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:9 D2:dropOutTwo0.1[0.38661667704582214, 0.46091797947883606, 0.49886390566825867, 0.532833456993103, 0.5655533075332642, 0.6003181338310242, 0.6255396604537964, 0.6491706371307373, 0.6605316996574402, 0.671097457408905, 0.6890479326248169, 0.6983640193939209, 0.6988184452056885, 0.7057486772537231]\n",
      "Model: \"model_1025\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1028 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2042 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2042 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2042 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2043 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1021 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2043 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2043 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:9 D2:dropOutTwo0.2[0.32265394926071167, 0.4255850911140442, 0.47534650564193726, 0.5107930302619934, 0.5436264276504517, 0.5520336031913757, 0.5747557282447815, 0.5797545909881592, 0.5973642468452454, 0.6077027916908264, 0.6220177412033081, 0.6290615797042847, 0.6319018602371216, 0.6367871165275574, 0.6449670791625977, 0.6508747935295105, 0.6521245241165161, 0.6574642062187195, 0.6563280820846558, 0.6590547561645508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1026\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1029 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2044 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2044 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2044 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2045 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1022 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2045 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2045 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:9 D2:dropOutTwo0.3[0.3269711434841156, 0.3837764263153076, 0.41161099076271057, 0.4426266849040985, 0.4670529365539551, 0.4998863935470581, 0.512269914150238, 0.5205634832382202, 0.5373778939247131, 0.5462394952774048, 0.5530561208724976, 0.561008870601654, 0.5670301914215088, 0.5650988221168518, 0.5866848230361938, 0.5802090167999268, 0.5872529149055481, 0.595887303352356]\n",
      "Model: \"model_1027\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1030 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2046 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2046 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2046 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2047 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1023 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2047 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2047 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:9 D2:dropOutTwo0.5[0.23710520565509796, 0.31651896238327026, 0.3584412634372711, 0.3745739459991455, 0.3909338712692261, 0.393774151802063, 0.39297887682914734, 0.4100204408168793, 0.4162690341472626, 0.4287661910057068, 0.4337650537490845, 0.43853670358657837, 0.44683027267456055, 0.44660302996635437, 0.44671666622161865, 0.4542149603366852, 0.45137467980384827, 0.46148601174354553, 0.4585321545600891, 0.45637354254722595, 0.4631901979446411, 0.4653487801551819, 0.4761417806148529, 0.47409680485725403, 0.4730742871761322, 0.4670529365539551, 0.4747784733772278, 0.4777323305606842, 0.48193591833114624]\n",
      "Model: \"model_1028\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1031 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2048 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2048 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2048 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2049 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1024 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2049 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2049 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:9 D2:dropOutTwo0.9[0.15519200265407562, 0.16643944382667542, 0.17961826920509338, 0.18507157266139984, 0.19563736021518707, 0.1922290325164795, 0.19756872951984406, 0.2160872519016266, 0.217336967587471, 0.21779140830039978, 0.21858668327331543, 0.21847307682037354, 0.22426721453666687, 0.22108611464500427, 0.22085890173912048, 0.22142694890499115, 0.223699152469635, 0.22790275514125824, 0.22517609596252441, 0.22279027104377747, 0.22653941810131073, 0.23221994936466217, 0.22767552733421326, 0.23221994936466217, 0.22937968373298645, 0.22733469307422638, 0.2286980301141739, 0.230288565158844, 0.23119746148586273, 0.23233355581760406]\n",
      "Model: \"model_1029\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1032 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2050 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2050 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2050 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2051 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1025 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2051 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2051 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:10 D2:dropOutTwo0.1[0.23926380276679993, 0.43126562237739563, 0.5012497305870056, 0.5438536405563354, 0.571461021900177, 0.6098613739013672, 0.6282662749290466, 0.6394001245498657, 0.6516700983047485, 0.6665530800819397, 0.6783685684204102, 0.6817768812179565, 0.7014315128326416, 0.7005226016044617, 0.7063167691230774]\n",
      "Model: \"model_1030\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1033 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2052 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2052 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2052 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2053 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1026 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2053 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2053 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:10 D2:dropOutTwo0.2[0.37695977091789246, 0.45921382308006287, 0.49409225583076477, 0.5130652189254761, 0.5399909019470215, 0.5568052530288696, 0.5797545909881592, 0.5927062034606934, 0.6022495031356812, 0.6138377785682678, 0.6207680106163025, 0.6294023990631104, 0.6345148682594299, 0.6432629227638245, 0.6486026048660278]\n",
      "Model: \"model_1031\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1034 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2054 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2054 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2054 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2055 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1027 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2055 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2055 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:10 D2:dropOutTwo0.3[0.34492161870002747, 0.4222903847694397, 0.4685298800468445, 0.4909111559391022, 0.5078391432762146, 0.5218132138252258, 0.5381731390953064, 0.5522608757019043, 0.5465803146362305, 0.5594183206558228, 0.5728243589401245, 0.5779368281364441, 0.58736652135849, 0.593047022819519, 0.5906612277030945, 0.6083844304084778, 0.6033855676651001, 0.607021152973175, 0.6148602366447449, 0.60429447889328]\n",
      "Model: \"model_1032\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1035 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2056 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2056 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2056 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2057 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1028 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2057 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2057 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:10 D2:dropOutTwo0.5[0.23755964636802673, 0.33072030544281006, 0.3712792694568634, 0.40263575315475464, 0.40718019008636475, 0.4237673282623291, 0.4362644851207733, 0.4429675042629242, 0.4542149603366852, 0.46750739216804504, 0.46466711163520813, 0.46750739216804504, 0.46921154856681824, 0.47534650564193726, 0.47989094257354736, 0.4909111559391022, 0.4859122931957245, 0.4859122931957245, 0.4885253310203552, 0.4915928244590759, 0.49250170588493347, 0.5005680322647095, 0.5024994611740112, 0.5054532885551453, 0.5059077739715576, 0.5067030191421509, 0.5142013430595398, 0.510452151298523, 0.5153374075889587, 0.5155646204948425]\n",
      "Model: \"model_1033\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1036 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2058 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2058 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2058 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2059 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1029 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2059 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_2059 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:10 D2:dropOutTwo0.9[0.17030219733715057, 0.1807543784379959, 0.18007270991802216, 0.1951829195022583, 0.2047262042760849, 0.2079072892665863, 0.20688480138778687, 0.20995227992534637, 0.20722563564777374, 0.217564195394516, 0.22142694890499115, 0.21949556469917297, 0.21801863610744476, 0.21301977336406708, 0.21972279250621796, 0.223699152469635, 0.22483526170253754, 0.21813224256038666, 0.22108611464500427, 0.22267666459083557, 0.22097250819206238, 0.22176778316497803, 0.22460804879665375, 0.22279027104377747, 0.22313110530376434, 0.22301749885082245, 0.22256305813789368, 0.22892524302005768, 0.22563053667545319, 0.22472165524959564]\n",
      "Model: \"model_1034\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1037 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2060 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2060 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2060 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2061 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1030 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2061 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2061 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:11 D2:dropOutTwo0.1[0.38979777693748474, 0.4873892366886139, 0.5306748747825623, 0.5680527091026306, 0.5979322791099548, 0.6225857734680176, 0.6382640600204468, 0.663485586643219, 0.6780277490615845, 0.6852988004684448, 0.6879118084907532, 0.700181782245636]\n",
      "Model: \"model_1035\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1038 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2062 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2062 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2062 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2063 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1031 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2063 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2063 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:11 D2:dropOutTwo0.2[0.3123153746128082, 0.4569416046142578, 0.4923880994319916, 0.529084324836731, 0.5566916465759277, 0.563849151134491, 0.5797545909881592, 0.5999772548675537, 0.6145194172859192, 0.623153805732727, 0.6317882537841797, 0.6356509923934937, 0.6545103192329407, 0.6587139368057251]\n",
      "Model: \"model_1036\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1039 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2064 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2064 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2064 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2065 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1032 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2065 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2065 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:11 D2:dropOutTwo0.3[0.321858674287796, 0.4336514472961426, 0.47205179929733276, 0.49920472502708435, 0.5111338496208191, 0.538627564907074, 0.5476028323173523, 0.565666913986206, 0.5786184668540955, 0.584639847278595, 0.5895251035690308, 0.5990684032440186, 0.6002045273780823, 0.6105430722236633, 0.6228129863739014, 0.6238355040550232, 0.635310173034668, 0.6369007229804993, 0.6320154666900635, 0.6339468359947205, 0.6384912729263306, 0.6395137310028076]\n",
      "Model: \"model_1037\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1040 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2066 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2066 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2066 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2067 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1033 (Activation  (None, 11)               0         \n",
      " )                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dropout_2067 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2067 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:11 D2:dropOutTwo0.5[0.26244035363197327, 0.33549192547798157, 0.3780958950519562, 0.3969552516937256, 0.4158145785331726, 0.4289934039115906, 0.43910473585128784, 0.45785048604011536, 0.4568279981613159, 0.46603044867515564, 0.4715973734855652, 0.4861395061016083, 0.48682117462158203, 0.4904567003250122, 0.4985230565071106, 0.5048852562904358, 0.505794107913971, 0.5090888142585754, 0.5205634832382202, 0.510452151298523, 0.5101113319396973, 0.5203362703323364]\n",
      "Model: \"model_1038\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1041 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2068 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2068 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2068 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2069 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1034 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2069 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2069 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:11 D2:dropOutTwo0.9[0.18302658200263977, 0.20983867347240448, 0.23381049931049347, 0.24039991199970245, 0.24733015894889832, 0.25028401613235474, 0.24960236251354218, 0.24539877474308014, 0.24801181256771088, 0.24698932468891144, 0.252329021692276, 0.24880708754062653, 0.25505566596984863, 0.2505112588405609, 0.2526698410511017, 0.2540331780910492, 0.25198817253112793, 0.25789594650268555, 0.2528970539569855, 0.25937286019325256, 0.2555101215839386, 0.258463978767395, 0.2551692724227905, 0.25607815384864807, 0.258918434381485, 0.2574414908885956, 0.25789594650268555, 0.2574414908885956, 0.2569870352745056, 0.25630539655685425]\n",
      "Model: \"model_1039\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1042 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2070 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2070 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2070 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2071 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1035 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2071 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2071 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:12 D2:dropOutTwo0.1[0.3684389889240265, 0.48023176193237305, 0.5415814518928528, 0.5837309956550598, 0.6074755787849426, 0.6341740489006042, 0.6559872627258301, 0.6754146814346313, 0.6921154260635376, 0.7012042999267578, 0.7164281010627747, 0.7206316590309143, 0.7331288456916809, 0.7409679889678955]\n",
      "Model: \"model_1040\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1043 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2072 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2072 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2072 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2073 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1036 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2073 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2073 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:12 D2:dropOutTwo0.2[0.3536696135997772, 0.4700068235397339, 0.5193138122558594, 0.553624153137207, 0.5743013024330139, 0.6009997725486755, 0.6165643930435181, 0.629743218421936, 0.6329243183135986, 0.6492842435836792, 0.6662122011184692, 0.6731424927711487, 0.6740513443946838, 0.6800727248191833]\n",
      "Model: \"model_1041\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1044 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2074 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2074 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2074 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2075 (B  (None, 12)               48        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1037 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2075 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2075 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:12 D2:dropOutTwo0.3[0.3029993176460266, 0.4204726219177246, 0.46478071808815, 0.5006816387176514, 0.5241990685462952, 0.5472620129585266, 0.564871609210968, 0.5808907151222229, 0.5957736968994141, 0.6067939400672913, 0.6119064092636108, 0.6187230348587036, 0.6251988410949707, 0.6257668733596802, 0.6384912729263306, 0.6479209065437317, 0.6525789499282837, 0.6453078985214233]\n",
      "Model: \"model_1042\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1045 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2076 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2076 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2076 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2077 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1038 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2077 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2077 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:12 D2:dropOutTwo0.5[0.2980004549026489, 0.36934787034988403, 0.40740740299224854, 0.4224039912223816, 0.44080889225006104, 0.45182913541793823, 0.4648943543434143, 0.47864121198654175, 0.4810270369052887, 0.4877300560474396, 0.4922744929790497, 0.49579641222953796, 0.5096569061279297, 0.5094296932220459, 0.5123835206031799, 0.5134060382843018, 0.5238581895828247, 0.5136332511901855, 0.5196546316146851, 0.5253351330757141, 0.5273801684379578, 0.5327198505401611, 0.5304476022720337, 0.5336287021636963]\n",
      "Model: \"model_1043\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1046 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2078 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2078 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2078 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2079 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1039 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2079 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2079 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.2 D2P:12 D2:dropOutTwo0.9[0.18961599469184875, 0.22006362676620483, 0.22119972109794617, 0.23153828084468842, 0.23721881210803986, 0.23687797784805298, 0.23608270287513733, 0.2505112588405609, 0.25187456607818604, 0.2526698410511017, 0.25346511602401733, 0.2557373344898224, 0.2591456472873688, 0.2553965151309967, 0.26096341013908386, 0.25982731580734253, 0.26141786575317383, 0.2568734288215637, 0.2618722915649414, 0.2573278844356537, 0.2615314722061157, 0.2666439414024353, 0.2638036906719208, 0.26596227288246155, 0.25971370935440063, 0.2634628415107727, 0.25960010290145874, 0.2648261785507202, 0.26573505997657776, 0.2649397850036621]\n",
      "Model: \"model_1044\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1047 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2080 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2080 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2080 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2081 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1040 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2081 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2081 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:8 D2:dropOutTwo0.1[0.2902749478816986, 0.4462622106075287, 0.4954555928707123, 0.5192002058029175, 0.5494205951690674, 0.5678254961967468, 0.5813451409339905, 0.6034992337226868, 0.6113383173942566, 0.6124744415283203, 0.6350829601287842, 0.6380367875099182, 0.6339468359947205, 0.6395137310028076, 0.6556464433670044, 0.6613269448280334, 0.6536014676094055, 0.658032238483429]\n",
      "Model: \"model_1045\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1048 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2082 (Dropout)      (None, 6144)              0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " batch_normalization_2082 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2082 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2083 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1041 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2083 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2083 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:8 D2:dropOutTwo0.2[0.2141558676958084, 0.3508293628692627, 0.410702109336853, 0.43899112939834595, 0.471824586391449, 0.487275630235672, 0.5026130676269531, 0.5162463188171387, 0.5343104004859924, 0.538627564907074, 0.5477164387702942, 0.5574869513511658, 0.5627130270004272, 0.5669165849685669, 0.5687344074249268, 0.5735059976577759, 0.5841854214668274, 0.5895251035690308, 0.593047022819519, 0.58736652135849, 0.5890706777572632, 0.6074755787849426]\n",
      "Model: \"model_1046\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1049 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2084 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2084 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2084 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2085 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1042 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2085 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2085 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:8 D2:dropOutTwo0.3[0.31970006227493286, 0.3907066583633423, 0.42160871624946594, 0.44183140993118286, 0.45126107335090637, 0.4684162735939026, 0.4745512306690216, 0.4860258996486664, 0.49897751212120056, 0.495341956615448, 0.4985230565071106, 0.5105657577514648, 0.5077255368232727, 0.5198818445205688, 0.5204498767852783, 0.5255623459815979, 0.5271528959274292, 0.5296523571014404, 0.5199954509735107, 0.5399909019470215, 0.5352192521095276]\n",
      "Model: \"model_1047\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1050 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2086 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2086 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2086 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2087 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1043 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2087 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2087 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:8 D2:dropOutTwo0.5[0.28141331672668457, 0.32129061222076416, 0.34196773171424866, 0.37252897024154663, 0.3792319893836975, 0.3886616826057434, 0.39411497116088867, 0.4092251658439636, 0.40740740299224854, 0.41660985350608826, 0.42444899678230286, 0.42626675963401794, 0.4376278221607208, 0.42467620968818665, 0.42660757899284363, 0.43069756031036377, 0.44035446643829346, 0.44035446643829346, 0.4430811107158661, 0.4425130784511566, 0.4476255476474762, 0.44694387912750244, 0.45148828625679016, 0.4446716606616974, 0.4460349977016449, 0.45762327313423157, 0.4575096666812897, 0.4551238417625427, 0.45773687958717346, 0.45171552896499634]\n",
      "Model: \"model_1048\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1051 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2088 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2088 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2088 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2089 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1044 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2089 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2089 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:8 D2:dropOutTwo0.9[0.17246080935001373, 0.20449897646903992, 0.20915700495243073, 0.21563281118869781, 0.21392865478992462, 0.21688252687454224, 0.21688252687454224, 0.21676892042160034, 0.22313110530376434, 0.2271074801683426, 0.2284708023071289, 0.22722108662128448, 0.2286980301141739, 0.22960691154003143, 0.22926607728004456, 0.23062939941883087, 0.23119746148586273, 0.22903884947299957, 0.23131106793880463, 0.23426494002342224, 0.23369689285755157, 0.23733241856098175, 0.2365371435880661, 0.234946608543396, 0.23437854647636414, 0.23744603991508484, 0.23596909642219543, 0.23562826216220856, 0.23676437139511108, 0.23858213424682617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1049\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1052 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2090 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2090 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2090 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2091 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1045 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2091 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2091 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:9 D2:dropOutTwo0.1[0.2668711543083191, 0.3822994828224182, 0.4686434864997864, 0.5184049010276794, 0.5423767566680908, 0.5702112913131714, 0.5894114971160889, 0.6004317402839661, 0.6191774606704712, 0.6357645988464355, 0.6326971054077148, 0.6505339741706848, 0.6455351114273071, 0.6562144756317139, 0.6542831063270569, 0.6678027510643005]\n",
      "Model: \"model_1050\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1053 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2092 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2092 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2092 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2093 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1046 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2093 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2093 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:9 D2:dropOutTwo0.2[0.33083391189575195, 0.3938877582550049, 0.4336514472961426, 0.4825039803981781, 0.498068630695343, 0.5277209877967834, 0.5426039695739746, 0.559191107749939, 0.5647580027580261, 0.5790729522705078, 0.5813451409339905, 0.5838446021080017, 0.5894114971160889, 0.5962281227111816, 0.6031583547592163, 0.6078163981437683, 0.6142922043800354, 0.6103158593177795, 0.6157691478729248, 0.6211088299751282]\n",
      "Model: \"model_1051\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1054 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2094 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2094 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2094 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2095 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1047 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2095 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2095 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:9 D2:dropOutTwo0.3[0.29266077280044556, 0.38309475779533386, 0.42467620968818665, 0.4444444477558136, 0.471824586391449, 0.4888661801815033, 0.5062485933303833, 0.5241990685462952, 0.528175413608551, 0.5344240069389343, 0.5435128211975098, 0.5387411713600159, 0.5458986759185791, 0.5497614145278931, 0.5574869513511658, 0.556464433670044, 0.5600999593734741, 0.5683935284614563, 0.5718018412590027, 0.5697568655014038, 0.5774824023246765, 0.5699840784072876, 0.5795273780822754, 0.5735059976577759, 0.5795273780822754, 0.5762326717376709, 0.5821404457092285]\n",
      "Model: \"model_1052\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1055 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2096 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2096 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2096 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2097 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1048 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2097 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2097 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:9 D2:dropOutTwo0.5[0.27050670981407166, 0.32004091143608093, 0.3583276569843292, 0.38786640763282776, 0.4078618586063385, 0.4186548590660095, 0.4345603287220001, 0.4352419972419739, 0.43887752294540405, 0.434673935174942, 0.44546693563461304, 0.45614632964134216, 0.4601227045059204, 0.4638718366622925, 0.46580323576927185, 0.46409907937049866, 0.46750739216804504, 0.469893217086792, 0.46750739216804504, 0.4796636998653412, 0.4726198613643646, 0.4812542498111725, 0.47989094257354736, 0.4838673174381256, 0.4853442311286926, 0.48988866806030273, 0.4907975494861603, 0.5076119303703308, 0.4889797866344452, 0.4843217432498932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1053\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1056 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2098 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2098 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2098 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2099 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1049 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2099 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2099 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:9 D2:dropOutTwo0.9[0.16916610300540924, 0.1730288565158844, 0.18677572906017303, 0.2049534171819687, 0.21211087703704834, 0.2157464176416397, 0.2189275175333023, 0.21960918605327606, 0.21926835179328918, 0.21813224256038666, 0.21983639895915985, 0.22188138961791992, 0.22199499607086182, 0.21790501475334167, 0.22006362676620483, 0.22722108662128448, 0.22290389239788055, 0.22506248950958252, 0.22154055535793304, 0.2222222238779068, 0.22574414312839508, 0.2222222238779068, 0.22517609596252441, 0.2255169302225113, 0.22778913378715515, 0.2224494367837906, 0.22756192088127136, 0.22017723321914673, 0.22199499607086182, 0.2267666459083557]\n",
      "Model: \"model_1054\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1057 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2100 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2100 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2100 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2101 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1050 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2101 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2101 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:10 D2:dropOutTwo0.1[0.3583276569843292, 0.4634174108505249, 0.5139740705490112, 0.5507839322090149, 0.5772551894187927, 0.5960009098052979, 0.6078163981437683, 0.627811849117279, 0.6354237794876099, 0.634401261806488, 0.6506475806236267, 0.6630311012268066, 0.6696205139160156, 0.6709838509559631]\n",
      "Model: \"model_1055\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1058 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2102 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2102 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2102 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2103 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1051 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2103 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2103 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:10 D2:dropOutTwo0.2[0.35628265142440796, 0.44364917278289795, 0.4843217432498932, 0.5109066367149353, 0.5369234085083008, 0.5496478080749512, 0.5673710703849792, 0.584639847278595, 0.592024564743042, 0.6017950177192688, 0.6057714223861694, 0.6153147220611572, 0.6304249167442322, 0.6244035363197327, 0.6214496493339539, 0.6309929490089417, 0.6378095746040344]\n",
      "Model: \"model_1056\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1059 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2104 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2104 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2104 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2105 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1052 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2105 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2105 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:10 D2:dropOutTwo0.3[0.3098159432411194, 0.3843444585800171, 0.42649397253990173, 0.45819130539894104, 0.469438761472702, 0.4843217432498932, 0.5002272129058838, 0.5111338496208191, 0.5318109393119812, 0.5293115377426147, 0.5419222712516785, 0.5420358777046204, 0.549875020980835, 0.5514655709266663, 0.5631674528121948, 0.5653260350227356, 0.5664621591567993, 0.5762326717376709, 0.5719154477119446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1057\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1060 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2106 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2106 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2106 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2107 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1053 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2107 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2107 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:10 D2:dropOutTwo0.5[0.28652578592300415, 0.3378777503967285, 0.36787092685699463, 0.3826403021812439, 0.4027493894100189, 0.3971824645996094, 0.41672345995903015, 0.42342647910118103, 0.45012497901916504, 0.4443308413028717, 0.45478299260139465, 0.45489662885665894, 0.46478071808815, 0.476028174161911, 0.46523517370224, 0.4618268609046936, 0.469893217086792, 0.48193591833114624, 0.48216313123703003, 0.4827311933040619, 0.4843217432498932, 0.4901158809661865, 0.49102476239204407, 0.49591001868247986, 0.48966145515441895, 0.4906839430332184, 0.48977506160736084, 0.49454668164253235, 0.4877300560474396, 0.49727335572242737]\n",
      "Model: \"model_1058\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1061 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2108 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2108 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2108 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2109 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1054 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2109 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2109 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:10 D2:dropOutTwo0.9[0.17087025940418243, 0.19132015109062195, 0.2048398107290268, 0.2081345170736313, 0.2064303606748581, 0.21313337981700897, 0.2158600389957428, 0.2157464176416397, 0.20563508570194244, 0.2142694890499115, 0.21551920473575592, 0.212906152009964, 0.21324698626995087, 0.21324698626995087, 0.21472392976284027, 0.21551920473575592, 0.22597137093544006, 0.22017723321914673, 0.21699613332748413, 0.22188138961791992, 0.21461030840873718, 0.21858668327331543, 0.2189275175333023, 0.21529197692871094, 0.22188138961791992, 0.21858668327331543, 0.22165417671203613, 0.2223358303308487, 0.2160872519016266, 0.22188138961791992]\n",
      "Model: \"model_1059\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1062 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2110 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2110 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2110 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2111 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1055 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2111 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2111 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:11 D2:dropOutTwo0.1[0.367075651884079, 0.4748920798301697, 0.5229493379592896, 0.5477164387702942, 0.5880481600761414, 0.6063394546508789, 0.6184958219528198, 0.6317882537841797, 0.6516700983047485, 0.6660985946655273, 0.6728016138076782, 0.6810951828956604, 0.6851851940155029, 0.6868893504142761, 0.6991592645645142]\n",
      "Model: \"model_1060\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1063 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2112 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2112 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2112 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2113 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1056 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2113 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2113 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:11 D2:dropOutTwo0.2[0.37571007013320923, 0.44705748558044434, 0.48148149251937866, 0.5132924318313599, 0.5287434458732605, 0.554533064365387, 0.5588502883911133, 0.5804362893104553, 0.5944103598594666, 0.6053169965744019, 0.61667799949646, 0.6141785979270935, 0.6242899298667908, 0.623267412185669, 0.6337196230888367]\n",
      "Model: \"model_1061\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1064 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2114 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2114 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2114 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2115 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1057 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2115 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2115 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:11 D2:dropOutTwo0.3[0.3335605561733246, 0.4201318025588989, 0.44717109203338623, 0.48023176193237305, 0.49147921800613403, 0.5194274187088013, 0.530106782913208, 0.5336287021636963, 0.5513519644737244, 0.5630538463592529, 0.5679391026496887, 0.5713474154472351, 0.5702112913131714, 0.5847534537315369, 0.5771415829658508, 0.5956600904464722, 0.5878209471702576, 0.6012269854545593, 0.5969098210334778, 0.5995228290557861, 0.6149738430976868]\n",
      "Model: \"model_1062\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1065 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2116 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2116 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2116 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2117 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1058 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2117 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2117 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:11 D2:dropOutTwo0.5[0.27880027890205383, 0.3473074436187744, 0.3796864449977875, 0.4032038152217865, 0.41501930356025696, 0.4221767783164978, 0.43081116676330566, 0.4368325471878052, 0.45660078525543213, 0.4480799734592438, 0.4571688175201416, 0.45330607891082764, 0.45955464243888855, 0.4745512306690216, 0.47977733612060547, 0.4728470742702484, 0.4823903739452362, 0.4842081367969513, 0.4859122931957245, 0.49454668164253235, 0.480686217546463, 0.5021585822105408, 0.4854578375816345, 0.5042036175727844, 0.4967052936553955, 0.4984094500541687, 0.5024994611740112, 0.5063621997833252, 0.4923880994319916, 0.5086343884468079]\n",
      "Model: \"model_1063\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1066 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2118 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2118 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2118 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2119 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1059 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2119 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2119 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:11 D2:dropOutTwo0.9[0.1826857477426529, 0.2159736454486847, 0.22915247082710266, 0.23233355581760406, 0.2350602149963379, 0.2397182434797287, 0.2363099306821823, 0.24210406839847565, 0.23858213424682617, 0.2414223998785019, 0.24471710622310638, 0.24721653759479523, 0.2411951869726181, 0.24335378408432007, 0.24074074625968933, 0.24880708754062653, 0.24517154693603516, 0.24846625328063965, 0.24982959032058716, 0.24857987463474274, 0.24471710622310638, 0.2477845996618271, 0.2491479218006134, 0.24869348108768463, 0.24994319677352905, 0.2477845996618271, 0.24835264682769775, 0.24892069399356842, 0.25005680322647095, 0.24869348108768463]\n",
      "Model: \"model_1064\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1067 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2120 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2120 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2120 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2121 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " activation_1060 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2121 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2121 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:12 D2:dropOutTwo0.1[0.3857077956199646, 0.4587593674659729, 0.504658043384552, 0.5396500825881958, 0.5786184668540955, 0.6027039289474487, 0.6203135848045349, 0.6441717743873596, 0.6513292193412781, 0.6730288863182068, 0.67473304271698, 0.677686870098114, 0.683253824710846, 0.6965462565422058]\n",
      "Model: \"model_1065\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1068 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2122 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2122 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2122 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2123 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1061 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2123 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2123 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:12 D2:dropOutTwo0.2[0.35616904497146606, 0.43865031003952026, 0.48307204246520996, 0.5251079201698303, 0.553624153137207, 0.5749829411506653, 0.5838446021080017, 0.5979322791099548, 0.6022495031356812, 0.6075891852378845, 0.6273574233055115, 0.6291751861572266, 0.6378095746040344, 0.6478073000907898, 0.6548511981964111, 0.6521245241165161, 0.6617814302444458]\n",
      "Model: \"model_1066\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1069 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2124 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2124 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2124 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2125 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1062 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2125 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2125 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:12 D2:dropOutTwo0.3[0.3506021499633789, 0.4281981289386749, 0.46296295523643494, 0.4857986867427826, 0.5120427012443542, 0.5321517586708069, 0.5356737375259399, 0.5466939210891724, 0.5482844710350037, 0.5631674528121948, 0.5720291137695312, 0.5760054588317871, 0.5840718150138855, 0.5863440036773682, 0.5923653841018677, 0.5941831469535828, 0.5988411903381348, 0.6019086837768555, 0.6045216917991638]\n",
      "Model: \"model_1067\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1070 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2126 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2126 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2126 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2127 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1063 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2127 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2127 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:12 D2:dropOutTwo0.5[0.2857305109500885, 0.3602590262889862, 0.3947966396808624, 0.421949565410614, 0.44535332918167114, 0.4568279981613159, 0.4650079607963562, 0.4748920798301697, 0.477959543466568, 0.4776187241077423, 0.4853442311286926, 0.49147921800613403, 0.5030674934387207, 0.49727335572242737, 0.5061349868774414, 0.5055668950080872, 0.5003408193588257, 0.4996591806411743, 0.5128380060195923, 0.5182912945747375, 0.5087479948997498, 0.5079527497291565, 0.5129516124725342, 0.5176096558570862, 0.521586000919342, 0.5304476022720337, 0.5211315751075745]\n",
      "Model: \"model_1068\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1071 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2128 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2128 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2128 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_2129 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1064 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2129 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2129 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.3 D2P:12 D2:dropOutTwo0.9[0.1779141128063202, 0.20290842652320862, 0.22483526170253754, 0.2254033237695694, 0.223699152469635, 0.22347193956375122, 0.23267439007759094, 0.23710520565509796, 0.24630765616893768, 0.24051351845264435, 0.24517154693603516, 0.24176323413848877, 0.24812541902065277, 0.2527834475040436, 0.2491479218006134, 0.24812541902065277, 0.24982959032058716, 0.247670978307724, 0.2505112588405609, 0.2491479218006134, 0.2510792911052704, 0.25482845306396484, 0.2551692724227905, 0.25142014026641846, 0.2567598223686218, 0.25198817253112793, 0.2559645473957062, 0.2525562345981598, 0.258463978767395, 0.2551692724227905]\n",
      "Model: \"model_1069\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1072 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2130 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2130 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2130 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2131 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1065 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2131 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2131 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:8 D2:dropOutTwo0.1[0.22915247082710266, 0.4142240285873413, 0.458645761013031, 0.4893206059932709, 0.5055668950080872, 0.5312429070472717, 0.5398772954940796, 0.5447625517845154, 0.5560100078582764, 0.5576005578041077, 0.5596455335617065, 0.5628266334533691, 0.5743013024330139, 0.5739604830741882, 0.576119065284729, 0.5775960087776184, 0.5815723538398743, 0.5931606292724609, 0.588388979434967, 0.5869120359420776, 0.5954328775405884, 0.5885025858879089, 0.5974778532981873, 0.6008861660957336, 0.595887303352356, 0.6049761176109314]\n",
      "Model: \"model_1070\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1073 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2132 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2132 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2132 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2133 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1066 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2133 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2133 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:8 D2:dropOutTwo0.2[0.21938195824623108, 0.3427630066871643, 0.4376278221607208, 0.4526244103908539, 0.4620540738105774, 0.4810270369052887, 0.48966145515441895, 0.4955691993236542, 0.5070438385009766, 0.5118154883384705, 0.5155646204948425, 0.522494912147522, 0.5268120765686035, 0.5310156941413879, 0.5429447889328003, 0.5330606698989868, 0.5346512198448181, 0.5369234085083008, 0.5438536405563354, 0.5426039695739746, 0.5469211339950562, 0.5606680512428284, 0.544080913066864, 0.5647580027580261, 0.547943651676178, 0.5529425144195557, 0.5481708645820618, 0.5590775012969971]\n",
      "Model: \"model_1071\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1074 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2134 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2134 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2134 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2135 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1067 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2135 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2135 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:8 D2:dropOutTwo0.3[0.2794819474220276, 0.36275845766067505, 0.40240854024887085, 0.4096796214580536, 0.4220631718635559, 0.4376278221607208, 0.44785276055336, 0.45660078525543213, 0.4603499174118042, 0.47364234924316406, 0.47557371854782104, 0.47398319840431213, 0.4843217432498932, 0.4876164495944977, 0.4842081367969513, 0.4968189001083374, 0.49250170588493347, 0.49625083804130554, 0.49250170588493347, 0.49454668164253235, 0.5020449757575989, 0.5037491321563721, 0.5001136064529419, 0.5003408193588257, 0.5062485933303833, 0.5062485933303833, 0.5148829817771912, 0.502726674079895, 0.5018177628517151, 0.5099977254867554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1072\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1075 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2136 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2136 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2136 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2137 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1068 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2137 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2137 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:8 D2:dropOutTwo0.5[0.24812541902065277, 0.3094751238822937, 0.33901387453079224, 0.3575323820114136, 0.36730289459228516, 0.38173142075538635, 0.38798001408576965, 0.38968417048454285, 0.4014996588230133, 0.39922744035720825, 0.401840478181839, 0.40524882078170776, 0.41320154070854187, 0.411156564950943, 0.4046807587146759, 0.41217905282974243, 0.41695070266723633, 0.41536015272140503, 0.42797091603279114, 0.4201318025588989, 0.4321745038032532, 0.41956374049186707, 0.4288797974586487, 0.42160871624946594, 0.42910701036453247, 0.42603954672813416, 0.42751646041870117, 0.4284253716468811, 0.43115201592445374, 0.41979095339775085]\n",
      "Model: \"model_1073\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1076 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2138 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2138 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2138 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2139 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1069 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2139 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2139 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:8 D2:dropOutTwo0.9[0.16746194660663605, 0.1807543784379959, 0.19075210392475128, 0.19802317023277283, 0.19325153529644012, 0.19722791016101837, 0.19779595732688904, 0.20234037935733795, 0.20074982941150665, 0.20415814220905304, 0.20518064498901367, 0.2079072892665863, 0.20688480138778687, 0.20381730794906616, 0.20608952641487122, 0.20552147924900055, 0.21086116135120392, 0.2079072892665863, 0.20972506701946259, 0.20972506701946259, 0.2110883891582489, 0.21199727058410645, 0.20904339849948883, 0.21222449839115143, 0.20836172997951508, 0.20983867347240448, 0.21006590127944946, 0.210974782705307, 0.21029311418533325, 0.21211087703704834]\n",
      "Model: \"model_1074\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1077 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2140 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2140 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2140 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2141 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1070 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2141 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2141 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:9 D2:dropOutTwo0.1[0.3319700062274933, 0.39434218406677246, 0.4377414286136627, 0.48148149251937866, 0.5107930302619934, 0.532833456993103, 0.5473756194114685, 0.556350827217102, 0.5632810592651367, 0.5737332701683044, 0.5697568655014038, 0.5860031843185425, 0.5836173892021179, 0.5945239663124084, 0.599636435508728, 0.599636435508728, 0.606225848197937, 0.6103158593177795, 0.6096341609954834]\n",
      "Model: \"model_1075\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1078 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2142 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2142 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2142 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2143 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1071 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2143 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2143 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:9 D2:dropOutTwo0.2[0.33719608187675476, 0.40195411443710327, 0.4444444477558136, 0.471824586391449, 0.4888661801815033, 0.5020449757575989, 0.5135196447372437, 0.5207907557487488, 0.5229493379592896, 0.5397636890411377, 0.5341967940330505, 0.5382867455482483, 0.5495342016220093, 0.5373778939247131, 0.5482844710350037, 0.5468075275421143, 0.5515791773796082, 0.55260169506073, 0.5625994205474854, 0.5621449947357178, 0.565780520439148, 0.5664621591567993, 0.5639627575874329]\n",
      "Model: \"model_1076\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1079 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2144 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2144 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2144 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2145 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1072 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2145 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2145 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:9 D2:dropOutTwo0.3[0.2663031220436096, 0.3694614768028259, 0.3949102461338043, 0.41808679699897766, 0.4395591914653778, 0.44171780347824097, 0.4615996479988098, 0.467166543006897, 0.4746648371219635, 0.4747784733772278, 0.47818678617477417, 0.48488980531692505, 0.4919336438179016, 0.4920472502708435, 0.4951147437095642, 0.49909111857414246, 0.5030674934387207, 0.5082935690879822, 0.5014769434928894, 0.5097705125808716, 0.5110202431678772, 0.5068166255950928, 0.5134060382843018, 0.5193138122558594, 0.5268120765686035, 0.5164735317230225, 0.5124971866607666, 0.5218132138252258, 0.5278345942497253, 0.5264712572097778]\n",
      "Model: \"model_1077\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1080 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2146 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2146 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2146 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2147 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1073 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2147 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2147 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:9 D2:dropOutTwo0.5[0.2427857369184494, 0.3189047873020172, 0.34526243805885315, 0.3702567517757416, 0.3809361457824707, 0.3934333026409149, 0.3936605453491211, 0.40104520320892334, 0.41672345995903015, 0.4160418212413788, 0.42478981614112854, 0.42456260323524475, 0.43285617232322693, 0.42751646041870117, 0.44717109203338623, 0.4400136470794678, 0.43092480301856995, 0.4392183721065521, 0.4414905607700348, 0.4476255476474762, 0.4463758170604706, 0.4493297040462494, 0.4463758170604706, 0.44785276055336, 0.4456941485404968, 0.460577130317688, 0.4558055102825165, 0.44830721616744995, 0.44978412985801697, 0.4463758170604706]\n",
      "Model: \"model_1078\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1081 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2148 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2148 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2148 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2149 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1074 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2149 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2149 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:9 D2:dropOutTwo0.9[0.17177914083003998, 0.18950238823890686, 0.20063622295856476, 0.20711201429367065, 0.21483753621578217, 0.21824584901332855, 0.21813224256038666, 0.21983639895915985, 0.22426721453666687, 0.2188139110803604, 0.22392638027668, 0.22165417671203613, 0.22324471175670624, 0.2223358303308487, 0.22358554601669312, 0.22085890173912048, 0.22290389239788055, 0.22665303945541382, 0.2254033237695694, 0.2254033237695694, 0.22506248950958252, 0.22631220519542694, 0.2222222238779068, 0.22915247082710266, 0.22574414312839508, 0.22585776448249817, 0.22563053667545319, 0.22790275514125824, 0.2284708023071289, 0.228357195854187]\n",
      "Model: \"model_1079\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1082 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2150 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2150 (B  (None, 6144)             24576     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2150 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2151 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1075 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2151 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2151 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:10 D2:dropOutTwo0.1[0.3337877690792084, 0.4430811107158661, 0.48829811811447144, 0.5118154883384705, 0.5356737375259399, 0.5469211339950562, 0.5613496899604797, 0.5681663155555725, 0.5795273780822754, 0.5882753729820251, 0.5937287211418152, 0.6003181338310242, 0.599636435508728, 0.6054306030273438, 0.6182685494422913, 0.613610565662384, 0.6149738430976868]\n",
      "Model: \"model_1080\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1083 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2152 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2152 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2152 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2153 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1076 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2153 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2153 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:10 D2:dropOutTwo0.2[0.2634628415107727, 0.3918427526950836, 0.4380822479724884, 0.47705066204071045, 0.49125197529792786, 0.5081799626350403, 0.5163599252700806, 0.5164735317230225, 0.5293115377426147, 0.5348784327507019, 0.5451033711433411, 0.5480572581291199, 0.5481708645820618, 0.556464433670044, 0.5622586011886597, 0.5577141642570496, 0.5674846768379211, 0.5619177222251892, 0.5745285153388977, 0.5763462781906128, 0.5771415829658508, 0.5729379653930664, 0.5689616203308105, 0.5798681974411011, 0.5815723538398743, 0.5840718150138855]\n",
      "Model: \"model_1081\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1084 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2154 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2154 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2154 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2155 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1077 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2155 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2155 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:10 D2:dropOutTwo0.3[0.32935696840286255, 0.39752328395843506, 0.42785730957984924, 0.4444444477558136, 0.4461486041545868, 0.46125879883766174, 0.4638718366622925, 0.47682344913482666, 0.47818678617477417, 0.4904567003250122, 0.4902294874191284, 0.48943421244621277, 0.5123835206031799, 0.5030674934387207, 0.506589412689209, 0.5153374075889587, 0.510338544845581, 0.5132924318313599, 0.5173823833465576, 0.5255623459815979, 0.5181776881217957, 0.5265848636627197, 0.530106782913208, 0.5369234085083008, 0.537491500377655, 0.5284026265144348, 0.5372642874717712]\n",
      "Model: \"model_1082\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1085 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2156 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2156 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2156 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2157 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1078 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2157 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2157 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:10 D2:dropOutTwo0.5[0.26562145352363586, 0.3269711434841156, 0.34344467520713806, 0.3526471257209778, 0.3744603395462036, 0.3838900327682495, 0.3935469090938568, 0.40240854024887085, 0.4094524085521698, 0.4093387722969055, 0.4281981289386749, 0.4218359589576721, 0.4301295280456543, 0.4409225285053253, 0.4397864043712616, 0.4509202539920807, 0.4447852671146393, 0.44228583574295044, 0.4429675042629242, 0.44546693563461304, 0.4506930112838745, 0.45171552896499634, 0.4541013538837433, 0.4568279981613159, 0.45341968536376953, 0.4584185481071472, 0.4553510546684265, 0.4521699547767639, 0.4570552110671997, 0.45978185534477234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1083\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1086 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2158 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2158 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2158 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2159 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1079 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2159 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2159 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:10 D2:dropOutTwo0.9[0.15587367117404938, 0.17666439712047577, 0.18768461048603058, 0.19881844520568848, 0.2031356543302536, 0.20359009504318237, 0.20245398581027985, 0.20222677290439606, 0.20972506701946259, 0.2143830955028534, 0.2125653326511383, 0.21370142698287964, 0.21347421407699585, 0.2144967019557953, 0.21517837047576904, 0.21620085835456848, 0.21801863610744476, 0.2159736454486847, 0.2160872519016266, 0.20881617069244385, 0.22006362676620483, 0.22097250819206238, 0.21620085835456848, 0.21767780184745789, 0.21960918605327606, 0.22085890173912048, 0.21847307682037354, 0.2205180674791336, 0.21654169261455536, 0.21688252687454224]\n",
      "Model: \"model_1084\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1087 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2160 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2160 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2160 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2161 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1080 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2161 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2161 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:11 D2:dropOutTwo0.1[0.30867984890937805, 0.4176323413848877, 0.4686434864997864, 0.5155646204948425, 0.5402181148529053, 0.5513519644737244, 0.5740740895271301, 0.5729379653930664, 0.5890706777572632, 0.5942967534065247, 0.6114519238471985, 0.6104294657707214, 0.6094069480895996, 0.6222449541091919, 0.6275846362113953, 0.6320154666900635, 0.6238355040550232, 0.6288343667984009, 0.6362190246582031, 0.6374687552452087, 0.6337196230888367]\n",
      "Model: \"model_1085\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1088 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2162 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2162 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2162 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2163 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1081 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2163 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2163 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:11 D2:dropOutTwo0.2[0.3224267065525055, 0.4096796214580536, 0.44523972272872925, 0.4728470742702484, 0.49295613169670105, 0.5184049010276794, 0.5226085186004639, 0.5332878828048706, 0.5389684438705444, 0.5385139584541321, 0.5528289079666138, 0.5540786385536194, 0.571461021900177, 0.5686207413673401, 0.5681663155555725, 0.5718018412590027, 0.5808907151222229, 0.5813451409339905, 0.5872529149055481, 0.5820268392562866, 0.5841854214668274, 0.5853215456008911]\n",
      "Model: \"model_1086\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1089 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2164 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2164 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2164 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2165 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1082 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2165 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2165 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:11 D2:dropOutTwo0.3[0.3221994936466217, 0.40433990955352783, 0.4428538978099823, 0.452056348323822, 0.47205179929733276, 0.4844353497028351, 0.5059077739715576, 0.5096569061279297, 0.5164735317230225, 0.5212451815605164, 0.5220404267311096, 0.5204498767852783, 0.5274937748908997, 0.5337423086166382, 0.5411270260810852, 0.5351056456565857, 0.5353328585624695, 0.5396500825881958, 0.5446489453315735, 0.5438536405563354, 0.5489661693572998, 0.5433992147445679, 0.5505567193031311]\n",
      "Model: \"model_1087\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1090 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2166 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2166 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2166 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2167 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1083 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2167 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2167 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:11 D2:dropOutTwo0.5[0.22426721453666687, 0.30833899974823, 0.3504885137081146, 0.37536922097206116, 0.39604634046554565, 0.4171779155731201, 0.41683709621429443, 0.42944785952568054, 0.42774370312690735, 0.4299022853374481, 0.4381958544254303, 0.44683027267456055, 0.44194501638412476, 0.4448988735675812, 0.4589865803718567, 0.4462622106075287, 0.45489662885665894, 0.4603499174118042, 0.4602363109588623, 0.4494433104991913, 0.4495569169521332, 0.4602363109588623, 0.4526244103908539, 0.4620540738105774, 0.4588729739189148, 0.4603499174118042]\n",
      "Model: \"model_1088\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1091 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2168 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2168 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2168 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2169 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1084 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2169 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2169 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:11 D2:dropOutTwo0.9[0.17211997509002686, 0.2157464176416397, 0.2159736454486847, 0.22744831442832947, 0.23449216783046722, 0.23699159920215607, 0.23460577428340912, 0.23767325282096863, 0.2366507649421692, 0.2382413148880005, 0.23994547128677368, 0.23755964636802673, 0.23710520565509796, 0.24698932468891144, 0.24801181256771088, 0.2430129498243332, 0.24471710622310638, 0.24721653759479523, 0.24789820611476898, 0.2460804432630539, 0.2490343153476715, 0.2446034997701645, 0.24982959032058716, 0.24664849042892456, 0.24971596896648407, 0.25005680322647095, 0.25005680322647095, 0.2522154152393341, 0.25460124015808105, 0.2555101215839386]\n",
      "Model: \"model_1089\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1092 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2170 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2170 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2170 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2171 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1085 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2171 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2171 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:12 D2:dropOutTwo0.1[0.3333333432674408, 0.434673935174942, 0.4901158809661865, 0.5129516124725342, 0.5359009504318237, 0.55260169506073, 0.5663485527038574, 0.5796409845352173, 0.5900931358337402, 0.5956600904464722, 0.5981594920158386, 0.6113383173942566, 0.610883891582489, 0.6236082911491394, 0.6115655303001404, 0.6247443556785583, 0.6300840973854065, 0.6403090357780457]\n",
      "Model: \"model_1090\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1093 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2172 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2172 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2172 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2173 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_1086 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2173 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2173 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:12 D2:dropOutTwo0.2[0.317655086517334, 0.4127471148967743, 0.45285162329673767, 0.4789820611476898, 0.5062485933303833, 0.5189729332923889, 0.5286298394203186, 0.53476482629776, 0.5487388968467712, 0.5535105466842651, 0.5712338089942932, 0.5598727464675903, 0.5755510330200195, 0.5808907151222229, 0.5740740895271301, 0.5782776474952698, 0.5881617665290833, 0.5916836857795715, 0.5924789905548096, 0.5945239663124084, 0.585435152053833, 0.5936151146888733, 0.6038400530815125, 0.6028175354003906, 0.6028175354003906, 0.6031583547592163]\n",
      "Model: \"model_1091\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1094 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2174 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2174 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2174 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2175 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1087 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2175 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2175 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:12 D2:dropOutTwo0.3[0.30879345536231995, 0.4030902087688446, 0.43899112939834595, 0.4585321545600891, 0.48466256260871887, 0.49284252524375916, 0.5012497305870056, 0.5053396821022034, 0.5174960494041443, 0.5218132138252258, 0.5330606698989868, 0.530106782913208, 0.5352192521095276, 0.5278345942497253, 0.5488525629043579, 0.5491933822631836, 0.5465803146362305, 0.5489661693572998, 0.5524880886077881, 0.562940239906311, 0.5639627575874329, 0.5538514256477356, 0.5604408383369446, 0.5645307898521423, 0.5510111451148987]\n",
      "Model: \"model_1092\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1095 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2176 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2176 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2176 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2177 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1088 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2177 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2177 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:12 D2:dropOutTwo0.5[0.1713247001171112, 0.29311519861221313, 0.37196090817451477, 0.4049079716205597, 0.4155873656272888, 0.4235401153564453, 0.4286525845527649, 0.43569642305374146, 0.44353556632995605, 0.4509202539920807, 0.45910021662712097, 0.45762327313423157, 0.45455577969551086, 0.4731879234313965, 0.46478071808815, 0.4827311933040619, 0.46523517370224, 0.47364234924316406, 0.47852760553359985, 0.4701204299926758, 0.47705066204071045, 0.47409680485725403, 0.47557371854782104, 0.4756873548030853, 0.48216313123703003, 0.4813678562641144, 0.48829811811447144, 0.48204952478408813, 0.48352646827697754, 0.4860258996486664]\n",
      "Model: \"model_1093\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1096 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2178 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2178 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2178 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2179 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1089 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2179 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2179 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.5 D2P:12 D2:dropOutTwo0.9[0.19120654463768005, 0.2141558676958084, 0.2207452803850174, 0.22324471175670624, 0.23312883079051971, 0.2332424521446228, 0.23403771221637726, 0.23517382144927979, 0.2350602149963379, 0.24005907773971558, 0.23369689285755157, 0.23767325282096863, 0.24017268419265747, 0.24164962768554688, 0.24221767485141754, 0.24369461834430695, 0.23767325282096863, 0.2396046370267868, 0.2414223998785019, 0.24221767485141754, 0.24074074625968933, 0.24551238119602203, 0.24653488397598267, 0.2475573718547821, 0.2443762719631195, 0.24869348108768463, 0.2444898933172226, 0.24857987463474274, 0.24994319677352905, 0.24857987463474274]\n",
      "Model: \"model_1094\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " input_1097 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2180 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2180 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2180 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2181 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1090 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2181 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2181 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:8 D2:dropOutTwo0.1[0.28039082884788513, 0.3478754758834839, 0.36071348190307617, 0.38014087080955505, 0.3876391649246216, 0.4051351845264435, 0.4097932279109955, 0.4201318025588989, 0.4267211854457855, 0.4347875416278839, 0.4367189407348633, 0.4367189407348633, 0.44398999214172363, 0.44660302996635437, 0.43092480301856995, 0.44876164197921753, 0.44978412985801697, 0.4508066475391388, 0.45001137256622314, 0.44989773631095886, 0.4570552110671997, 0.45762327313423157, 0.45160192251205444, 0.4554646611213684, 0.4522835612297058, 0.4601227045059204, 0.4619404673576355, 0.4598954916000366, 0.4570552110671997, 0.4535332918167114]\n",
      "Model: \"model_1095\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1098 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2182 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2182 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2182 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2183 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1091 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2183 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2183 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:8 D2:dropOutTwo0.2[0.22574414312839508, 0.29936379194259644, 0.3267439305782318, 0.3523063063621521, 0.37218815088272095, 0.38513973355293274, 0.3918427526950836, 0.39934104681015015, 0.41024768352508545, 0.41172459721565247, 0.4078618586063385, 0.411156564950943, 0.4204726219177246, 0.4139968156814575, 0.42149510979652405, 0.42763009667396545, 0.428538978099823, 0.42649397253990173, 0.4251306653022766, 0.428538978099823, 0.4224039912223816, 0.42626675963401794, 0.4320608973503113, 0.4333105981349945, 0.4271756410598755, 0.42956146597862244, 0.42967507243156433, 0.4337650537490845, 0.4329697787761688, 0.43853670358657837]\n",
      "Model: \"model_1096\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1099 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2184 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2184 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2184 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2185 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1092 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2185 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2185 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:8 D2:dropOutTwo0.3[0.17064303159713745, 0.27550557255744934, 0.3234492242336273, 0.3393546938896179, 0.36287206411361694, 0.3694614768028259, 0.36718928813934326, 0.37377870082855225, 0.37559646368026733, 0.38832083344459534, 0.3861622214317322, 0.3965007960796356, 0.39138832688331604, 0.4061577022075653, 0.39888662099838257, 0.39900022745132446, 0.3954783082008362, 0.4094524085521698, 0.40524882078170776, 0.4093387722969055, 0.4157009720802307, 0.4143376648426056, 0.4096796214580536, 0.4029766023159027, 0.404567152261734, 0.40740740299224854, 0.4108157157897949, 0.4114973843097687, 0.41536015272140503, 0.410702109336853]\n",
      "Model: \"model_1097\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1100 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2186 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2186 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2186 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2187 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1093 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2187 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2187 (Dense)          (None, 9)                 81        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:8 D2:dropOutTwo0.5[0.13144740462303162, 0.24130879342556, 0.275846391916275, 0.29311519861221313, 0.29595547914505005, 0.32129061222076416, 0.32276755571365356, 0.3236764371395111, 0.3321972191333771, 0.3361735939979553, 0.35173824429512024, 0.3459441065788269, 0.34480801224708557, 0.34708020091056824, 0.35185185074806213, 0.35037490725517273, 0.3554873764514923, 0.35457849502563477, 0.36082708835601807, 0.35639628767967224, 0.3653714954853058, 0.3587820827960968, 0.36048623919487, 0.36764371395111084, 0.35787320137023926, 0.3637809455394745, 0.3603726327419281, 0.3567371070384979, 0.3633265197277069, 0.3615087568759918]\n",
      "Model: \"model_1098\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1101 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2188 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2188 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2188 (Dense)          (None, 8)                 49160     \n",
      "                                                                 \n",
      " batch_normalization_2189 (B  (None, 8)                32        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1094 (Activation  (None, 8)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2189 (Dropout)      (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2189 (Dense)          (None, 9)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,849\n",
      "Trainable params: 61,545\n",
      "Non-trainable params: 12,304\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:8 D2:dropOutTwo0.9[0.16882526874542236, 0.17518745362758636, 0.18643489480018616, 0.19279709458351135, 0.19404681026935577, 0.1983640044927597, 0.19972734153270721, 0.19643263518810272, 0.2014314979314804, 0.20086343586444855, 0.20506702363491058, 0.20381730794906616, 0.2031356543302536, 0.20245398581027985, 0.2046125829219818, 0.20290842652320862, 0.20245398581027985, 0.20586229860782623, 0.20518064498901367, 0.20529425144195557, 0.2064303606748581, 0.20586229860782623, 0.2077936828136444, 0.20552147924900055, 0.20574869215488434, 0.2081345170736313, 0.20881617069244385, 0.2062031328678131, 0.2110883891582489, 0.20983867347240448]\n",
      "Model: \"model_1099\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1102 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2190 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2190 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2190 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2191 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1095 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2191 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2191 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:9 D2:dropOutTwo0.1[0.2477845996618271, 0.35298794507980347, 0.3908202648162842, 0.40558964014053345, 0.4187684655189514, 0.42433539032936096, 0.4286525845527649, 0.43240171670913696, 0.43251532316207886, 0.4331969916820526, 0.4428538978099823, 0.44512611627578735, 0.44671666622161865, 0.44205862283706665, 0.4480799734592438, 0.45625993609428406, 0.45171552896499634, 0.45785048604011536, 0.453987717628479, 0.4573960602283478, 0.4519427418708801, 0.4535332918167114, 0.4631901979446411, 0.46137240529060364, 0.46091797947883606, 0.45625993609428406, 0.4587593674659729, 0.46421268582344055, 0.45637354254722595, 0.46125879883766174]\n",
      "Model: \"model_1100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1103 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2192 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2192 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2192 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2193 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1096 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2193 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2193 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:9 D2:dropOutTwo0.2[0.21790501475334167, 0.3142467737197876, 0.334583044052124, 0.34855714440345764, 0.367075651884079, 0.38820722699165344, 0.39445582032203674, 0.3987730145454407, 0.40422630310058594, 0.40263575315475464, 0.40593045949935913, 0.4035446345806122, 0.41842761635780334, 0.4204726219177246, 0.4205862283706665, 0.43001589179039, 0.4193365275859833, 0.4318336844444275, 0.4344467222690582, 0.4395591914653778, 0.42956146597862244, 0.43740057945251465, 0.43421950936317444, 0.43399226665496826, 0.441263347864151, 0.4318336844444275, 0.44080889225006104, 0.44024085998535156, 0.4347875416278839, 0.4335378408432007]\n",
      "Model: \"model_1101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1104 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_2194 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2194 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2194 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2195 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1097 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2195 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2195 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:9 D2:dropOutTwo0.3[0.19961372017860413, 0.2970915734767914, 0.3251533806324005, 0.3478754758834839, 0.36934787034988403, 0.36582595109939575, 0.38025447726249695, 0.38820722699165344, 0.3903658390045166, 0.39297887682914734, 0.39456942677497864, 0.3986594080924988, 0.39581912755966187, 0.39752328395843506, 0.40695297718048096, 0.3955919146537781, 0.39945468306541443, 0.41172459721565247, 0.406498521566391, 0.4092251658439636, 0.41331514716148376, 0.4100204408168793, 0.40388548374176025, 0.4128607213497162, 0.4129743278026581, 0.411156564950943, 0.41047489643096924, 0.411156564950943, 0.4079754650592804, 0.4170643091201782]\n",
      "Model: \"model_1102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1105 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2196 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2196 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2196 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2197 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1098 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2197 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2197 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:9 D2:dropOutTwo0.5[0.18166325986385345, 0.24823904037475586, 0.27845942974090576, 0.2917518615722656, 0.3094751238822937, 0.3186775743961334, 0.3191320300102234, 0.341626912355423, 0.3427630066871643, 0.34230858087539673, 0.3426494002342224, 0.34867075085639954, 0.3460577130317688, 0.34855714440345764, 0.349693238735199, 0.3528743386268616, 0.35605543851852417, 0.3575323820114136, 0.35764598846435547, 0.35173824429512024, 0.354351282119751, 0.3599182069301605, 0.35616904497146606, 0.3536696135997772, 0.3568507134914398, 0.36241763830184937, 0.35764598846435547, 0.35810044407844543, 0.36605316400527954, 0.36593955755233765]\n",
      "Model: \"model_1103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1106 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2198 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2198 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2198 (Dense)          (None, 9)                 55305     \n",
      "                                                                 \n",
      " batch_normalization_2199 (B  (None, 9)                36        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1099 (Activation  (None, 9)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2199 (Dropout)      (None, 9)                 0         \n",
      "                                                                 \n",
      " dense_2199 (Dense)          (None, 9)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,007\n",
      "Trainable params: 67,701\n",
      "Non-trainable params: 12,306\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:9 D2:dropOutTwo0.9[0.1616678088903427, 0.16280390322208405, 0.18598045408725739, 0.18950238823890686, 0.19631901383399963, 0.2032492607831955, 0.20711201429367065, 0.210974782705307, 0.21086116135120392, 0.21222449839115143, 0.21540558338165283, 0.21767780184745789, 0.217336967587471, 0.21483753621578217, 0.21767780184745789, 0.21949556469917297, 0.22154055535793304, 0.2207452803850174, 0.22017723321914673, 0.22392638027668, 0.2269938588142395, 0.22801636159420013, 0.22608497738838196, 0.22494886815547943, 0.2284708023071289, 0.22778913378715515, 0.23085662722587585, 0.22972051799297333, 0.22892524302005768, 0.22903884947299957]\n",
      "Model: \"model_1104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1107 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2200 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2200 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2200 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2201 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1100 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2201 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2201 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:10 D2:dropOutTwo0.1[0.18382185697555542, 0.31492841243743896, 0.38661667704582214, 0.39740967750549316, 0.4114973843097687, 0.4188820719718933, 0.4289934039115906, 0.4364916980266571, 0.44558054208755493, 0.44046807289123535, 0.4477391541004181, 0.45137467980384827, 0.44978412985801697, 0.4551238417625427, 0.4537605047225952, 0.45819130539894104, 0.4572824239730835, 0.45296522974967957, 0.4600090980529785, 0.4620540738105774, 0.46262213587760925, 0.45932742953300476, 0.46921154856681824, 0.4619404673576355, 0.4573960602283478, 0.4665985107421875, 0.4663712680339813, 0.4667121171951294, 0.46523517370224, 0.47046124935150146]\n",
      "Model: \"model_1105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1108 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2202 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2202 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2202 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2203 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1101 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2203 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2203 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:10 D2:dropOutTwo0.2[0.2607361972332001, 0.3445807695388794, 0.3716200888156891, 0.3807089328765869, 0.39127472043037415, 0.3983185589313507, 0.41320154070854187, 0.42001816630363464, 0.4174051284790039, 0.42172232270240784, 0.4236537218093872, 0.42126789689064026, 0.4333105981349945, 0.4288797974586487, 0.4334242343902588, 0.4317200779914856, 0.44012725353240967, 0.43717336654663086, 0.4409225285053253, 0.436605304479599, 0.4445580542087555, 0.4536468982696533, 0.44398999214172363, 0.44035446643829346, 0.4430811107158661, 0.4350147545337677, 0.44830721616744995, 0.4400136470794678, 0.4462622106075287, 0.4425130784511566]\n",
      "Model: \"model_1106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1109 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2204 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2204 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2204 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2205 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1102 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2205 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2205 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:10 D2:dropOutTwo0.3[0.1666666716337204, 0.2967507243156433, 0.33594638109207153, 0.3527607321739197, 0.3827539086341858, 0.38650307059288025, 0.3951374590396881, 0.39127472043037415, 0.3921836018562317, 0.3890025019645691, 0.40195411443710327, 0.41013404726982117, 0.406498521566391, 0.41206544637680054, 0.41365599632263184, 0.4171779155731201, 0.4186548590660095, 0.4129743278026581, 0.4143376648426056, 0.41047489643096924, 0.4193365275859833, 0.41672345995903015, 0.41342875361442566, 0.41990455985069275, 0.41331514716148376, 0.4239945411682129, 0.4176323413848877, 0.41979095339775085, 0.4269484281539917, 0.4335378408432007]\n",
      "Model: \"model_1107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1110 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2206 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2206 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2206 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2207 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1103 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2207 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2207 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:10 D2:dropOutTwo0.5[0.15019313991069794, 0.22097250819206238, 0.29470574855804443, 0.31822311878204346, 0.3329924941062927, 0.34037718176841736, 0.34662577509880066, 0.349693238735199, 0.35503295063972473, 0.3569643199443817, 0.3542376756668091, 0.36298567056655884, 0.3727561831474304, 0.36105430126190186, 0.3666212260723114, 0.36787092685699463, 0.3746875822544098, 0.38195863366127014, 0.3711656332015991, 0.37389230728149414, 0.3860486149787903, 0.37832310795783997, 0.3812769949436188, 0.3810497522354126, 0.37355145812034607, 0.3824130892753601, 0.3808225393295288, 0.3822994828224182, 0.37707340717315674, 0.3744603395462036]\n",
      "Model: \"model_1108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1111 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2208 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2208 (B  (None, 6144)             24576     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2208 (Dense)          (None, 10)                61450     \n",
      "                                                                 \n",
      " batch_normalization_2209 (B  (None, 10)               40        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1104 (Activation  (None, 10)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2209 (Dropout)      (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2209 (Dense)          (None, 9)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,165\n",
      "Trainable params: 73,857\n",
      "Non-trainable params: 12,308\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:10 D2:dropOutTwo0.9[0.1540558934211731, 0.17166553437709808, 0.18336741626262665, 0.19325153529644012, 0.1998409479856491, 0.2015451043844223, 0.20586229860782623, 0.2092706263065338, 0.2112019956111908, 0.21211087703704834, 0.21563281118869781, 0.21858668327331543, 0.22119972109794617, 0.21835947036743164, 0.21790501475334167, 0.22358554601669312, 0.22426721453666687, 0.22290389239788055, 0.22358554601669312, 0.22438082098960876, 0.22744831442832947, 0.22778913378715515, 0.22517609596252441, 0.23233355581760406, 0.2254033237695694, 0.23040218651294708, 0.2332424521446228, 0.2269938588142395, 0.22949329018592834, 0.2317655086517334]\n",
      "Model: \"model_1109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1112 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2210 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2210 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2210 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2211 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1105 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2211 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2211 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:11 D2:dropOutTwo0.1[0.21165643632411957, 0.33265167474746704, 0.3618495762348175, 0.3843444585800171, 0.404567152261734, 0.41206544637680054, 0.4272892475128174, 0.4399000108242035, 0.43853670358657837, 0.4444444477558136, 0.44523972272872925, 0.4523971676826477, 0.45955464243888855, 0.4570552110671997, 0.46296295523643494, 0.46273574233055115, 0.46137240529060364, 0.46262213587760925, 0.4651215672492981, 0.4583049416542053, 0.46728014945983887, 0.46773460507392883, 0.47386956214904785, 0.46284934878349304, 0.46625766158103943, 0.4742104113101959, 0.4762553870677948, 0.47057485580444336, 0.4715973734855652, 0.46921154856681824]\n",
      "Model: \"model_1110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1113 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2212 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2212 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2212 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2213 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1106 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2213 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2213 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:11 D2:dropOutTwo0.2[0.2522154152393341, 0.34560325741767883, 0.37355145812034607, 0.3858214020729065, 0.3995682895183563, 0.40740740299224854, 0.41672345995903015, 0.41979095339775085, 0.42751646041870117, 0.42478981614112854, 0.43410587310791016, 0.4384230971336365, 0.44171780347824097, 0.4361508786678314, 0.44535332918167114, 0.443194717168808, 0.4416041672229767, 0.4396727979183197, 0.4447852671146393, 0.44228583574295044, 0.44558054208755493, 0.4463758170604706, 0.44171780347824097, 0.43751421570777893, 0.45489662885665894, 0.452510803937912, 0.44705748558044434, 0.44512611627578735, 0.45455577969551086, 0.45444217324256897]\n",
      "Model: \"model_1111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1114 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2214 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2214 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2214 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2215 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1107 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2215 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2215 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:11 D2:dropOutTwo0.3[0.23426494002342224, 0.3143603801727295, 0.34230858087539673, 0.37048399448394775, 0.380595326423645, 0.3936605453491211, 0.39752328395843506, 0.40570324659347534, 0.4093387722969055, 0.41206544637680054, 0.4154737591743469, 0.41797319054603577, 0.4159281849861145, 0.4201318025588989, 0.4220631718635559, 0.4191092848777771, 0.4272892475128174, 0.4225175976753235, 0.42626675963401794, 0.43103840947151184, 0.42933425307273865, 0.42501702904701233, 0.42490342259407043, 0.4318336844444275, 0.43047034740448, 0.4302431344985962, 0.4344467222690582, 0.4331969916820526, 0.43262895941734314, 0.4396727979183197]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1115 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2216 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2216 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2216 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2217 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1108 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2217 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2217 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:11 D2:dropOutTwo0.5[0.19268348813056946, 0.2774369418621063, 0.30356737971305847, 0.3252669870853424, 0.3300386369228363, 0.339241087436676, 0.3553737699985504, 0.35446488857269287, 0.354351282119751, 0.3620767891407013, 0.3617359697818756, 0.36253124475479126, 0.3712792694568634, 0.3729834258556366, 0.37411952018737793, 0.3727561831474304, 0.3760508894920349, 0.382526695728302, 0.38502612709999084, 0.3821858763694763, 0.38457170128822327, 0.38479891419410706, 0.38468530774116516, 0.382526695728302, 0.3918427526950836, 0.3853669762611389, 0.3885480463504791, 0.38968417048454285, 0.38979777693748474, 0.3869574964046478]\n",
      "Model: \"model_1113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1116 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2218 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2218 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2218 (Dense)          (None, 11)                67595     \n",
      "                                                                 \n",
      " batch_normalization_2219 (B  (None, 11)               44        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1109 (Activation  (None, 11)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2219 (Dropout)      (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2219 (Dense)          (None, 9)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92,323\n",
      "Trainable params: 80,013\n",
      "Non-trainable params: 12,310\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:11 D2:dropOutTwo0.9[0.15337423980236053, 0.15928198397159576, 0.17166553437709808, 0.17961826920509338, 0.1922290325164795, 0.20290842652320862, 0.2094978392124176, 0.2126789391040802]\n",
      "Model: \"model_1114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1117 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2220 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2220 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2220 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2221 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1110 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2221 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2221 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:12 D2:dropOutTwo0.1[0.2426721155643463, 0.36275845766067505, 0.39934104681015015, 0.41331514716148376, 0.4239945411682129, 0.43592366576194763, 0.43581002950668335, 0.4492160975933075, 0.4396727979183197, 0.44853442907333374, 0.4506930112838745, 0.44546693563461304, 0.4543285667896271, 0.45614632964134216, 0.4635310173034668, 0.4620540738105774, 0.4636446237564087, 0.46466711163520813, 0.46432629227638245, 0.46568962931632996, 0.46603044867515564, 0.46932515501976013, 0.4731879234313965, 0.46739378571510315, 0.4715973734855652, 0.47205179929733276, 0.46591684222221375, 0.4756873548030853, 0.4793228805065155, 0.4762553870677948]\n",
      "Model: \"model_1115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1118 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2222 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2222 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2222 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2223 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1111 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2223 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2223 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1:0.9 D2P:12 D2:dropOutTwo0.2[0.2602817416191101, 0.35503295063972473, 0.3713928759098053, 0.389116108417511, 0.40377187728881836, 0.41638264060020447, 0.42138150334358215, 0.42274484038352966, 0.425812304019928, 0.4302431344985962, 0.43433311581611633, 0.4361508786678314, 0.4334242343902588, 0.44853442907333374, 0.4361508786678314, 0.44364917278289795, 0.4458077847957611, 0.44671666622161865, 0.4400136470794678, 0.4463758170604706, 0.44228583574295044, 0.45307883620262146, 0.452056348323822, 0.44819357991218567, 0.4495569169521332, 0.4489888548851013, 0.4551238417625427, 0.45489662885665894, 0.4585321545600891, 0.4541013538837433]\n",
      "Model: \"model_1116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1119 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2224 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2224 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2224 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2225 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1112 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2225 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2225 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:12 D2:dropOutTwo0.3[0.24664849042892456, 0.3271983563899994, 0.35469210147857666, 0.37037035822868347, 0.37684616446495056, 0.3842308521270752, 0.39309248328208923, 0.3953647017478943, 0.41013404726982117, 0.41036128997802734, 0.41320154070854187, 0.411156564950943, 0.4206998348236084, 0.42126789689064026, 0.4193365275859833, 0.42160871624946594, 0.42615315318107605, 0.4205862283706665, 0.4220631718635559, 0.42592594027519226, 0.42944785952568054, 0.4221767783164978, 0.43569642305374146, 0.43115201592445374, 0.4329697787761688, 0.4334242343902588, 0.435128390789032, 0.43717336654663086, 0.4349011480808258, 0.43569642305374146]\n",
      "Model: \"model_1117\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1120 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2226 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2226 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2226 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2227 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1113 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2227 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2227 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:12 D2:dropOutTwo0.5[0.18314018845558167, 0.28039082884788513, 0.31651896238327026, 0.3289025127887726, 0.339241087436676, 0.35003408789634705, 0.359009325504303, 0.3713928759098053, 0.36900705099105835, 0.37241536378860474, 0.37366506457328796, 0.3765053451061249, 0.37684616446495056, 0.3837764263153076, 0.3828675448894501, 0.3907066583633423, 0.3859350085258484, 0.38991138339042664, 0.3893433213233948, 0.39752328395843506, 0.39127472043037415, 0.39138832688331604, 0.399909108877182, 0.3908202648162842, 0.3919563591480255, 0.3924108147621155, 0.39320608973503113, 0.39445582032203674, 0.3935469090938568, 0.3983185589313507]\n",
      "Model: \"model_1118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1121 (InputLayer)     [(None, 6144)]            0         \n",
      "                                                                 \n",
      " dropout_2228 (Dropout)      (None, 6144)              0         \n",
      "                                                                 \n",
      " batch_normalization_2228 (B  (None, 6144)             24576     \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dense_2228 (Dense)          (None, 12)                73740     \n",
      "                                                                 \n",
      " batch_normalization_2229 (B  (None, 12)               48        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_1114 (Activation  (None, 12)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_2229 (Dropout)      (None, 12)                0         \n",
      "                                                                 \n",
      " dense_2229 (Dense)          (None, 9)                 117       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 86,169\n",
      "Non-trainable params: 12,312\n",
      "_________________________________________________________________\n",
      "D1:0.9 D2P:12 D2:dropOutTwo0.9[0.15928198397159576, 0.1680299937725067, 0.17961826920509338, 0.19575096666812897, 0.19870483875274658, 0.2030220478773117, 0.20733924210071564, 0.2112019956111908, 0.21336059272289276, 0.21654169261455536, 0.22097250819206238, 0.21654169261455536, 0.22290389239788055, 0.22142694890499115, 0.2221086174249649, 0.2238127738237381, 0.22619858384132385, 0.228357195854187, 0.22642581164836884, 0.22983412444591522, 0.23153828084468842, 0.23085662722587585, 0.2333560585975647, 0.23210634291172028, 0.2334696650505066, 0.23778685927391052, 0.2350602149963379, 0.23233355581760406, 0.23585548996925354, 0.24062712490558624]\n"
     ]
    }
   ],
   "source": [
    "iterations = {}\n",
    "\n",
    "\n",
    "for dropOutOne in [0.1, 0.2, 0.3, 0.5, 0.9]:               #[0.1,0.2]: #\n",
    "    for denseTwoPower in [8,9,10,11,12]:                         #[9,10]: #\n",
    "        for dropOutTwo in [0.1, 0.2, 0.3, 0.5, 0.9]:       #[0.1]: #\n",
    "\n",
    "        \n",
    "            #dropOutOne = 0.7\n",
    "            #denseTwoPower = 12 # 9 = 512\n",
    "            #dropOutTwo = 0.3\n",
    "\n",
    "            thisIteration=\"D1:\" + str(dropOutOne) + \" D2P:\" + str(denseTwoPower) + \" D2:dropOutTwo\" + str(dropOutTwo)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            combined_features = np.concatenate([resnet_predictions, vgg16_predictions],axis=1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(combined_features, y, test_size=0.1, random_state=42)\n",
    "            from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Activation, BatchNormalization\n",
    "\n",
    "            combined_inputs = Input(shape = (6144))\n",
    "            x = Dropout(dropOutOne)(combined_inputs) # add a dropout layer\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dense(denseTwoPower)(x) # add a dense layer, but not adding activation so that we can add batch-norm first\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation(\"relu\")(x)\n",
    "            x = Dropout(dropOutTwo)(x) # add a dropout layer\n",
    "            # Softmax layer to the output classes\n",
    "            new_predictions = Dense(num_classes, activation='softmax')(x) # arg1 is: units = dimensionality of the output space.\n",
    "            from tensorflow.keras.models import Model\n",
    "            model = Model(inputs=combined_inputs, outputs=new_predictions) # specify what is network input, and what is network output\n",
    "            model.summary()\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "            from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "            early_stop = EarlyStopping(monitor='val_loss',  patience=6, verbose=0)\n",
    "            # stop if loss does not improve for 3 iterations\n",
    "\n",
    "            history=model.fit(X_train, y_train, batch_size=128, epochs=30, \n",
    "                          validation_data=(X_test, y_test), callbacks=[early_stop], verbose=0)\n",
    "\n",
    "            iterations[thisIteration] = history.history['accuracy']\n",
    "            \n",
    "            print(thisIteration + str(history.history['accuracy']))\n",
    "\n",
    "\n",
    "#for obj in iterations:\n",
    "#    print(obj)\n",
    "#print(iterations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "815a7088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "OBJ:D1:0.1 D2P:8 D2:dropOutTwo0.1 acc:0.7149511575698853\n",
      "OBJ:D1:0.1 D2P:8 D2:dropOutTwo0.2 acc:0.6395137310028076\n",
      "OBJ:D1:0.1 D2P:8 D2:dropOutTwo0.3 acc:0.610883891582489\n",
      "OBJ:D1:0.1 D2P:8 D2:dropOutTwo0.5 acc:0.5029538869857788\n",
      "OBJ:D1:0.1 D2P:8 D2:dropOutTwo0.9 acc:0.22937968373298645\n",
      "OBJ:D1:0.1 D2P:9 D2:dropOutTwo0.1 acc:0.7400590777397156\n",
      "OBJ:D1:0.1 D2P:9 D2:dropOutTwo0.2 acc:0.6788229942321777\n",
      "OBJ:D1:0.1 D2P:9 D2:dropOutTwo0.3 acc:0.6262212991714478\n",
      "OBJ:D1:0.1 D2P:9 D2:dropOutTwo0.5 acc:0.48648035526275635\n",
      "OBJ:D1:0.1 D2P:9 D2:dropOutTwo0.9 acc:0.2590320408344269\n",
      "OBJ:D1:0.1 D2P:10 D2:dropOutTwo0.1 acc:0.7600545287132263\n",
      "OBJ:D1:0.1 D2P:10 D2:dropOutTwo0.2 acc:0.6805271506309509\n",
      "OBJ:D1:0.1 D2P:10 D2:dropOutTwo0.3 acc:0.6389456987380981\n",
      "OBJ:D1:0.1 D2P:10 D2:dropOutTwo0.5 acc:0.5360145568847656\n",
      "OBJ:D1:0.1 D2P:10 D2:dropOutTwo0.9 acc:0.22960691154003143\n",
      "OBJ:D1:0.1 D2P:11 D2:dropOutTwo0.1 acc:0.7701658606529236\n",
      "OBJ:D1:0.1 D2P:11 D2:dropOutTwo0.2 acc:0.713360607624054\n",
      "OBJ:D1:0.1 D2P:11 D2:dropOutTwo0.3 acc:0.6512156128883362\n",
      "OBJ:D1:0.1 D2P:11 D2:dropOutTwo0.5 acc:0.5466939210891724\n",
      "OBJ:D1:0.1 D2P:11 D2:dropOutTwo0.9 acc:0.23608270287513733\n",
      "OBJ:D1:0.1 D2P:12 D2:dropOutTwo0.1 acc:0.7786866426467896\n",
      "OBJ:D1:0.1 D2P:12 D2:dropOutTwo0.2 acc:0.728357195854187\n",
      "OBJ:D1:0.1 D2P:12 D2:dropOutTwo0.3 acc:0.6815496683120728\n",
      "OBJ:D1:0.1 D2P:12 D2:dropOutTwo0.5 acc:0.5471483469009399\n",
      "OBJ:D1:0.1 D2P:12 D2:dropOutTwo0.9 acc:0.25505566596984863\n",
      "OBJ:D1:0.2 D2P:8 D2:dropOutTwo0.1 acc:0.6779140830039978\n",
      "OBJ:D1:0.2 D2P:8 D2:dropOutTwo0.2 acc:0.6299704909324646\n",
      "OBJ:D1:0.2 D2P:8 D2:dropOutTwo0.3 acc:0.5904340147972107\n",
      "OBJ:D1:0.2 D2P:8 D2:dropOutTwo0.5 acc:0.4669393301010132\n",
      "OBJ:D1:0.2 D2P:8 D2:dropOutTwo0.9 acc:0.20540785789489746\n",
      "OBJ:D1:0.2 D2P:9 D2:dropOutTwo0.1 acc:0.7057486772537231\n",
      "OBJ:D1:0.2 D2P:9 D2:dropOutTwo0.2 acc:0.6590547561645508\n",
      "OBJ:D1:0.2 D2P:9 D2:dropOutTwo0.3 acc:0.595887303352356\n",
      "OBJ:D1:0.2 D2P:9 D2:dropOutTwo0.5 acc:0.48193591833114624\n",
      "OBJ:D1:0.2 D2P:9 D2:dropOutTwo0.9 acc:0.23233355581760406\n",
      "OBJ:D1:0.2 D2P:10 D2:dropOutTwo0.1 acc:0.7063167691230774\n",
      "OBJ:D1:0.2 D2P:10 D2:dropOutTwo0.2 acc:0.6486026048660278\n",
      "OBJ:D1:0.2 D2P:10 D2:dropOutTwo0.3 acc:0.60429447889328\n",
      "OBJ:D1:0.2 D2P:10 D2:dropOutTwo0.5 acc:0.5155646204948425\n",
      "OBJ:D1:0.2 D2P:10 D2:dropOutTwo0.9 acc:0.22472165524959564\n",
      "OBJ:D1:0.2 D2P:11 D2:dropOutTwo0.1 acc:0.700181782245636\n",
      "OBJ:D1:0.2 D2P:11 D2:dropOutTwo0.2 acc:0.6587139368057251\n",
      "OBJ:D1:0.2 D2P:11 D2:dropOutTwo0.3 acc:0.6395137310028076\n",
      "OBJ:D1:0.2 D2P:11 D2:dropOutTwo0.5 acc:0.5203362703323364\n",
      "OBJ:D1:0.2 D2P:11 D2:dropOutTwo0.9 acc:0.25630539655685425\n",
      "OBJ:D1:0.2 D2P:12 D2:dropOutTwo0.1 acc:0.7409679889678955\n",
      "OBJ:D1:0.2 D2P:12 D2:dropOutTwo0.2 acc:0.6800727248191833\n",
      "OBJ:D1:0.2 D2P:12 D2:dropOutTwo0.3 acc:0.6453078985214233\n",
      "OBJ:D1:0.2 D2P:12 D2:dropOutTwo0.5 acc:0.5336287021636963\n",
      "OBJ:D1:0.2 D2P:12 D2:dropOutTwo0.9 acc:0.2649397850036621\n",
      "OBJ:D1:0.3 D2P:8 D2:dropOutTwo0.1 acc:0.658032238483429\n",
      "OBJ:D1:0.3 D2P:8 D2:dropOutTwo0.2 acc:0.6074755787849426\n",
      "OBJ:D1:0.3 D2P:8 D2:dropOutTwo0.3 acc:0.5352192521095276\n",
      "OBJ:D1:0.3 D2P:8 D2:dropOutTwo0.5 acc:0.45171552896499634\n",
      "OBJ:D1:0.3 D2P:8 D2:dropOutTwo0.9 acc:0.23858213424682617\n",
      "OBJ:D1:0.3 D2P:9 D2:dropOutTwo0.1 acc:0.6678027510643005\n",
      "OBJ:D1:0.3 D2P:9 D2:dropOutTwo0.2 acc:0.6211088299751282\n",
      "OBJ:D1:0.3 D2P:9 D2:dropOutTwo0.3 acc:0.5821404457092285\n",
      "OBJ:D1:0.3 D2P:9 D2:dropOutTwo0.5 acc:0.4843217432498932\n",
      "OBJ:D1:0.3 D2P:9 D2:dropOutTwo0.9 acc:0.2267666459083557\n",
      "OBJ:D1:0.3 D2P:10 D2:dropOutTwo0.1 acc:0.6709838509559631\n",
      "OBJ:D1:0.3 D2P:10 D2:dropOutTwo0.2 acc:0.6378095746040344\n",
      "OBJ:D1:0.3 D2P:10 D2:dropOutTwo0.3 acc:0.5719154477119446\n",
      "OBJ:D1:0.3 D2P:10 D2:dropOutTwo0.5 acc:0.49727335572242737\n",
      "OBJ:D1:0.3 D2P:10 D2:dropOutTwo0.9 acc:0.22188138961791992\n",
      "OBJ:D1:0.3 D2P:11 D2:dropOutTwo0.1 acc:0.6991592645645142\n",
      "OBJ:D1:0.3 D2P:11 D2:dropOutTwo0.2 acc:0.6337196230888367\n",
      "OBJ:D1:0.3 D2P:11 D2:dropOutTwo0.3 acc:0.6149738430976868\n",
      "OBJ:D1:0.3 D2P:11 D2:dropOutTwo0.5 acc:0.5086343884468079\n",
      "OBJ:D1:0.3 D2P:11 D2:dropOutTwo0.9 acc:0.24869348108768463\n",
      "OBJ:D1:0.3 D2P:12 D2:dropOutTwo0.1 acc:0.6965462565422058\n",
      "OBJ:D1:0.3 D2P:12 D2:dropOutTwo0.2 acc:0.6617814302444458\n",
      "OBJ:D1:0.3 D2P:12 D2:dropOutTwo0.3 acc:0.6045216917991638\n",
      "OBJ:D1:0.3 D2P:12 D2:dropOutTwo0.5 acc:0.5211315751075745\n",
      "OBJ:D1:0.3 D2P:12 D2:dropOutTwo0.9 acc:0.2551692724227905\n",
      "OBJ:D1:0.5 D2P:8 D2:dropOutTwo0.1 acc:0.6049761176109314\n",
      "OBJ:D1:0.5 D2P:8 D2:dropOutTwo0.2 acc:0.5590775012969971\n",
      "OBJ:D1:0.5 D2P:8 D2:dropOutTwo0.3 acc:0.5099977254867554\n",
      "OBJ:D1:0.5 D2P:8 D2:dropOutTwo0.5 acc:0.41979095339775085\n",
      "OBJ:D1:0.5 D2P:8 D2:dropOutTwo0.9 acc:0.21211087703704834\n",
      "OBJ:D1:0.5 D2P:9 D2:dropOutTwo0.1 acc:0.6096341609954834\n",
      "OBJ:D1:0.5 D2P:9 D2:dropOutTwo0.2 acc:0.5639627575874329\n",
      "OBJ:D1:0.5 D2P:9 D2:dropOutTwo0.3 acc:0.5264712572097778\n",
      "OBJ:D1:0.5 D2P:9 D2:dropOutTwo0.5 acc:0.4463758170604706\n",
      "OBJ:D1:0.5 D2P:9 D2:dropOutTwo0.9 acc:0.228357195854187\n",
      "OBJ:D1:0.5 D2P:10 D2:dropOutTwo0.1 acc:0.6149738430976868\n",
      "OBJ:D1:0.5 D2P:10 D2:dropOutTwo0.2 acc:0.5840718150138855\n",
      "OBJ:D1:0.5 D2P:10 D2:dropOutTwo0.3 acc:0.5372642874717712\n",
      "OBJ:D1:0.5 D2P:10 D2:dropOutTwo0.5 acc:0.45978185534477234\n",
      "OBJ:D1:0.5 D2P:10 D2:dropOutTwo0.9 acc:0.21688252687454224\n",
      "OBJ:D1:0.5 D2P:11 D2:dropOutTwo0.1 acc:0.6337196230888367\n",
      "OBJ:D1:0.5 D2P:11 D2:dropOutTwo0.2 acc:0.5853215456008911\n",
      "OBJ:D1:0.5 D2P:11 D2:dropOutTwo0.3 acc:0.5505567193031311\n",
      "OBJ:D1:0.5 D2P:11 D2:dropOutTwo0.5 acc:0.4603499174118042\n",
      "OBJ:D1:0.5 D2P:11 D2:dropOutTwo0.9 acc:0.2555101215839386\n",
      "OBJ:D1:0.5 D2P:12 D2:dropOutTwo0.1 acc:0.6403090357780457\n",
      "OBJ:D1:0.5 D2P:12 D2:dropOutTwo0.2 acc:0.6031583547592163\n",
      "OBJ:D1:0.5 D2P:12 D2:dropOutTwo0.3 acc:0.5510111451148987\n",
      "OBJ:D1:0.5 D2P:12 D2:dropOutTwo0.5 acc:0.4860258996486664\n",
      "OBJ:D1:0.5 D2P:12 D2:dropOutTwo0.9 acc:0.24857987463474274\n",
      "OBJ:D1:0.9 D2P:8 D2:dropOutTwo0.1 acc:0.4535332918167114\n",
      "OBJ:D1:0.9 D2P:8 D2:dropOutTwo0.2 acc:0.43853670358657837\n",
      "OBJ:D1:0.9 D2P:8 D2:dropOutTwo0.3 acc:0.410702109336853\n",
      "OBJ:D1:0.9 D2P:8 D2:dropOutTwo0.5 acc:0.3615087568759918\n",
      "OBJ:D1:0.9 D2P:8 D2:dropOutTwo0.9 acc:0.20983867347240448\n",
      "OBJ:D1:0.9 D2P:9 D2:dropOutTwo0.1 acc:0.46125879883766174\n",
      "OBJ:D1:0.9 D2P:9 D2:dropOutTwo0.2 acc:0.4335378408432007\n",
      "OBJ:D1:0.9 D2P:9 D2:dropOutTwo0.3 acc:0.4170643091201782\n",
      "OBJ:D1:0.9 D2P:9 D2:dropOutTwo0.5 acc:0.36593955755233765\n",
      "OBJ:D1:0.9 D2P:9 D2:dropOutTwo0.9 acc:0.22903884947299957\n",
      "OBJ:D1:0.9 D2P:10 D2:dropOutTwo0.1 acc:0.47046124935150146\n",
      "OBJ:D1:0.9 D2P:10 D2:dropOutTwo0.2 acc:0.4425130784511566\n",
      "OBJ:D1:0.9 D2P:10 D2:dropOutTwo0.3 acc:0.4335378408432007\n",
      "OBJ:D1:0.9 D2P:10 D2:dropOutTwo0.5 acc:0.3744603395462036\n",
      "OBJ:D1:0.9 D2P:10 D2:dropOutTwo0.9 acc:0.2317655086517334\n",
      "OBJ:D1:0.9 D2P:11 D2:dropOutTwo0.1 acc:0.46921154856681824\n",
      "OBJ:D1:0.9 D2P:11 D2:dropOutTwo0.2 acc:0.45444217324256897\n",
      "OBJ:D1:0.9 D2P:11 D2:dropOutTwo0.3 acc:0.4396727979183197\n",
      "OBJ:D1:0.9 D2P:11 D2:dropOutTwo0.5 acc:0.3869574964046478\n",
      "OBJ:D1:0.9 D2P:11 D2:dropOutTwo0.9 acc:0.2126789391040802\n",
      "OBJ:D1:0.9 D2P:12 D2:dropOutTwo0.1 acc:0.4762553870677948\n",
      "OBJ:D1:0.9 D2P:12 D2:dropOutTwo0.2 acc:0.4541013538837433\n",
      "OBJ:D1:0.9 D2P:12 D2:dropOutTwo0.3 acc:0.43569642305374146\n",
      "OBJ:D1:0.9 D2P:12 D2:dropOutTwo0.5 acc:0.3983185589313507\n",
      "OBJ:D1:0.9 D2P:12 D2:dropOutTwo0.9 acc:0.24062712490558624\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "#print(model.metrics['accuracy'])\n",
    "#print(model.loss_tracker.result().numpy())\n",
    "#print(str(model.metrics[1]))\n",
    "\n",
    "#print(keras.callbacks.History)\n",
    "#print(iterations)\n",
    "for obj in iterations:\n",
    "    #print(str(iterations[obj]))\n",
    "    #print(iterations[obj][len(iterations[obj]-1)])\n",
    "    #print(\"OBJ:\" + obj + \" acc:\"+  str(iterations[obj][0]))\n",
    "    #print(len(iterations[obj]))\n",
    "    #print(len(iterations[obj]))\n",
    "    print(\"OBJ:\" + obj + \" acc:\"+ str(iterations[obj][len(iterations[obj])-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec32eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725b86f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
